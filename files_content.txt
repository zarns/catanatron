
--- catanatron_core/catanatron/game.py ---
"""
Contains Game class which is a thin-wrapper around the State class.
"""

import uuid
import random
import sys
from typing import List, Union, Optional

from catanatron.models.enums import Action, ActionPrompt, ActionType
from catanatron.state import State, apply_action
from catanatron.state_functions import player_key, player_has_rolled
from catanatron.models.map import CatanMap
from catanatron.models.player import Color, Player

# To timeout RandomRobots from getting stuck...
TURNS_LIMIT = 1000


def is_valid_action(state, action):
    """True if its a valid action right now. An action is valid
    if its in playable_actions or if its a OFFER_TRADE in the right time."""
    if action.action_type == ActionType.OFFER_TRADE:
        return (
            state.current_color() == action.color
            and state.current_prompt == ActionPrompt.PLAY_TURN
            and player_has_rolled(state, action.color)
            and is_valid_trade(action.value)
        )

    return action in state.playable_actions


def is_valid_trade(action_value):
    """Checks the value of a OFFER_TRADE does not
    give away resources or trade matching resources.
    """
    offering = action_value[:5]
    asking = action_value[5:]
    if sum(offering) == 0 or sum(asking) == 0:
        return False  # cant give away cards

    for i, j in zip(offering, asking):
        if i > 0 and j > 0:
            return False  # cant trade same resources
    return True


class GameAccumulator:
    """Interface to hook into different game lifecycle events.

    Useful to compute aggregate statistics, log information, etc...
    """

    def __init__(*args, **kwargs):
        pass

    def before(self, game):
        """
        Called when the game is created, no actions have
        been taken by players yet, but the board is decided.
        """
        pass

    def step(self, game_before_action, action):
        """
        Called after each action taken by a player.
        Game should be right before action is taken.
        """
        pass

    def after(self, game):
        """
        Called when the game is finished.

        Check game.winning_color() to see if the game
        actually finished or exceeded turn limit (is None).
        """
        pass


class Game:
    """
    Initializes a map, decides player seating order, and exposes two main
    methods for executing the game (play and play_tick; to advance until
    completion or just by one decision by a player respectively).
    """

    def __init__(
        self,
        players: List[Player],
        seed: Optional[int] = None,
        discard_limit: int = 7,
        vps_to_win: int = 10,
        catan_map: Optional[CatanMap] = None,
        initialize: bool = True,
    ):
        """Creates a game (doesn't run it).

        Args:
            players (List[Player]): list of players, should be at most 4.
            seed (int, optional): Random seed to use (for reproducing games). Defaults to None.
            discard_limit (int, optional): Discard limit to use. Defaults to 7.
            vps_to_win (int, optional): Victory Points needed to win. Defaults to 10.
            catan_map (CatanMap, optional): Map to use. Defaults to None.
            initialize (bool, optional): Whether to initialize. Defaults to True.
        """
        if initialize:
            self.seed = seed if seed is not None else random.randrange(sys.maxsize)
            random.seed(self.seed)

            self.id = str(uuid.uuid4())
            self.vps_to_win = vps_to_win
            self.state = State(players, catan_map, discard_limit=discard_limit)

    def play(self, accumulators=[], decide_fn=None):
        """Executes game until a player wins or exceeded TURNS_LIMIT.

        Args:
            accumulators (list[Accumulator], optional): list of Accumulator classes to use.
                Their .consume method will be called with every action, and
                their .finalize method will be called when the game ends (if it ends)
                Defaults to [].
            decide_fn (function, optional): Function to overwrite current player's decision with.
                Defaults to None.
        Returns:
            Color: winning color or None if game exceeded TURNS_LIMIT
        """
        for accumulator in accumulators:
            accumulator.before(self)
        while self.winning_color() is None and self.state.num_turns < TURNS_LIMIT:
            self.play_tick(decide_fn=decide_fn, accumulators=accumulators)
        for accumulator in accumulators:
            accumulator.after(self)
        return self.winning_color()

    def play_tick(self, decide_fn=None, accumulators=[]):
        """Advances game by one ply (player decision).

        Args:
            decide_fn (function, optional): Function to overwrite current player's decision with.
                Defaults to None.

        Returns:
            Action: Final action (modified to be used as Log)
        """
        player = self.state.current_player()
        actions = self.state.playable_actions

        action = (
            decide_fn(player, self, actions)
            if decide_fn is not None
            else player.decide(self, actions)
        )
        # Call accumulator.step here, because we want game_before_action, action
        if len(accumulators) > 0:
            for accumulator in accumulators:
                accumulator.step(self, action)
        return self.execute(action)

    def execute(self, action: Action, validate_action: bool = True) -> Action:
        """Internal call that carries out decided action by player"""
        if validate_action and not is_valid_action(self.state, action):
            raise ValueError(
                f"{action} not playable right now. playable_actions={self.state.playable_actions}"
            )

        return apply_action(self.state, action)

    def winning_color(self) -> Union[Color, None]:
        """Gets winning color

        Returns:
            Union[Color, None]: Might be None if game truncated by TURNS_LIMIT
        """
        result = None
        for color in self.state.colors:
            key = player_key(self.state, color)
            if (
                self.state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"]
                >= self.vps_to_win
            ):
                result = color

        return result

    def copy(self) -> "Game":
        """Creates a copy of this Game, that can be modified without
        repercusions on this one (useful for simulations).

        Returns:
            Game: Game copy.
        """
        game_copy = Game(players=[], initialize=False)
        game_copy.seed = self.seed
        game_copy.id = self.id
        game_copy.vps_to_win = self.vps_to_win
        game_copy.state = self.state.copy()
        return game_copy

--- catanatron_core/catanatron/json.py ---
"""
Classes to encode/decode catanatron classes to JSON format.
"""

import json
from enum import Enum

from catanatron.models.map import Water, Port, LandTile
from catanatron.game import Game
from catanatron.models.player import Color
from catanatron.models.enums import RESOURCES, Action, ActionType
from catanatron.state_functions import get_longest_road_length


def longest_roads_by_player(state):
    result = dict()
    for color in state.colors:
        result[color.value] = get_longest_road_length(state, color)
    return result


def action_from_json(data):
    color = Color[data[0]]
    action_type = ActionType[data[1]]
    if action_type == ActionType.BUILD_ROAD:
        action = Action(color, action_type, tuple(data[2]))
    elif action_type == ActionType.MARITIME_TRADE:
        value = tuple(data[2])
        action = Action(color, action_type, value)
    else:
        action = Action(color, action_type, data[2])
    return action


class GameEncoder(json.JSONEncoder):
    def default(self, obj):
        if obj is None:
            return None
        if isinstance(obj, str):
            return obj
        if isinstance(obj, Enum):
            return obj.value
        if isinstance(obj, tuple):
            return obj
        if isinstance(obj, Game):
            nodes = {}
            edges = {}
            for coordinate, tile in obj.state.board.map.tiles.items():
                for direction, node_id in tile.nodes.items():
                    building = obj.state.board.buildings.get(node_id, None)
                    color = None if building is None else building[0]
                    building_type = None if building is None else building[1]
                    nodes[node_id] = {
                        "id": node_id,
                        "tile_coordinate": coordinate,
                        "direction": self.default(direction),
                        "building": self.default(building_type),
                        "color": self.default(color),
                    }
                for direction, edge in tile.edges.items():
                    color = obj.state.board.roads.get(edge, None)
                    edge_id = tuple(sorted(edge))
                    edges[edge_id] = {
                        "id": edge_id,
                        "tile_coordinate": coordinate,
                        "direction": self.default(direction),
                        "color": self.default(color),
                    }
            return {
                "tiles": [
                    {"coordinate": coordinate, "tile": self.default(tile)}
                    for coordinate, tile in obj.state.board.map.tiles.items()
                ],
                "adjacent_tiles": obj.state.board.map.adjacent_tiles,
                "nodes": nodes,
                "edges": list(edges.values()),
                "actions": [self.default(a) for a in obj.state.actions],
                "player_state": obj.state.player_state,
                "colors": obj.state.colors,
                "bot_colors": list(
                    map(
                        lambda p: p.color, filter(lambda p: p.is_bot, obj.state.players)
                    )
                ),
                "is_initial_build_phase": obj.state.is_initial_build_phase,
                "robber_coordinate": obj.state.board.robber_coordinate,
                "current_color": obj.state.current_color(),
                "current_prompt": obj.state.current_prompt,
                "current_playable_actions": obj.state.playable_actions,
                "longest_roads_by_player": longest_roads_by_player(obj.state),
                "winning_color": obj.winning_color(),
            }
        if isinstance(obj, Water):
            return {"type": "WATER"}
        if isinstance(obj, Port):
            return {
                "id": obj.id,
                "type": "PORT",
                "direction": self.default(obj.direction),
                "resource": self.default(obj.resource),
            }
        if isinstance(obj, LandTile):
            if obj.resource is None:
                return {"id": obj.id, "type": "DESERT"}
            return {
                "id": obj.id,
                "type": "RESOURCE_TILE",
                "resource": self.default(obj.resource),
                "number": obj.number,
            }
        return json.JSONEncoder.default(self, obj)

--- catanatron_core/catanatron/state.py ---
"""
Module with main State class and main apply_action call (game controller).
"""

import random
import pickle
from collections import defaultdict
from typing import Any, List, Tuple, Dict, Iterable

from catanatron.models.map import BASE_MAP_TEMPLATE, CatanMap
from catanatron.models.board import Board
from catanatron.models.enums import (
    DEVELOPMENT_CARDS,
    MONOPOLY,
    RESOURCES,
    YEAR_OF_PLENTY,
    SETTLEMENT,
    CITY,
    Action,
    ActionPrompt,
    ActionType,
)
from catanatron.models.decks import (
    CITY_COST_FREQDECK,
    DEVELOPMENT_CARD_COST_FREQDECK,
    SETTLEMENT_COST_FREQDECK,
    draw_from_listdeck,
    freqdeck_add,
    freqdeck_can_draw,
    freqdeck_contains,
    freqdeck_draw,
    freqdeck_from_listdeck,
    freqdeck_replenish,
    freqdeck_subtract,
    starting_devcard_bank,
    starting_resource_bank,
)
from catanatron.models.actions import (
    generate_playable_actions,
    road_building_possibilities,
)
from catanatron.state_functions import (
    build_city,
    build_road,
    build_settlement,
    buy_dev_card,
    maintain_longest_road,
    play_dev_card,
    player_can_afford_dev_card,
    player_can_play_dev,
    player_clean_turn,
    player_freqdeck_add,
    player_deck_draw,
    player_deck_random_draw,
    player_deck_replenish,
    player_freqdeck_subtract,
    player_deck_to_array,
    player_key,
    player_num_resource_cards,
    player_resource_freqdeck_contains,
)
from catanatron.models.player import Color, Player
from catanatron.models.enums import FastResource

# These will be prefixed by P0_, P1_, ...
# Create Player State blueprint
PLAYER_INITIAL_STATE = {
    "VICTORY_POINTS": 0,
    "ROADS_AVAILABLE": 15,
    "SETTLEMENTS_AVAILABLE": 5,
    "CITIES_AVAILABLE": 4,
    "HAS_ROAD": False,
    "HAS_ARMY": False,
    "HAS_ROLLED": False,
    "HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN": False,
    # de-normalized features (for performance since we think they are good features)
    "ACTUAL_VICTORY_POINTS": 0,
    "LONGEST_ROAD_LENGTH": 0,
}
for resource in RESOURCES:
    PLAYER_INITIAL_STATE[f"{resource}_IN_HAND"] = 0
for dev_card in DEVELOPMENT_CARDS:
    PLAYER_INITIAL_STATE[f"{dev_card}_IN_HAND"] = 0
    PLAYER_INITIAL_STATE[f"PLAYED_{dev_card}"] = 0


class State:
    """Collection of variables representing state

    Attributes:
        players (List[Player]): DEPRECATED. Reference to list of players.
            Use .colors instead, and move this reference to the Game class.
            Deprecated because we want this class to only contain state
            information that can be easily copiable.
        board (Board): Board state. Settlement locations, cities,
            roads, ect... See Board class.
        player_state (Dict[str, Any]): See PLAYER_INITIAL_STATE. It will
            contain one of each key in PLAYER_INITIAL_STATE but prefixed
            with "P<index_of_player>".
            Example: { P0_HAS_ROAD: False, P1_SETTLEMENTS_AVAILABLE: 18, ... }
        color_to_index (Dict[Color, int]): Color to seating location cache
        colors (Tuple[Color]): Represents seating order.
        resource_freqdeck (List[int]): Represents resource cards in the bank.
            Each element is the amount of [WOOD, BRICK, SHEEP, WHEAT, ORE].
        development_listdeck (List[FastDevCard]): Represents development cards in
            the bank. Already shuffled.
        buildings_by_color (Dict[Color, Dict[FastBuildingType, List]]): Cache of
            buildings. Can be used like: `buildings_by_color[Color.RED][SETTLEMENT]`
            to get a list of all node ids where RED has settlements.
        actions (List[Action]): Log of all actions taken. Fully-specified actions.
        num_turns (int): number of turns thus far
        current_player_index (int): index per colors array of player that should be
            making a decision now. Not necesarilly the same as current_turn_index
            because there are out-of-turn decisions like discarding.
        current_turn_index (int): index per colors array of player whose turn is it.
        current_prompt (ActionPrompt): DEPRECATED. Not needed; use is_initial_build_phase,
            is_moving_knight, etc... instead.
        is_discarding (bool): If current player needs to discard.
        is_moving_knight (bool): If current player needs to move robber.
        is_road_building (bool): If current player needs to build free roads per Road
            Building dev card.
        free_roads_available (int): Number of roads available left in Road Building
            phase.
        playable_actions (List[Action]): List of playable actions by current player.
    """

    def __init__(
        self,
        players: List[Player],
        catan_map=None,
        discard_limit=7,
        initialize=True,
    ):
        if initialize:
            self.players = random.sample(players, len(players))
            self.colors = tuple([player.color for player in self.players])
            self.board = Board(catan_map or CatanMap.from_template(BASE_MAP_TEMPLATE))
            self.discard_limit = discard_limit

            # feature-ready dictionary
            self.player_state = dict()
            for index in range(len(self.colors)):
                for key, value in PLAYER_INITIAL_STATE.items():
                    self.player_state[f"P{index}_{key}"] = value
            self.color_to_index = {
                color: index for index, color in enumerate(self.colors)
            }

            self.resource_freqdeck = starting_resource_bank()
            self.development_listdeck = starting_devcard_bank()
            random.shuffle(self.development_listdeck)

            # Auxiliary attributes to implement game logic
            self.buildings_by_color: Dict[Color, Dict[Any, Any]] = {
                p.color: defaultdict(list) for p in players
            }
            self.actions: List[Action] = []  # log of all action taken by players
            self.num_turns = 0  # num_completed_turns

            # Current prompt / player
            # Two variables since there can be out-of-turn plays
            self.current_player_index = 0
            self.current_turn_index = 0

            # TODO: Deprecate self.current_prompt in favor of indicator variables
            self.current_prompt = ActionPrompt.BUILD_INITIAL_SETTLEMENT
            self.is_initial_build_phase = True
            self.is_discarding = False
            self.is_moving_knight = False
            self.is_road_building = False
            self.free_roads_available = 0

            self.is_resolving_trade = False
            self.current_trade: Tuple = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
            self.acceptees = tuple(False for _ in self.colors)

            self.playable_actions = generate_playable_actions(self)

    def current_player(self):
        """Helper for accessing Player instance who should decide next"""
        return self.players[self.current_player_index]

    def current_color(self):
        """Helper for accessing color (player) who should decide next"""
        return self.colors[self.current_player_index]

    def copy(self):
        """Creates a copy of this State class that can be modified without
        repercusions to this one. Immutable values are just copied over.

        Returns:
            State: State copy.
        """
        state_copy = State([], None, initialize=False)
        state_copy.players = self.players
        state_copy.discard_limit = self.discard_limit  # immutable

        state_copy.board = self.board.copy()

        state_copy.player_state = self.player_state.copy()
        state_copy.color_to_index = self.color_to_index
        state_copy.colors = self.colors  # immutable

        state_copy.resource_freqdeck = self.resource_freqdeck.copy()
        state_copy.development_listdeck = self.development_listdeck.copy()

        state_copy.buildings_by_color = pickle.loads(
            pickle.dumps(self.buildings_by_color)
        )
        state_copy.actions = self.actions.copy()
        state_copy.num_turns = self.num_turns

        # Current prompt / player
        # Two variables since there can be out-of-turn plays
        state_copy.current_player_index = self.current_player_index
        state_copy.current_turn_index = self.current_turn_index

        state_copy.current_prompt = self.current_prompt
        state_copy.is_initial_build_phase = self.is_initial_build_phase
        state_copy.is_discarding = self.is_discarding
        state_copy.is_moving_knight = self.is_moving_knight
        state_copy.is_road_building = self.is_road_building
        state_copy.free_roads_available = self.free_roads_available

        state_copy.is_resolving_trade = self.is_resolving_trade
        state_copy.current_trade = self.current_trade
        state_copy.acceptees = self.acceptees

        state_copy.playable_actions = self.playable_actions
        return state_copy


def roll_dice():
    """Yields two random numbers

    Returns:
        tuple[int, int]: 2-tuple of random numbers from 1 to 6 inclusive.
    """
    return (random.randint(1, 6), random.randint(1, 6))


def yield_resources(board: Board, resource_freqdeck, number):
    """Computes resource payouts for given board and dice roll number.

    Args:
        board (Board): Board state
        resource_freqdeck (List[int]): Bank's resource freqdeck
        number (int): Sum of dice roll

    Returns:
        (dict, List[int]): 2-tuple.
            First element is color => freqdeck mapping. e.g. {Color.RED: [0,0,0,3,0]}.
            Second is an array of resources that couldn't be yieleded
            because they depleted.
    """
    intented_payout: Dict[Color, Dict[FastResource, int]] = defaultdict(
        lambda: defaultdict(int)
    )
    resource_totals: Dict[FastResource, int] = defaultdict(int)
    for coordinate, tile in board.map.land_tiles.items():
        if tile.number != number or board.robber_coordinate == coordinate:
            continue  # doesn't yield

        for node_id in tile.nodes.values():
            building = board.buildings.get(node_id, None)
            assert tile.resource is not None
            if building is None:
                continue
            elif building[1] == SETTLEMENT:
                intented_payout[building[0]][tile.resource] += 1
                resource_totals[tile.resource] += 1
            elif building[1] == CITY:
                intented_payout[building[0]][tile.resource] += 2
                resource_totals[tile.resource] += 2

    # for each resource, check enough in deck to yield.
    depleted = []
    for resource in RESOURCES:
        total = resource_totals[resource]
        if not freqdeck_can_draw(resource_freqdeck, total, resource):
            depleted.append(resource)

    # build final data color => freqdeck structure
    payout = {}
    for player, player_payout in intented_payout.items():
        payout[player] = [0, 0, 0, 0, 0]

        for resource, count in player_payout.items():
            if resource not in depleted:
                freqdeck_replenish(payout[player], count, resource)

    return payout, depleted


def advance_turn(state, direction=1):
    """Sets .current_player_index"""
    next_index = next_player_index(state, direction)
    state.current_player_index = next_index
    state.current_turn_index = next_index
    state.num_turns += 1


def next_player_index(state, direction=1):
    return (state.current_player_index + direction) % len(state.colors)


def apply_action(state: State, action: Action):
    """Main controller call. Follows redux-like pattern and
    routes the given action to the appropiate state-changing calls.

    Responsible for maintaining:
        .current_player_index, .current_turn_index,
        .current_prompt (and similars), .playable_actions.

    Appends given action to the list of actions, as fully-specified action.

    Args:
        state (State): State to mutate
        action (Action): Action to carry out

    Raises:
        ValueError: If invalid action given

    Returns:
        Action: Fully-specified action
    """

    if action.action_type == ActionType.END_TURN:
        player_clean_turn(state, action.color)
        advance_turn(state)
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.BUILD_SETTLEMENT:
        node_id = action.value
        if state.is_initial_build_phase:
            state.board.build_settlement(action.color, node_id, True)
            build_settlement(state, action.color, node_id, True)
            buildings = state.buildings_by_color[action.color][SETTLEMENT]

            # yield resources if second settlement
            is_second_house = len(buildings) == 2
            if is_second_house:
                key = player_key(state, action.color)
                for tile in state.board.map.adjacent_tiles[node_id]:
                    if tile.resource != None:
                        freqdeck_draw(state.resource_freqdeck, 1, tile.resource)  # type: ignore
                        state.player_state[f"{key}_{tile.resource}_IN_HAND"] += 1

            # state.current_player_index stays the same
            state.current_prompt = ActionPrompt.BUILD_INITIAL_ROAD
            state.playable_actions = generate_playable_actions(state)
        else:
            (
                previous_road_color,
                road_color,
                road_lengths,
            ) = state.board.build_settlement(action.color, node_id, False)
            build_settlement(state, action.color, node_id, False)
            state.resource_freqdeck = freqdeck_add(
                state.resource_freqdeck, SETTLEMENT_COST_FREQDECK
            )  # replenish bank
            maintain_longest_road(state, previous_road_color, road_color, road_lengths)

            # state.current_player_index stays the same
            # state.current_prompt stays as PLAY
            state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.BUILD_ROAD:
        edge = action.value
        if state.is_initial_build_phase:
            state.board.build_road(action.color, edge)
            build_road(state, action.color, edge, True)

            # state.current_player_index depend on what index are we
            # state.current_prompt too
            buildings = [
                len(state.buildings_by_color[color][SETTLEMENT])
                for color in state.color_to_index.keys()
            ]
            num_buildings = sum(buildings)
            num_players = len(buildings)
            going_forward = num_buildings < num_players
            at_the_end = num_buildings == num_players
            if going_forward:
                advance_turn(state)
                state.current_prompt = ActionPrompt.BUILD_INITIAL_SETTLEMENT
            elif at_the_end:
                state.current_prompt = ActionPrompt.BUILD_INITIAL_SETTLEMENT
            elif num_buildings == 2 * num_players:
                state.is_initial_build_phase = False
                state.current_prompt = ActionPrompt.PLAY_TURN
            else:
                advance_turn(state, -1)
                state.current_prompt = ActionPrompt.BUILD_INITIAL_SETTLEMENT
            state.playable_actions = generate_playable_actions(state)
        elif state.is_road_building and state.free_roads_available > 0:
            result = state.board.build_road(action.color, edge)
            previous_road_color, road_color, road_lengths = result
            build_road(state, action.color, edge, True)
            maintain_longest_road(state, previous_road_color, road_color, road_lengths)

            state.free_roads_available -= 1
            if (
                state.free_roads_available == 0
                or len(road_building_possibilities(state, action.color, False)) == 0
            ):
                state.is_road_building = False
                state.free_roads_available = 0
                # state.current_player_index stays the same
                # state.current_prompt stays as PLAY
            state.playable_actions = generate_playable_actions(state)
        else:
            result = state.board.build_road(action.color, edge)
            previous_road_color, road_color, road_lengths = result
            build_road(state, action.color, edge, False)
            maintain_longest_road(state, previous_road_color, road_color, road_lengths)

            # state.current_player_index stays the same
            # state.current_prompt stays as PLAY
            state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.BUILD_CITY:
        node_id = action.value
        state.board.build_city(action.color, node_id)
        build_city(state, action.color, node_id)
        state.resource_freqdeck = freqdeck_add(
            state.resource_freqdeck, CITY_COST_FREQDECK
        )  # replenish bank

        # state.current_player_index stays the same
        # state.current_prompt stays as PLAY
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.BUY_DEVELOPMENT_CARD:
        if len(state.development_listdeck) == 0:
            raise ValueError("No more development cards")
        if not player_can_afford_dev_card(state, action.color):
            raise ValueError("No money to buy development card")

        if action.value is None:
            card = state.development_listdeck.pop()  # already shuffled
        else:
            card = action.value
            draw_from_listdeck(state.development_listdeck, 1, card)

        buy_dev_card(state, action.color, card)
        state.resource_freqdeck = freqdeck_add(
            state.resource_freqdeck, DEVELOPMENT_CARD_COST_FREQDECK
        )

        action = Action(action.color, action.action_type, card)
        # state.current_player_index stays the same
        # state.current_prompt stays as PLAY
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.ROLL:
        key = player_key(state, action.color)
        state.player_state[f"{key}_HAS_ROLLED"] = True

        dices = action.value or roll_dice()
        number = dices[0] + dices[1]
        action = Action(action.color, action.action_type, dices)

        if number == 7:
            discarders = [
                player_num_resource_cards(state, color) > state.discard_limit
                for color in state.colors
            ]
            should_enter_discarding_sequence = any(discarders)

            if should_enter_discarding_sequence:
                state.current_player_index = discarders.index(True)
                state.current_prompt = ActionPrompt.DISCARD
                state.is_discarding = True
            else:
                # state.current_player_index stays the same
                state.current_prompt = ActionPrompt.MOVE_ROBBER
                state.is_moving_knight = True
            state.playable_actions = generate_playable_actions(state)
        else:
            payout, _ = yield_resources(state.board, state.resource_freqdeck, number)
            for color, resource_freqdeck in payout.items():
                # Atomically add to player's hand and remove from bank
                player_freqdeck_add(state, color, resource_freqdeck)
                state.resource_freqdeck = freqdeck_subtract(
                    state.resource_freqdeck, resource_freqdeck
                )

            # state.current_player_index stays the same
            state.current_prompt = ActionPrompt.PLAY_TURN
            state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.DISCARD:
        hand = player_deck_to_array(state, action.color)
        num_to_discard = len(hand) // 2
        if action.value is None:
            # TODO: Forcefully discard randomly so that decision tree doesnt explode in possibilities.
            discarded = random.sample(hand, k=num_to_discard)
        else:
            discarded = action.value  # for replay functionality
        to_discard = freqdeck_from_listdeck(discarded)

        player_freqdeck_subtract(state, action.color, to_discard)
        state.resource_freqdeck = freqdeck_add(state.resource_freqdeck, to_discard)
        action = Action(action.color, action.action_type, discarded)

        # Advance turn
        discarders_left = [
            player_num_resource_cards(state, color) > 7 for color in state.colors
        ][state.current_player_index + 1 :]
        if any(discarders_left):
            to_skip = discarders_left.index(True)
            state.current_player_index = state.current_player_index + 1 + to_skip
            # state.current_prompt stays the same
        else:
            state.current_player_index = state.current_turn_index
            state.current_prompt = ActionPrompt.MOVE_ROBBER
            state.is_discarding = False
            state.is_moving_knight = True

        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.MOVE_ROBBER:
        (coordinate, robbed_color, robbed_resource) = action.value
        state.board.robber_coordinate = coordinate
        if robbed_color is not None:
            if robbed_resource is None:
                robbed_resource = player_deck_random_draw(state, robbed_color)
                action = Action(
                    action.color,
                    action.action_type,
                    (coordinate, robbed_color, robbed_resource),
                )
            else:  # for replay functionality
                player_deck_draw(state, robbed_color, robbed_resource)
            player_deck_replenish(state, action.color, robbed_resource)

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.PLAY_KNIGHT_CARD:
        if not player_can_play_dev(state, action.color, "KNIGHT"):
            raise ValueError("Player cant play knight card now")

        play_dev_card(state, action.color, "KNIGHT")

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.MOVE_ROBBER
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.PLAY_YEAR_OF_PLENTY:
        cards_selected = freqdeck_from_listdeck(action.value)
        if not player_can_play_dev(state, action.color, YEAR_OF_PLENTY):
            raise ValueError("Player cant play year of plenty now")
        if not freqdeck_contains(state.resource_freqdeck, cards_selected):
            raise ValueError("Not enough resources of this type (these types?) in bank")
        player_freqdeck_add(state, action.color, cards_selected)
        state.resource_freqdeck = freqdeck_subtract(
            state.resource_freqdeck, cards_selected
        )
        play_dev_card(state, action.color, YEAR_OF_PLENTY)

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.PLAY_MONOPOLY:
        mono_resource = action.value
        cards_stolen = [0, 0, 0, 0, 0]
        if not player_can_play_dev(state, action.color, MONOPOLY):
            raise ValueError("Player cant play monopoly now")
        for color in state.colors:
            if not color == action.color:
                key = player_key(state, color)
                number_of_cards_to_steal = state.player_state[
                    f"{key}_{mono_resource}_IN_HAND"
                ]
                freqdeck_replenish(
                    cards_stolen, number_of_cards_to_steal, mono_resource
                )
                player_deck_draw(state, color, mono_resource, number_of_cards_to_steal)
        player_freqdeck_add(state, action.color, cards_stolen)
        play_dev_card(state, action.color, MONOPOLY)

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.PLAY_ROAD_BUILDING:
        if not player_can_play_dev(state, action.color, "ROAD_BUILDING"):
            raise ValueError("Player cant play road building now")

        play_dev_card(state, action.color, "ROAD_BUILDING")
        state.is_road_building = True
        state.free_roads_available = 2

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.MARITIME_TRADE:
        trade_offer = action.value
        offering = freqdeck_from_listdeck(
            filter(lambda r: r is not None, trade_offer[:-1])
        )
        asking = freqdeck_from_listdeck(trade_offer[-1:])
        if not player_resource_freqdeck_contains(state, action.color, offering):
            raise ValueError("Trying to trade without money")
        if not freqdeck_contains(state.resource_freqdeck, asking):
            raise ValueError("Bank doenst have those cards")
        player_freqdeck_subtract(state, action.color, offering)
        state.resource_freqdeck = freqdeck_add(state.resource_freqdeck, offering)
        player_freqdeck_add(state, action.color, asking)
        state.resource_freqdeck = freqdeck_subtract(state.resource_freqdeck, asking)

        # state.current_player_index stays the same
        state.current_prompt = ActionPrompt.PLAY_TURN
        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.OFFER_TRADE:
        state.is_resolving_trade = True
        state.current_trade = (*action.value, state.current_turn_index)

        # go in seating order; order won't matter because of "acceptees hook"
        state.current_player_index = next(
            i for i, c in enumerate(state.colors) if c != action.color
        )  # cant ask yourself
        state.current_prompt = ActionPrompt.DECIDE_TRADE

        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.ACCEPT_TRADE:
        # add yourself to self.acceptees
        index = state.colors.index(action.color)
        new_acceptess = list(state.acceptees)
        new_acceptess[index] = True  # type: ignore
        state.acceptees = tuple(new_acceptess)

        try:
            # keep going around table w/o asking yourself or players that have answered
            state.current_player_index = next(
                i
                for i, c in enumerate(state.colors)
                if c != action.color and i > state.current_player_index
            )
            # .is_resolving_trade, .current_trade, .current_prompt, .acceptees stay the same
        except StopIteration:
            # by this action, there is at least 1 acceptee, so go to DECIDE_ACCEPTEES
            # .is_resolving_trade, .current_trade, .acceptees stay the same
            state.current_player_index = state.current_turn_index
            state.current_prompt = ActionPrompt.DECIDE_ACCEPTEES

        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.REJECT_TRADE:
        try:
            # keep going around table w/o asking yourself or players that have answered
            state.current_player_index = next(
                i
                for i, c in enumerate(state.colors)
                if c != action.color and i > state.current_player_index
            )
            # .is_resolving_trade, .current_trade, .current_prompt, .acceptees stay the same
        except StopIteration:
            # if no acceptees at this point, go back to PLAY_TURN
            if sum(state.acceptees) == 0:
                reset_trading_state(state)

                state.current_player_index = state.current_turn_index
                state.current_prompt = ActionPrompt.PLAY_TURN
            else:
                # go to offering player with all the answers
                # .is_resolving_trade, .current_trade, .acceptees stay the same
                state.current_player_index = state.current_turn_index
                state.current_prompt = ActionPrompt.DECIDE_ACCEPTEES

        state.playable_actions = generate_playable_actions(state)
    elif action.action_type == ActionType.CONFIRM_TRADE:
        # apply trade
        offering = action.value[:5]
        asking = action.value[5:10]
        enemy_color = action.value[10]
        player_freqdeck_subtract(state, action.color, offering)
        player_freqdeck_add(state, action.color, asking)
        player_freqdeck_subtract(state, enemy_color, asking)
        player_freqdeck_add(state, enemy_color, offering)

        reset_trading_state(state)

        state.current_player_index = state.current_turn_index
        state.current_prompt = ActionPrompt.PLAY_TURN
    elif action.action_type == ActionType.CANCEL_TRADE:
        reset_trading_state(state)

        state.current_player_index = state.current_turn_index
        state.current_prompt = ActionPrompt.PLAY_TURN
    else:
        raise ValueError("Unknown ActionType " + str(action.action_type))

    # TODO: Think about possible-action/idea vs finalized-action design
    state.actions.append(action)
    return action


def reset_trading_state(state):
    state.is_resolving_trade = False
    state.current_trade = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
    state.acceptees = tuple(False for _ in state.colors)

--- catanatron_core/catanatron/state_functions.py ---
"""
Functions that mutate the given state accordingly. Core of game logic.
Some are helpers to _read_ information from state and keep the rest
of the code decoupled from state representation.
"""
import random
from typing import Optional

from catanatron.models.decks import ROAD_COST_FREQDECK, freqdeck_add
from catanatron.models.enums import (
    VICTORY_POINT,
    WOOD,
    BRICK,
    SHEEP,
    WHEAT,
    ORE,
    SETTLEMENT,
    CITY,
    ROAD,
    FastResource,
)


def maintain_longest_road(state, previous_road_color, road_color, road_lengths):
    for color, length in road_lengths.items():
        key = player_key(state, color)
        state.player_state[f"{key}_LONGEST_ROAD_LENGTH"] = length

    # If road_color is not set or is the same as before, do nothing.
    if road_color is None or (previous_road_color == road_color):
        return

    # Set new longest road player and unset previous if any.
    winner_key = player_key(state, road_color)
    state.player_state[f"{winner_key}_HAS_ROAD"] = True
    state.player_state[f"{winner_key}_VICTORY_POINTS"] += 2
    state.player_state[f"{winner_key}_ACTUAL_VICTORY_POINTS"] += 2
    if previous_road_color is not None:
        loser_key = player_key(state, previous_road_color)
        state.player_state[f"{loser_key}_HAS_ROAD"] = False
        state.player_state[f"{loser_key}_VICTORY_POINTS"] -= 2
        state.player_state[f"{loser_key}_ACTUAL_VICTORY_POINTS"] -= 2


def maintain_largest_army(state, color, previous_army_color, previous_army_size):
    candidate_size = get_played_dev_cards(state, color, "KNIGHT")

    # Skip if army is too small to be considered.
    if candidate_size < 3:
        return

    if previous_army_color is None:
        winner_key = player_key(state, color)
        state.player_state[f"{winner_key}_HAS_ARMY"] = True
        state.player_state[f"{winner_key}_VICTORY_POINTS"] += 2
        state.player_state[f"{winner_key}_ACTUAL_VICTORY_POINTS"] += 2
    elif previous_army_size < candidate_size and previous_army_color != color:
        # switch, remove previous points and award to new king
        winner_key = player_key(state, color)
        state.player_state[f"{winner_key}_HAS_ARMY"] = True
        state.player_state[f"{winner_key}_VICTORY_POINTS"] += 2
        state.player_state[f"{winner_key}_ACTUAL_VICTORY_POINTS"] += 2

        loser_key = player_key(state, previous_army_color)
        state.player_state[f"{loser_key}_HAS_ARMY"] = False
        state.player_state[f"{loser_key}_VICTORY_POINTS"] -= 2
        state.player_state[f"{loser_key}_ACTUAL_VICTORY_POINTS"] -= 2
    # else: someone else has army and we dont compete


# ===== State Getters
def player_key(state, color):
    return f"P{state.color_to_index[color]}"


def get_enemy_colors(colors, player_color):
    return filter(lambda c: c != player_color, colors)


def get_actual_victory_points(state, color):
    key = player_key(state, color)
    return state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"]


def get_visible_victory_points(state, color):
    key = player_key(state, color)
    return state.player_state[f"{key}_VICTORY_POINTS"]


def get_longest_road_color(state):
    for index in range(len(state.colors)):
        if state.player_state[f"P{index}_HAS_ROAD"]:
            return state.colors[index]
    return None


def get_largest_army(state):
    for index in range(len(state.colors)):
        if state.player_state[f"P{index}_HAS_ARMY"]:
            return (
                state.colors[index],
                state.player_state[f"P{index}_PLAYED_KNIGHT"],
            )
    return None, None


def player_has_rolled(state, color):
    key = player_key(state, color)
    return state.player_state[f"{key}_HAS_ROLLED"]


def get_longest_road_length(state, color):
    key = player_key(state, color)
    return state.player_state[key + "_LONGEST_ROAD_LENGTH"]


def get_played_dev_cards(state, color, dev_card=None):
    key = player_key(state, color)
    if dev_card is None:
        return (
            state.player_state[f"{key}_PLAYED_KNIGHT"]
            + state.player_state[f"{key}_PLAYED_MONOPOLY"]
            + state.player_state[f"{key}_PLAYED_ROAD_BUILDING"]
            + state.player_state[f"{key}_PLAYED_YEAR_OF_PLENTY"]
        )
    else:
        return state.player_state[f"{key}_PLAYED_{dev_card}"]


def get_dev_cards_in_hand(state, color, dev_card=None):
    key = player_key(state, color)
    if dev_card is None:
        return (
            state.player_state[f"{key}_KNIGHT_IN_HAND"]
            + state.player_state[f"{key}_MONOPOLY_IN_HAND"]
            + state.player_state[f"{key}_ROAD_BUILDING_IN_HAND"]
            + state.player_state[f"{key}_YEAR_OF_PLENTY_IN_HAND"]
            + state.player_state[f"{key}_VICTORY_POINT_IN_HAND"]
        )
    else:
        return state.player_state[f"{key}_{dev_card}_IN_HAND"]


def get_player_buildings(state, color_param, building_type_param):
    return state.buildings_by_color[color_param][building_type_param]


def get_player_freqdeck(state, color):
    """Returns a 'freqdeck' of a player's resource hand."""
    key = player_key(state, color)
    return [
        state.player_state[f"{key}_WOOD_IN_HAND"],
        state.player_state[f"{key}_BRICK_IN_HAND"],
        state.player_state[f"{key}_SHEEP_IN_HAND"],
        state.player_state[f"{key}_WHEAT_IN_HAND"],
        state.player_state[f"{key}_ORE_IN_HAND"],
    ]


# ===== State Mutators
def build_settlement(state, color, node_id, is_free):
    state.buildings_by_color[color][SETTLEMENT].append(node_id)

    key = player_key(state, color)
    state.player_state[f"{key}_SETTLEMENTS_AVAILABLE"] -= 1

    state.player_state[f"{key}_VICTORY_POINTS"] += 1
    state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"] += 1

    if not is_free:
        state.player_state[f"{key}_WOOD_IN_HAND"] -= 1
        state.player_state[f"{key}_BRICK_IN_HAND"] -= 1
        state.player_state[f"{key}_SHEEP_IN_HAND"] -= 1
        state.player_state[f"{key}_WHEAT_IN_HAND"] -= 1


def build_road(state, color, edge, is_free):
    state.buildings_by_color[color][ROAD].append(edge)

    key = player_key(state, color)
    state.player_state[f"{key}_ROADS_AVAILABLE"] -= 1
    if not is_free:
        state.player_state[f"{key}_WOOD_IN_HAND"] -= 1
        state.player_state[f"{key}_BRICK_IN_HAND"] -= 1
        state.resource_freqdeck = freqdeck_add(
            state.resource_freqdeck, ROAD_COST_FREQDECK
        )  # replenish bank


def build_city(state, color, node_id):
    state.buildings_by_color[color][SETTLEMENT].remove(node_id)
    state.buildings_by_color[color][CITY].append(node_id)

    key = player_key(state, color)
    state.player_state[f"{key}_SETTLEMENTS_AVAILABLE"] += 1
    state.player_state[f"{key}_CITIES_AVAILABLE"] -= 1

    state.player_state[f"{key}_VICTORY_POINTS"] += 1
    state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"] += 1

    state.player_state[f"{key}_WHEAT_IN_HAND"] -= 2
    state.player_state[f"{key}_ORE_IN_HAND"] -= 3


# ===== Deck Functions
def player_can_afford_dev_card(state, color):
    key = player_key(state, color)
    return (
        state.player_state[f"{key}_SHEEP_IN_HAND"] >= 1
        and state.player_state[f"{key}_WHEAT_IN_HAND"] >= 1
        and state.player_state[f"{key}_ORE_IN_HAND"] >= 1
    )


def player_resource_freqdeck_contains(state, color, freqdeck):
    key = player_key(state, color)
    return (
        state.player_state[f"{key}_WOOD_IN_HAND"] >= freqdeck[0]
        and state.player_state[f"{key}_BRICK_IN_HAND"] >= freqdeck[1]
        and state.player_state[f"{key}_SHEEP_IN_HAND"] >= freqdeck[2]
        and state.player_state[f"{key}_WHEAT_IN_HAND"] >= freqdeck[3]
        and state.player_state[f"{key}_ORE_IN_HAND"] >= freqdeck[4]
    )


def player_can_play_dev(state, color, dev_card):
    key = player_key(state, color)
    return (
        not state.player_state[f"{key}_HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN"]
        and state.player_state[f"{key}_{dev_card}_IN_HAND"] >= 1
    )


def player_freqdeck_add(state, color, freqdeck):
    key = player_key(state, color)
    state.player_state[f"{key}_WOOD_IN_HAND"] += freqdeck[0]
    state.player_state[f"{key}_BRICK_IN_HAND"] += freqdeck[1]
    state.player_state[f"{key}_SHEEP_IN_HAND"] += freqdeck[2]
    state.player_state[f"{key}_WHEAT_IN_HAND"] += freqdeck[3]
    state.player_state[f"{key}_ORE_IN_HAND"] += freqdeck[4]


def player_freqdeck_subtract(state, color, freqdeck):
    key = player_key(state, color)
    state.player_state[f"{key}_WOOD_IN_HAND"] -= freqdeck[0]
    state.player_state[f"{key}_BRICK_IN_HAND"] -= freqdeck[1]
    state.player_state[f"{key}_SHEEP_IN_HAND"] -= freqdeck[2]
    state.player_state[f"{key}_WHEAT_IN_HAND"] -= freqdeck[3]
    state.player_state[f"{key}_ORE_IN_HAND"] -= freqdeck[4]


def buy_dev_card(state, color, dev_card):
    key = player_key(state, color)

    assert state.player_state[f"{key}_SHEEP_IN_HAND"] >= 1
    assert state.player_state[f"{key}_WHEAT_IN_HAND"] >= 1
    assert state.player_state[f"{key}_ORE_IN_HAND"] >= 1

    state.player_state[f"{key}_{dev_card}_IN_HAND"] += 1
    if dev_card == VICTORY_POINT:
        state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"] += 1

    state.player_state[f"{key}_SHEEP_IN_HAND"] -= 1
    state.player_state[f"{key}_WHEAT_IN_HAND"] -= 1
    state.player_state[f"{key}_ORE_IN_HAND"] -= 1


def player_num_resource_cards(state, color, card: Optional[FastResource] = None):
    key = player_key(state, color)
    if card is None:
        return (
            state.player_state[f"{key}_WOOD_IN_HAND"]
            + state.player_state[f"{key}_BRICK_IN_HAND"]
            + state.player_state[f"{key}_SHEEP_IN_HAND"]
            + state.player_state[f"{key}_WHEAT_IN_HAND"]
            + state.player_state[f"{key}_ORE_IN_HAND"]
        )
    else:
        return state.player_state[f"{key}_{card}_IN_HAND"]


def player_num_dev_cards(state, color):
    key = player_key(state, color)
    return (
        state.player_state[f"{key}_YEAR_OF_PLENTY_IN_HAND"]
        + state.player_state[f"{key}_MONOPOLY_IN_HAND"]
        + state.player_state[f"{key}_VICTORY_POINT_IN_HAND"]
        + state.player_state[f"{key}_KNIGHT_IN_HAND"]
        + state.player_state[f"{key}_ROAD_BUILDING_IN_HAND"]
    )


def player_deck_to_array(state, color):
    key = player_key(state, color)
    return (
        state.player_state[f"{key}_WOOD_IN_HAND"] * [WOOD]
        + state.player_state[f"{key}_BRICK_IN_HAND"] * [BRICK]
        + state.player_state[f"{key}_SHEEP_IN_HAND"] * [SHEEP]
        + state.player_state[f"{key}_WHEAT_IN_HAND"] * [WHEAT]
        + state.player_state[f"{key}_ORE_IN_HAND"] * [ORE]
    )


def player_deck_draw(state, color, card, amount=1):
    key = player_key(state, color)
    assert state.player_state[f"{key}_{card}_IN_HAND"] >= amount
    state.player_state[f"{key}_{card}_IN_HAND"] -= amount


def player_deck_replenish(state, color, resource, amount=1):
    key = player_key(state, color)
    state.player_state[f"{key}_{resource}_IN_HAND"] += amount


def player_deck_random_draw(state, color):
    deck_array = player_deck_to_array(state, color)
    resource = random.choice(deck_array)
    player_deck_draw(state, color, resource)
    return resource


def play_dev_card(state, color, dev_card):
    if dev_card == "KNIGHT":
        previous_army_color, previous_army_size = get_largest_army(state)
    key = player_key(state, color)
    player_deck_draw(state, color, dev_card)
    state.player_state[f"{key}_HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN"] = True
    state.player_state[f"{key}_PLAYED_{dev_card}"] += 1
    if dev_card == "KNIGHT":
        maintain_largest_army(state, color, previous_army_color, previous_army_size)  # type: ignore


def player_clean_turn(state, color):
    key = player_key(state, color)
    state.player_state[f"{key}_HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN"] = False
    state.player_state[f"{key}_HAS_ROLLED"] = False

--- catanatron_core/catanatron/__init__.py ---
"""
This is to allow an API like:

from catanatron import Game, Player, Color, Accumulator
"""
from catanatron.game import Game, GameAccumulator
from catanatron.models.player import Player, Color, RandomPlayer
from catanatron.models.enums import (
    Action,
    ActionType,
    WOOD,
    BRICK,
    SHEEP,
    WHEAT,
    ORE,
    RESOURCES,
)

--- catanatron_core/catanatron/models/actions.py ---
"""
Move-generation functions (these return a list of actions that can be taken 
by current player). Main function is generate_playable_actions.
"""
import operator as op
from functools import reduce
from typing import Any, Dict, List, Set, Tuple, Union

from catanatron.models.decks import (
    CITY_COST_FREQDECK,
    ROAD_COST_FREQDECK,
    SETTLEMENT_COST_FREQDECK,
    freqdeck_can_draw,
    freqdeck_contains,
    freqdeck_count,
    freqdeck_from_listdeck,
)
from catanatron.models.enums import (
    RESOURCES,
    Action,
    ActionPrompt,
    ActionType,
    BRICK,
    ORE,
    FastResource,
    SETTLEMENT,
    SHEEP,
    WHEAT,
    WOOD,
)
from catanatron.state_functions import (
    get_player_buildings,
    get_player_freqdeck,
    player_can_afford_dev_card,
    player_can_play_dev,
    player_has_rolled,
    player_key,
    player_num_resource_cards,
    player_resource_freqdeck_contains,
)


def generate_playable_actions(state) -> List[Action]:
    action_prompt = state.current_prompt
    color = state.current_color()

    if action_prompt == ActionPrompt.BUILD_INITIAL_SETTLEMENT:
        return settlement_possibilities(state, color, True)
    elif action_prompt == ActionPrompt.BUILD_INITIAL_ROAD:
        return initial_road_possibilities(state, color)
    elif action_prompt == ActionPrompt.MOVE_ROBBER:
        return robber_possibilities(state, color)
    elif action_prompt == ActionPrompt.PLAY_TURN:
        if state.is_road_building:
            actions = road_building_possibilities(state, color, False)
        elif not player_has_rolled(state, color):
            actions = [Action(color, ActionType.ROLL, None)]
            if player_can_play_dev(state, color, "KNIGHT"):
                actions.append(Action(color, ActionType.PLAY_KNIGHT_CARD, None))
        else:
            actions = [Action(color, ActionType.END_TURN, None)]
            actions.extend(road_building_possibilities(state, color))
            actions.extend(settlement_possibilities(state, color))
            actions.extend(city_possibilities(state, color))

            can_buy_dev_card = (
                player_can_afford_dev_card(state, color)
                and len(state.development_listdeck) > 0
            )
            if can_buy_dev_card:
                actions.append(Action(color, ActionType.BUY_DEVELOPMENT_CARD, None))

            # Play Dev Cards
            if player_can_play_dev(state, color, "YEAR_OF_PLENTY"):
                actions.extend(
                    year_of_plenty_possibilities(color, state.resource_freqdeck)
                )
            if player_can_play_dev(state, color, "MONOPOLY"):
                actions.extend(monopoly_possibilities(color))
            if player_can_play_dev(state, color, "KNIGHT"):
                actions.append(Action(color, ActionType.PLAY_KNIGHT_CARD, None))
            if (
                player_can_play_dev(state, color, "ROAD_BUILDING")
                and len(road_building_possibilities(state, color, False)) > 0
            ):
                actions.append(Action(color, ActionType.PLAY_ROAD_BUILDING, None))

            # Trade
            actions.extend(maritime_trade_possibilities(state, color))
        return actions
    elif action_prompt == ActionPrompt.DISCARD:
        return discard_possibilities(color)
    elif action_prompt == ActionPrompt.DECIDE_TRADE:
        actions = [Action(color, ActionType.REJECT_TRADE, state.current_trade)]

        # can only accept if have enough cards
        freqdeck = get_player_freqdeck(state, color)
        asked = state.current_trade[5:10]
        if freqdeck_contains(freqdeck, asked):
            actions.append(Action(color, ActionType.ACCEPT_TRADE, state.current_trade))

        return actions
    elif action_prompt == ActionPrompt.DECIDE_ACCEPTEES:
        # you should be able to accept for each of the "accepting players"
        actions = [Action(color, ActionType.CANCEL_TRADE, None)]

        for other_color, accepted in zip(state.colors, state.acceptees):
            if accepted:
                actions.append(
                    Action(
                        color,
                        ActionType.CONFIRM_TRADE,
                        (*state.current_trade[:10], other_color),
                    )
                )
        return actions
    else:
        raise RuntimeError("Unknown ActionPrompt: " + str(action_prompt))


def monopoly_possibilities(color) -> List[Action]:
    return [Action(color, ActionType.PLAY_MONOPOLY, card) for card in RESOURCES]


def year_of_plenty_possibilities(color, freqdeck: List[int]) -> List[Action]:
    options: Set[Union[Tuple[FastResource, FastResource], Tuple[FastResource]]] = set()
    for i, first_card in enumerate(RESOURCES):
        for j in range(i, len(RESOURCES)):
            second_card = RESOURCES[j]  # doing it this way to not repeat

            to_draw = freqdeck_from_listdeck([first_card, second_card])
            if freqdeck_contains(freqdeck, to_draw):
                options.add((first_card, second_card))
            else:  # try allowing player select 1 card only.
                if freqdeck_can_draw(freqdeck, 1, first_card):
                    options.add((first_card,))
                if freqdeck_can_draw(freqdeck, 1, second_card):
                    options.add((second_card,))

    return list(
        map(
            lambda cards: Action(color, ActionType.PLAY_YEAR_OF_PLENTY, tuple(cards)),
            options,
        )
    )


def road_building_possibilities(state, color, check_money=True) -> List[Action]:
    key = player_key(state, color)

    # Check if can't build any more roads.
    has_roads_available = state.player_state[f"{key}_ROADS_AVAILABLE"] > 0
    if not has_roads_available:
        return []

    # Check if need to pay for roads but can't afford them.
    has_money = player_resource_freqdeck_contains(state, color, ROAD_COST_FREQDECK)
    if check_money and not has_money:
        return []

    buildable_edges = state.board.buildable_edges(color)
    return [Action(color, ActionType.BUILD_ROAD, edge) for edge in buildable_edges]


def settlement_possibilities(state, color, initial_build_phase=False) -> List[Action]:
    if initial_build_phase:
        buildable_node_ids = state.board.buildable_node_ids(
            color, initial_build_phase=True
        )
        return [
            Action(color, ActionType.BUILD_SETTLEMENT, node_id)
            for node_id in buildable_node_ids
        ]
    else:
        key = player_key(state, color)
        has_money = player_resource_freqdeck_contains(
            state, color, SETTLEMENT_COST_FREQDECK
        )
        has_settlements_available = (
            state.player_state[f"{key}_SETTLEMENTS_AVAILABLE"] > 0
        )
        if has_money and has_settlements_available:
            buildable_node_ids = state.board.buildable_node_ids(color)
            return [
                Action(color, ActionType.BUILD_SETTLEMENT, node_id)
                for node_id in buildable_node_ids
            ]
        else:
            return []


def city_possibilities(state, color) -> List[Action]:
    key = player_key(state, color)

    can_buy_city = player_resource_freqdeck_contains(state, color, CITY_COST_FREQDECK)
    if not can_buy_city:
        return []

    has_cities_available = state.player_state[f"{key}_CITIES_AVAILABLE"] > 0
    if not has_cities_available:
        return []

    return [
        Action(color, ActionType.BUILD_CITY, node_id)
        for node_id in get_player_buildings(state, color, SETTLEMENT)
    ]


def robber_possibilities(state, color) -> List[Action]:
    actions = []
    for coordinate, tile in state.board.map.land_tiles.items():
        if coordinate == state.board.robber_coordinate:
            continue  # ignore. must move robber.

        # each tile can yield a (move-but-cant-steal) action or
        #   several (move-and-steal-from-x) actions.
        to_steal_from = set()  # set of player_indexs
        for node_id in tile.nodes.values():
            building = state.board.buildings.get(node_id, None)
            if building is not None:
                candidate_color = building[0]
                if (
                    player_num_resource_cards(state, candidate_color) >= 1
                    and color != candidate_color  # can't play yourself
                ):
                    to_steal_from.add(candidate_color)

        if len(to_steal_from) == 0:
            actions.append(
                Action(color, ActionType.MOVE_ROBBER, (coordinate, None, None))
            )
        else:
            for enemy_color in to_steal_from:
                actions.append(
                    Action(
                        color, ActionType.MOVE_ROBBER, (coordinate, enemy_color, None)
                    )
                )

    return actions


def initial_road_possibilities(state, color) -> List[Action]:
    # Must be connected to last settlement
    last_settlement_node_id = state.buildings_by_color[color][SETTLEMENT][-1]

    buildable_edges = filter(
        lambda edge: last_settlement_node_id in edge,
        state.board.buildable_edges(color),
    )
    return [Action(color, ActionType.BUILD_ROAD, edge) for edge in buildable_edges]


def discard_possibilities(color) -> List[Action]:
    return [Action(color, ActionType.DISCARD, None)]
    # TODO: Be robust to high dimensionality of DISCARD
    # hand = player.resource_deck.to_array()
    # num_cards = player.resource_deck.num_cards()
    # num_to_discard = num_cards // 2

    # num_possibilities = ncr(num_cards, num_to_discard)
    # if num_possibilities > 100:  # if too many, just take first N
    #     return [Action(player, ActionType.DISCARD, hand[:num_to_discard])]

    # to_discard = itertools.combinations(hand, num_to_discard)
    # return list(
    #     map(
    #         lambda combination: Action(player, ActionType.DISCARD, combination),
    #         to_discard,
    #     )
    # )


def ncr(n, r):
    """n choose r. helper for discard_possibilities"""
    r = min(r, n - r)
    numer = reduce(op.mul, range(n, n - r, -1), 1)
    denom = reduce(op.mul, range(1, r + 1), 1)
    return numer // denom


def maritime_trade_possibilities(state, color) -> List[Action]:
    hand_freqdeck = [
        player_num_resource_cards(state, color, resource) for resource in RESOURCES
    ]
    port_resources = state.board.get_player_port_resources(color)
    trade_offers = inner_maritime_trade_possibilities(
        hand_freqdeck, state.resource_freqdeck, port_resources
    )

    return list(
        map(lambda t: Action(color, ActionType.MARITIME_TRADE, t), trade_offers)
    )


def inner_maritime_trade_possibilities(hand_freqdeck, bank_freqdeck, port_resources):
    """This inner function is to make this logic more shareable"""
    trade_offers = set()

    # Get lowest rate per resource
    rates: Dict[FastResource, int] = {WOOD: 4, BRICK: 4, SHEEP: 4, WHEAT: 4, ORE: 4}
    if None in port_resources:
        rates = {WOOD: 3, BRICK: 3, SHEEP: 3, WHEAT: 3, ORE: 3}
    for resource in port_resources:
        if resource != None:
            rates[resource] = 2

    # For resource in hand
    for index, resource in enumerate(RESOURCES):
        amount = hand_freqdeck[index]
        if amount >= rates[resource]:
            resource_out: List[Any] = [resource] * rates[resource]
            resource_out += [None] * (4 - rates[resource])
            for j_resource in RESOURCES:
                if (
                    resource != j_resource
                    and freqdeck_count(bank_freqdeck, j_resource) > 0
                ):
                    trade_offer = tuple(resource_out + [j_resource])
                    trade_offers.add(trade_offer)

    return trade_offers

--- catanatron_core/catanatron/models/board.py ---
import pickle
import copy
from collections import defaultdict
from typing import Any, Set, Dict, Tuple, List
import functools

import networkx as nx  # type: ignore

from catanatron.models.player import Color
from catanatron.models.map import (
    BASE_MAP_TEMPLATE,
    MINI_MAP_TEMPLATE,
    NUM_NODES,
    CatanMap,
    NodeId,
)
from catanatron.models.enums import FastBuildingType, SETTLEMENT, CITY


# Used to find relationships between nodes and edges
base_map = CatanMap.from_template(BASE_MAP_TEMPLATE)
mini_map = CatanMap.from_template(MINI_MAP_TEMPLATE)
STATIC_GRAPH = nx.Graph()
for tile in base_map.tiles.values():
    STATIC_GRAPH.add_nodes_from(tile.nodes.values())
    STATIC_GRAPH.add_edges_from(tile.edges.values())


@functools.lru_cache(1)
def get_node_distances():
    return nx.floyd_warshall(STATIC_GRAPH)


@functools.lru_cache(3)  # None, range(54), range(24)
def get_edges(land_nodes=None):
    return list(STATIC_GRAPH.subgraph(land_nodes or range(NUM_NODES)).edges())


class Board:
    """Encapsulates all state information regarding the board.

    Attributes:
        buildings (Dict[NodeId, Tuple[Color, FastBuildingType]]): Mapping from
            node id to building (if there is a building there).
        roads (Dict[EdgeId, Color]): Mapping from edge
            to Color (if there is a road there). Contains inverted
            edges as well for ease of querying.
        connected_components (Dict[Color, List[Set[NodeId]]]): Cache
            datastructure to speed up maintaining longest road computation.
            To be queried by Color. Value is a list of node sets.
        board_buildable_ids (Set[NodeId]): Cache of buildable node ids in board.
        road_color (Color): Color of player with longest road.
        road_length (int): Number of roads of longest road
        robber_coordinate (Coordinate): Coordinate where robber is.
    """

    def __init__(self, catan_map=None, initialize=True):
        self.buildable_subgraph: Any = None
        self.buildable_edges_cache = {}
        self.player_port_resources_cache = {}
        if initialize:
            self.map: CatanMap = catan_map or CatanMap.from_template(
                BASE_MAP_TEMPLATE
            )  # Static State (no need to copy)

            self.buildings: Dict[NodeId, Tuple[Color, FastBuildingType]] = dict()
            self.roads = dict()  # (node_id, node_id) => color

            # color => int{}[] (list of node_id sets) one per component
            #   nodes in sets are incidental (might not be owned by player)
            self.connected_components: Any = defaultdict(list)
            self.board_buildable_ids = set(self.map.land_nodes)
            self.road_lengths = defaultdict(int)
            self.road_color = None
            self.road_length = 0

            # assumes there is at least one desert:
            self.robber_coordinate = filter(
                lambda coordinate: self.map.land_tiles[coordinate].resource is None,
                self.map.land_tiles.keys(),
            ).__next__()

            # Cache buildable subgraph
            self.buildable_subgraph = STATIC_GRAPH.subgraph(self.map.land_nodes)

    def build_settlement(self, color, node_id, initial_build_phase=False):
        """Adds a settlement, and ensures is a valid place to build.

        Args:
            color (Color): player's color
            node_id (int): where to build
            initial_build_phase (bool, optional):
                Whether this is part of initial building phase, so as to skip
                connectedness validation. Defaults to True.
        """
        buildable = self.buildable_node_ids(
            color, initial_build_phase=initial_build_phase
        )
        if node_id not in buildable:
            raise ValueError(
                "Invalid Settlement Placement: not connected and not initial-placement"
            )

        if node_id in self.buildings:
            raise ValueError("Invalid Settlement Placement: a building exists there")

        self.buildings[node_id] = (color, SETTLEMENT)

        previous_road_color = self.road_color
        if initial_build_phase:
            self.connected_components[color].append({node_id})
        else:
            # Maybe cut connected components.
            edges_by_color = defaultdict(list)
            for edge in STATIC_GRAPH.edges(node_id):
                edges_by_color[self.roads.get(edge, None)].append(edge)

            for edge_color, edges in edges_by_color.items():
                if edge_color == color or edge_color is None:
                    continue  # ignore
                if len(edges) == 2:  # rip, edge_color has been plowed
                    # consider cut was at b=node_id for edges (a, b) and (b, c)
                    a = [n for n in edges[0] if n != node_id].pop()
                    c = [n for n in edges[1] if n != node_id].pop()

                    # do dfs from a adding all encountered nodes
                    a_nodeset = self.dfs_walk(a, edge_color)
                    c_nodeset = self.dfs_walk(c, edge_color)

                    # split this components on here.
                    b_index = self._get_connected_component_index(node_id, edge_color)
                    del self.connected_components[edge_color][b_index]
                    self.connected_components[edge_color].append(a_nodeset)
                    self.connected_components[edge_color].append(c_nodeset)

                    # Update longest road by plowed player. Compare again with all
                    self.road_lengths[edge_color] = max(
                        *[
                            len(longest_acyclic_path(self, component, edge_color))
                            for component in self.connected_components[edge_color]
                        ]
                    )
                    self.road_color, self.road_length = max(
                        self.road_lengths.items(), key=lambda e: e[1]
                    )

        self.board_buildable_ids.discard(node_id)
        for n in STATIC_GRAPH.neighbors(node_id):
            self.board_buildable_ids.discard(n)

        self.buildable_edges_cache = {}  # Reset buildable_edges
        self.player_port_resources_cache = {}  # Reset port resources
        return previous_road_color, self.road_color, self.road_lengths

    def dfs_walk(self, node_id, color):
        """Generates set of nodes that are "connected" to given node.

        Args:
            node_id (int): Where to start search/walk.
            color (Color): Player color asking

        Returns:
            Set[int]: Nodes that are "connected" to this one
                by roads of the color player.
        """
        agenda = [node_id]  # assuming node_id is owned.
        visited = set()

        while len(agenda) != 0:
            n = agenda.pop()
            visited.add(n)

            if self.is_enemy_node(n, color):
                continue  # end of the road

            neighbors = [v for v in STATIC_GRAPH.neighbors(n) if v not in visited]
            expandable = [v for v in neighbors if self.roads.get((n, v), None) == color]
            agenda.extend(expandable)

        return visited

    def _get_connected_component_index(self, node_id, color):
        for i, component in enumerate(self.connected_components[color]):
            if node_id in component:
                return i

    def build_road(self, color, edge):
        buildable = self.buildable_edges(color)
        inverted_edge = (edge[1], edge[0])
        if edge not in buildable and inverted_edge not in buildable:
            raise ValueError("Invalid Road Placement")

        self.roads[edge] = color
        self.roads[inverted_edge] = color

        # Find connected components corresponding to edge nodes (buildings).
        a, b = edge
        a_index = self._get_connected_component_index(a, color)
        b_index = self._get_connected_component_index(b, color)

        # Extend or merge components
        if a_index is None and not self.is_enemy_node(a, color):
            component = self.connected_components[color][b_index]
            component.add(a)
        elif b_index is None and not self.is_enemy_node(b, color):
            component = self.connected_components[color][a_index]
            component.add(b)
        elif a_index is not None and b_index is not None and a_index != b_index:
            # Merge both components into one and delete the other.
            component = set.union(
                self.connected_components[color][a_index],
                self.connected_components[color][b_index],
            )
            self.connected_components[color][a_index] = component
            del self.connected_components[color][b_index]
        else:
            # In this case, a_index == b_index, which means that the edge
            # is already part of one component. No actions needed.
            chosen_index = a_index if a_index is not None else b_index
            component = self.connected_components[color][chosen_index]

        # find longest path on component under question
        previous_road_color = self.road_color
        candidate_length = len(longest_acyclic_path(self, component, color))
        self.road_lengths[color] = max(self.road_lengths[color], candidate_length)
        if candidate_length >= 5 and candidate_length > self.road_length:
            self.road_color = color
            self.road_length = candidate_length

        self.buildable_edges_cache = {}  # Reset buildable_edges
        return previous_road_color, self.road_color, self.road_lengths

    def build_city(self, color, node_id):
        building = self.buildings.get(node_id, None)
        if building is None or building[0] != color or building[1] != SETTLEMENT:
            raise ValueError("Invalid City Placement: no player settlement there")

        self.buildings[node_id] = (color, CITY)

    def buildable_node_ids(self, color: Color, initial_build_phase=False):
        if initial_build_phase:
            return sorted(list(self.board_buildable_ids))

        subgraphs = self.find_connected_components(color)
        nodes = set().union(*subgraphs)
        return sorted(list(nodes.intersection(self.board_buildable_ids)))

    def buildable_edges(self, color: Color):
        """List of (n1,n2) tuples. Edges are in n1 < n2 order."""
        if color in self.buildable_edges_cache:
            return self.buildable_edges_cache[color]

        expandable = set()

        # All nodes for this color.
        # TODO(tonypr): Explore caching for 'expandable_nodes'?
        # The 'expandable_nodes' set should only increase in size monotonically I think.
        # We can take advantage of that.
        expandable_nodes = set()
        expandable_nodes = expandable_nodes.union(*self.connected_components[color])

        candidate_edges = self.buildable_subgraph.edges(expandable_nodes)
        for edge in candidate_edges:
            if self.get_edge_color(edge) is None:
                expandable.add(tuple(sorted(edge)))

        self.buildable_edges_cache[color] = list(expandable)
        return self.buildable_edges_cache[color]

    def get_player_port_resources(self, color):
        """Yields resources (None for 3:1) of ports owned by color"""
        if color in self.player_port_resources_cache:
            return self.player_port_resources_cache[color]

        resources = set()
        for resource, node_ids in self.map.port_nodes.items():
            if any(self.is_friendly_node(node_id, color) for node_id in node_ids):
                resources.add(resource)

        self.player_port_resources_cache[color] = resources
        return resources

    def find_connected_components(self, color: Color):
        """
        Returns:
            nx.Graph[]: connected subgraphs. subgraphs
                might include nodes that color doesnt own (on the way and on ends),
                just to make it is "closed" and easier for buildable_nodes to operate.
        """
        return self.connected_components[color]

    def continuous_roads_by_player(self, color: Color):
        paths = []
        components = self.find_connected_components(color)
        for component in components:
            paths.append(longest_acyclic_path(self, component, color))
        return paths

    def copy(self):
        board = Board(self.map, initialize=False)
        board.map = self.map  # reuse since its immutable
        board.buildings = self.buildings.copy()
        board.roads = self.roads.copy()
        board.connected_components = pickle.loads(
            pickle.dumps(self.connected_components)
        )
        board.board_buildable_ids = self.board_buildable_ids.copy()
        board.road_lengths = self.road_lengths.copy()
        board.road_color = self.road_color
        board.road_length = self.road_length

        board.robber_coordinate = self.robber_coordinate
        board.buildable_subgraph = self.buildable_subgraph
        board.buildable_edges_cache = copy.deepcopy(self.buildable_edges_cache)
        board.player_port_resources_cache = copy.deepcopy(
            self.player_port_resources_cache
        )
        return board

    # ===== Helper functions
    def get_node_color(self, node_id):
        # using try-except instead of .get for performance
        try:
            return self.buildings[node_id][0]
        except KeyError:
            return None

    def get_edge_color(self, edge):
        # using try-except instead of .get for performance
        try:
            return self.roads[edge]
        except KeyError:
            return None

    def is_enemy_node(self, node_id, color):
        node_color = self.get_node_color(node_id)
        return node_color is not None and node_color != color

    def is_enemy_road(self, edge, color):
        edge_color = self.get_edge_color(edge)
        return edge_color is not None and self.get_edge_color(edge) != color

    def is_friendly_node(self, node_id, color):
        return self.get_node_color(node_id) == color

    def is_friendly_road(self, edge, color):
        return self.get_edge_color(edge) == color


def longest_acyclic_path(board: Board, node_set: Set[int], color: Color):
    paths = []
    for start_node in node_set:
        # do DFS when reach leaf node, stop and add to paths
        paths_from_this_node = []
        agenda: List[Tuple[int, Any]] = [(start_node, [])]
        while len(agenda) > 0:
            node, path_thus_far = agenda.pop()

            able_to_navigate = False
            for neighbor_node in STATIC_GRAPH.neighbors(node):
                edge = tuple(sorted((node, neighbor_node)))

                # Must travel on a friendly road.
                if not board.is_friendly_road(edge, color):
                    continue

                # Can't expand past an enemy node.
                if board.is_enemy_node(neighbor_node, color):
                    continue

                if edge not in path_thus_far:
                    agenda.append((neighbor_node, path_thus_far + [edge]))
                    able_to_navigate = True

            if not able_to_navigate:  # then it is leaf node
                paths_from_this_node.append(path_thus_far)

        paths.extend(paths_from_this_node)

    return max(paths, key=len)

--- catanatron_core/catanatron/models/coordinate_system.py ---
from enum import Enum


# We'll be using Cube coordinates in https://math.stackexchange.com/questions/2254655/hexagon-grid-coordinate-system
class Direction(Enum):
    EAST = "EAST"
    SOUTHEAST = "SOUTHEAST"
    SOUTHWEST = "SOUTHWEST"
    WEST = "WEST"
    NORTHWEST = "NORTHWEST"
    NORTHEAST = "NORTHEAST"


UNIT_VECTORS = {
    # X-axis
    Direction.NORTHEAST: (1, 0, -1),
    Direction.SOUTHWEST: (-1, 0, 1),
    # Y-axis
    Direction.NORTHWEST: (0, 1, -1),
    Direction.SOUTHEAST: (0, -1, 1),
    # Z-axis
    Direction.EAST: (1, -1, 0),
    Direction.WEST: (-1, 1, 0),
}


def add(acoord, bcoord):
    (x, y, z) = acoord
    (u, v, w) = bcoord
    return (x + u, y + v, z + w)


def num_tiles_for(layer):
    """Including inner-layer tiles"""
    if layer == 0:
        return 1

    return 6 * layer + num_tiles_for(layer - 1)


def generate_coordinate_system(num_layers):
    """
    Generates a set of coordinates by expanding outward from a center tile on
    (0,0,0) with the given number of layers (as in an onion :)). Follows BFS.
    """
    num_tiles = num_tiles_for(num_layers)

    agenda = [(0, 0, 0)]
    visited = set()
    while len(visited) < num_tiles:
        node = agenda.pop(0)
        visited.add(node)

        neighbors = [add(node, UNIT_VECTORS[d]) for d in Direction]
        new_neighbors = filter(
            lambda x: x not in visited and x not in agenda, neighbors
        )
        agenda.extend(new_neighbors)
    return visited


def cube_to_axial(cube):
    q = cube[0]
    r = cube[2]
    return (q, r)


def cube_to_offset(cube):
    col = cube[0] + (cube[2] - (cube[2] & 1)) / 2
    row = cube[2]
    return (col, row)


def offset_to_cube(offset):
    x = offset[0] - (offset[1] - (offset[1] & 1)) / 2
    z = offset[1]
    y = -x - z
    return (x, y, z)

--- catanatron_core/catanatron/models/decks.py ---
"""Providers helper functions to deal with representations of decks of cards

We use a histogram / 'frequency list' to represent decks (aliased 'freqdeck').
This representation is concise, easy to copy, access and fast to compare.
"""
from typing import Iterable, List

from catanatron.models.enums import (
    KNIGHT,
    MONOPOLY,
    ROAD_BUILDING,
    VICTORY_POINT,
    YEAR_OF_PLENTY,
    WOOD,
    BRICK,
    SHEEP,
    WHEAT,
    ORE,
    FastDevCard,
    FastResource,
)


ROAD_COST_FREQDECK = [1, 1, 0, 0, 0]
SETTLEMENT_COST_FREQDECK = [1, 1, 1, 1, 0]
CITY_COST_FREQDECK = [0, 0, 0, 2, 3]
DEVELOPMENT_CARD_COST_FREQDECK = [0, 0, 1, 1, 1]


# ===== ListDecks
def starting_resource_bank():
    """Returns freqdeck of resource cards"""
    return [19, 19, 19, 19, 19]


RESOURCE_FREQDECK_INDEXES = {WOOD: 0, BRICK: 1, SHEEP: 2, WHEAT: 3, ORE: 4}


def freqdeck_can_draw(freqdeck, amount: int, card: FastResource):
    return freqdeck[RESOURCE_FREQDECK_INDEXES[card]] >= amount


def freqdeck_draw(freqdeck, amount: int, card: FastResource):
    freqdeck[RESOURCE_FREQDECK_INDEXES[card]] -= amount


def freqdeck_replenish(freqdeck, amount: int, card: FastResource):
    freqdeck[RESOURCE_FREQDECK_INDEXES[card]] += amount


def freqdeck_count(freqdeck, card: FastResource):
    return freqdeck[RESOURCE_FREQDECK_INDEXES[card]]


def freqdeck_from_listdeck(listdeck: Iterable[FastResource]):
    freqdeck = [0, 0, 0, 0, 0]
    for resource in listdeck:
        freqdeck_replenish(freqdeck, 1, resource)
    return freqdeck


def starting_devcard_proba(card: FastDevCard):
    starting_deck = starting_devcard_bank()
    return starting_deck.count(card) / len(starting_deck)


def starting_devcard_bank():
    """Returns listdeck of devcards"""
    return (
        [KNIGHT] * 14
        + [YEAR_OF_PLENTY] * 2
        + [ROAD_BUILDING] * 2
        + [MONOPOLY] * 2
        + [VICTORY_POINT] * 5
    )


def draw_from_listdeck(list1: List, amount: int, card: int):
    i = 0
    while i < amount:
        index = list1.index(card)
        del list1[index]
        i += 1


def freqdeck_add(list1, list2):
    return [a + b for a, b in zip(list1, list2)]


def freqdeck_subtract(list1, list2):
    return [a - b for a, b in zip(list1, list2)]


def freqdeck_contains(list1, list2):
    """True if list1 >= list2 element-wise"""
    return all([a >= b for a, b in zip(list1, list2)])

--- catanatron_core/catanatron/models/enums.py ---
from enum import Enum
from collections import namedtuple
from typing import List, Literal, Final


FastResource = Literal["WOOD", "BRICK", "SHEEP", "WHEAT", "ORE"]
FastDevCard = Literal[
    "KNIGHT", "YEAR_OF_PLENTY", "MONOPOLY", "ROAD_BUILDING", "VICTORY_POINT"
]
FastBuildingType = Literal["SETTLEMENT", "CITY", "ROAD"]

# Strings are considerably faster than Python Enum's (e.g. at being hashed).
# TODO: Move to ints
WOOD: Final = "WOOD"
BRICK: Final = "BRICK"
SHEEP: Final = "SHEEP"
WHEAT: Final = "WHEAT"
ORE: Final = "ORE"
RESOURCES: List[FastResource] = [WOOD, BRICK, SHEEP, WHEAT, ORE]

KNIGHT: Final = "KNIGHT"
YEAR_OF_PLENTY: Final = "YEAR_OF_PLENTY"
MONOPOLY: Final = "MONOPOLY"
ROAD_BUILDING: Final = "ROAD_BUILDING"
VICTORY_POINT: Final = "VICTORY_POINT"
DEVELOPMENT_CARDS: List[FastDevCard] = [
    KNIGHT,
    YEAR_OF_PLENTY,
    MONOPOLY,
    ROAD_BUILDING,
    VICTORY_POINT,
]

SETTLEMENT: Final = "SETTLEMENT"
CITY: Final = "CITY"
ROAD: Final = "ROAD"


# Given a tile, the reference to the node.
class NodeRef(Enum):
    NORTH = "NORTH"
    NORTHEAST = "NORTHEAST"
    SOUTHEAST = "SOUTHEAST"
    SOUTH = "SOUTH"
    SOUTHWEST = "SOUTHWEST"
    NORTHWEST = "NORTHWEST"


# References an edge from a tile.
class EdgeRef(Enum):
    EAST = "EAST"
    SOUTHEAST = "SOUTHEAST"
    SOUTHWEST = "SOUTHWEST"
    WEST = "WEST"
    NORTHWEST = "NORTHWEST"
    NORTHEAST = "NORTHEAST"


class ActionPrompt(Enum):
    BUILD_INITIAL_SETTLEMENT = "BUILD_INITIAL_SETTLEMENT"
    BUILD_INITIAL_ROAD = "BUILD_INITIAL_ROAD"
    PLAY_TURN = "PLAY_TURN"
    DISCARD = "DISCARD"
    MOVE_ROBBER = "MOVE_ROBBER"
    DECIDE_TRADE = "DECIDE_TRADE"
    DECIDE_ACCEPTEES = "DECIDE_ACCEPTEES"


class ActionType(Enum):
    """Type of action taken by a player.

    See comments next to each ActionType for the shape of the corresponding
    .value field in Actions of that type.
    """

    ROLL = "ROLL"  # value is None. Log instead sets it to (int, int) rolled.
    MOVE_ROBBER = "MOVE_ROBBER"  # value is (coordinate, Color|None). Log has extra element of card stolen.
    DISCARD = "DISCARD"  # value is None|Resource[]. TODO: Should always be Resource[].

    # Building/Buying
    BUILD_ROAD = "BUILD_ROAD"  # value is edge_id
    BUILD_SETTLEMENT = "BUILD_SETTLEMENT"  # value is node_id
    BUILD_CITY = "BUILD_CITY"  # value is node_id
    BUY_DEVELOPMENT_CARD = "BUY_DEVELOPMENT_CARD"  # value is None. Log value is card

    # Dev Card Plays
    PLAY_KNIGHT_CARD = "PLAY_KNIGHT_CARD"  # value is None
    PLAY_YEAR_OF_PLENTY = "PLAY_YEAR_OF_PLENTY"  # value is (Resource, Resource)
    PLAY_MONOPOLY = "PLAY_MONOPOLY"  # value is Resource
    PLAY_ROAD_BUILDING = "PLAY_ROAD_BUILDING"  # value is None

    # ===== Trade
    # MARITIME_TRADE value is 5-resouce tuple, where last resource is resource asked.
    #   resources in index 2 and 3 might be None, denoting a port-trade.
    MARITIME_TRADE = "MARITIME_TRADE"
    # Domestic Trade (player to player trade)
    # Values for all three is a 10-resource tuple, first 5 is offered freqdeck, last 5 is
    #   receiving freqdeck.
    OFFER_TRADE = "OFFER_TRADE"
    ACCEPT_TRADE = "ACCEPT_TRADE"
    REJECT_TRADE = "REJECT_TRADE"
    # CONFIRM_TRADE value is 11-tuple. first 10 as in OFFER_TRADE, last is color of accepting player
    CONFIRM_TRADE = "CONFIRM_TRADE"
    CANCEL_TRADE = "CANCEL_TRADE"  # value is None

    END_TURN = "END_TURN"  # value is None


def __repr__(self):
    return f"ActionType.{self.value}"


# TODO: Distinguish between Action and ActionLog?
Action = namedtuple("Action", ["color", "action_type", "value"])
Action.__doc__ = """
Main class to represent action. Should be immutable.

The "value" is a polymorphic field that acts as the "parameters"
for the "action_type". e.g. where to ActionType.BUILD_SETTLEMENT
or who to steal from in a ActionType.MOVE_ROBBER action.

We use this class to represent both the _intent_ of say "moving a
robber to Tile (0,0,0) and stealing from Blue" as well as
the final result of such a move. In moves like these where the intent
is not enough to be used to reproduce the game identically,
we use "None"s in the "value" container as placeholders 
for that information needed for fully reproducing a game.
(e.g. card stolen, dev card bought, etc...)

See more on ActionType.
"""

--- catanatron_core/catanatron/models/map.py ---
import typing
from dataclasses import dataclass
import random
from collections import Counter, defaultdict
from typing import Dict, FrozenSet, List, Literal, Mapping, Set, Tuple, Type, Union

from catanatron.models.coordinate_system import Direction, add, UNIT_VECTORS
from catanatron.models.enums import (
    FastResource,
    WOOD,
    BRICK,
    SHEEP,
    WHEAT,
    ORE,
    EdgeRef,
    NodeRef,
)

NUM_NODES = 54
NUM_EDGES = 72
NUM_TILES = 19


EdgeId = Tuple[int, int]
NodeId = int
Coordinate = Tuple[int, int, int]


@dataclass
class LandTile:
    id: int
    resource: Union[FastResource, None]  # None means desert tile
    number: Union[int, None]  # None if desert
    nodes: Dict[NodeRef, NodeId]  # node_ref => node_id
    edges: Dict[EdgeRef, EdgeId]  # edge_ref => edge

    # The id is unique among the tiles, so we can use it as the hash.
    def __hash__(self):
        return self.id


@dataclass
class Port:
    id: int
    resource: Union[FastResource, None]  # None means desert tile
    direction: Direction
    nodes: Dict[NodeRef, NodeId]  # node_ref => node_id
    edges: Dict[EdgeRef, EdgeId]  # edge_ref => edge

    # The id is unique among the tiles, so we can use it as the hash.
    def __hash__(self):
        return self.id


@dataclass(frozen=True)
class Water:
    nodes: Dict[NodeRef, int]
    edges: Dict[EdgeRef, EdgeId]


Tile = Union[LandTile, Port, Water]


@dataclass(frozen=True)
class MapTemplate:
    numbers: List[int]
    port_resources: List[Union[FastResource, None]]
    tile_resources: List[Union[FastResource, None]]
    topology: Mapping[
        Coordinate, Union[Type[LandTile], Type[Water], Tuple[Type[Port], Direction]]
    ]


# Small 7-tile map, no ports.
MINI_MAP_TEMPLATE = MapTemplate(
    [3, 4, 5, 6, 8, 9, 10],
    [],
    [WOOD, None, BRICK, SHEEP, WHEAT, WHEAT, ORE],
    {
        # center
        (0, 0, 0): LandTile,
        # first layer
        (1, -1, 0): LandTile,
        (0, -1, 1): LandTile,
        (-1, 0, 1): LandTile,
        (-1, 1, 0): LandTile,
        (0, 1, -1): LandTile,
        (1, 0, -1): LandTile,
        # second layer
        (2, -2, 0): Water,
        (1, -2, 1): Water,
        (0, -2, 2): Water,
        (-1, -1, 2): Water,
        (-2, 0, 2): Water,
        (-2, 1, 1): Water,
        (-2, 2, 0): Water,
        (-1, 2, -1): Water,
        (0, 2, -2): Water,
        (1, 1, -2): Water,
        (2, 0, -2): Water,
        (2, -1, -1): Water,
    },
)

"""Standard 4-player map"""
BASE_MAP_TEMPLATE = MapTemplate(
    [2, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 9, 9, 10, 10, 11, 11, 12],
    [
        # These are 2:1 ports
        WOOD,
        BRICK,
        SHEEP,
        WHEAT,
        ORE,
        # These represet 3:1 ports
        None,
        None,
        None,
        None,
    ],
    [
        # Four wood tiles
        WOOD,
        WOOD,
        WOOD,
        WOOD,
        # Three brick tiles
        BRICK,
        BRICK,
        BRICK,
        # Four sheep tiles
        SHEEP,
        SHEEP,
        SHEEP,
        SHEEP,
        # Four wheat tiles
        WHEAT,
        WHEAT,
        WHEAT,
        WHEAT,
        # Three ore tiles
        ORE,
        ORE,
        ORE,
        # One desert
        None,
    ],
    # 3 layers, where last layer is water
    {
        # center
        (0, 0, 0): LandTile,
        # first layer
        (1, -1, 0): LandTile,
        (0, -1, 1): LandTile,
        (-1, 0, 1): LandTile,
        (-1, 1, 0): LandTile,
        (0, 1, -1): LandTile,
        (1, 0, -1): LandTile,
        # second layer
        (2, -2, 0): LandTile,
        (1, -2, 1): LandTile,
        (0, -2, 2): LandTile,
        (-1, -1, 2): LandTile,
        (-2, 0, 2): LandTile,
        (-2, 1, 1): LandTile,
        (-2, 2, 0): LandTile,
        (-1, 2, -1): LandTile,
        (0, 2, -2): LandTile,
        (1, 1, -2): LandTile,
        (2, 0, -2): LandTile,
        (2, -1, -1): LandTile,
        # third (water) layer
        (3, -3, 0): (Port, Direction.WEST),
        (2, -3, 1): Water,
        (1, -3, 2): (Port, Direction.NORTHWEST),
        (0, -3, 3): Water,
        (-1, -2, 3): (Port, Direction.NORTHWEST),
        (-2, -1, 3): Water,
        (-3, 0, 3): (Port, Direction.NORTHEAST),
        (-3, 1, 2): Water,
        (-3, 2, 1): (Port, Direction.EAST),
        (-3, 3, 0): Water,
        (-2, 3, -1): (Port, Direction.EAST),
        (-1, 3, -2): Water,
        (0, 3, -3): (Port, Direction.SOUTHEAST),
        (1, 2, -3): Water,
        (2, 1, -3): (Port, Direction.SOUTHWEST),
        (3, 0, -3): Water,
        (3, -1, -2): (Port, Direction.SOUTHWEST),
        (3, -2, -1): Water,
    },
)


class CatanMap:
    """Represents a randomly initialized map."""

    def __init__(
        self,
        tiles: Dict[Coordinate, Tile] = dict(),
        land_tiles: Dict[Coordinate, LandTile] = dict(),
        port_nodes: Dict[Union[FastResource, None], Set[int]] = dict(),
        land_nodes: FrozenSet[NodeId] = frozenset(),
        adjacent_tiles: Dict[int, List[LandTile]] = dict(),
        node_production: Dict[NodeId, Counter] = dict(),
        tiles_by_id: Dict[int, LandTile] = dict(),
        ports_by_id: Dict[int, Port] = dict(),
    ):
        self.tiles = tiles
        self.land_tiles = land_tiles
        self.port_nodes = port_nodes
        self.land_nodes = land_nodes
        self.adjacent_tiles = adjacent_tiles
        self.node_production = node_production
        self.tiles_by_id = tiles_by_id
        self.ports_by_id = ports_by_id

    @staticmethod
    def from_template(map_template: MapTemplate):
        tiles = initialize_tiles(map_template)

        return CatanMap.from_tiles(tiles)

    @staticmethod
    def from_tiles(tiles: Dict[Coordinate, Tile]):
        self = CatanMap()
        self.tiles = tiles

        self.land_tiles = {
            k: v for k, v in self.tiles.items() if isinstance(v, LandTile)
        }

        # initialize auxiliary data structures for fast-lookups
        self.port_nodes = init_port_nodes_cache(self.tiles)

        land_nodes_list = map(lambda t: set(t.nodes.values()), self.land_tiles.values())
        self.land_nodes = frozenset().union(*land_nodes_list)

        # TODO: Rename to self.node_to_tiles
        self.adjacent_tiles = init_adjacent_tiles(self.land_tiles)
        self.node_production = init_node_production(self.adjacent_tiles)
        self.tiles_by_id = {
            t.id: t for t in self.tiles.values() if isinstance(t, LandTile)
        }
        self.ports_by_id = {p.id: p for p in self.tiles.values() if isinstance(p, Port)}

        return self


def init_port_nodes_cache(
    tiles: Dict[Coordinate, Tile]
) -> Dict[Union[FastResource, None], Set[int]]:
    """Initializes board.port_nodes cache.

    Args:
        tiles (Dict[Coordinate, Tile]): initialized tiles datastructure

    Returns:
        Dict[Union[FastResource, None], Set[int]]: Mapping from FastResource to node_ids that
            enable port trading. None key represents 3:1 port.
    """
    port_nodes = defaultdict(set)
    for tile in tiles.values():
        if not isinstance(tile, Port):
            continue

        (a_noderef, b_noderef) = PORT_DIRECTION_TO_NODEREFS[tile.direction]
        port_nodes[tile.resource].add(tile.nodes[a_noderef])
        port_nodes[tile.resource].add(tile.nodes[b_noderef])
    return port_nodes


def init_adjacent_tiles(
    land_tiles: Dict[Coordinate, LandTile]
) -> Dict[int, List[LandTile]]:
    adjacent_tiles = defaultdict(list)  # node_id => tile[3]
    for tile in land_tiles.values():
        for node_id in tile.nodes.values():
            adjacent_tiles[node_id].append(tile)
    return adjacent_tiles


def init_node_production(
    adjacent_tiles: Dict[int, List[LandTile]]
) -> Dict[NodeId, Counter]:
    """Returns node_id => Counter({WHEAT: 0.123, ...})"""
    node_production = dict()
    for node_id in adjacent_tiles.keys():
        node_production[node_id] = get_node_counter_production(adjacent_tiles, node_id)
    return node_production


def get_node_counter_production(
    adjacent_tiles: Dict[int, List[LandTile]], node_id: NodeId
):
    tiles = adjacent_tiles[node_id]
    production = defaultdict(float)
    for tile in tiles:
        if tile.resource is not None:
            production[tile.resource] += number_probability(tile.number)
    return Counter(production)


def build_dice_probas():
    probas = defaultdict(float)
    for i in range(1, 7):
        for j in range(1, 7):
            probas[i + j] += 1 / 36
    return probas


DICE_PROBAS = build_dice_probas()


def number_probability(number):
    return DICE_PROBAS[number]


def initialize_tiles(
    map_template: MapTemplate,
    shuffled_numbers_param=None,
    shuffled_port_resources_param=None,
    shuffled_tile_resources_param=None,
) -> Dict[Coordinate, Tile]:
    """Initializes a new random board, based on the MapTemplate.

    It first shuffles tiles, ports, and numbers. Then goes satisfying the
    topology (i.e. placing tiles on coordinates); ensuring to "attach" these to
    neighbor tiles (so as to not repeat nodes or edges objects).

    Args:
        map_template (MapTemplate): Template to initialize.

    Raises:
        ValueError: Invalid tile in topology

    Returns:
        Dict[Coordinate, Tile]: Coordinate to initialized Tile mapping.
    """
    shuffled_port_resources = shuffled_port_resources_param or random.sample(
        map_template.port_resources, len(map_template.port_resources)
    )
    shuffled_tile_resources = shuffled_tile_resources_param or random.sample(
        map_template.tile_resources, len(map_template.tile_resources)
    )
    shuffled_numbers = shuffled_numbers_param or random.sample(
        map_template.numbers, len(map_template.numbers)
    )

    # for each topology entry, place a tile. keep track of nodes and edges
    all_tiles: Dict[Coordinate, Tile] = {}
    node_autoinc = 0
    tile_autoinc = 0
    port_autoinc = 0
    for coordinate, tile_type in map_template.topology.items():
        nodes, edges, node_autoinc = get_nodes_and_edges(
            all_tiles, coordinate, node_autoinc
        )

        # create and save tile
        if isinstance(tile_type, tuple):  # is port
            (_, direction) = tile_type
            port = Port(
                port_autoinc, shuffled_port_resources.pop(), direction, nodes, edges
            )
            all_tiles[coordinate] = port
            port_autoinc += 1
        elif tile_type == LandTile:
            resource = shuffled_tile_resources.pop()
            if resource != None:
                number = shuffled_numbers.pop()
                tile = LandTile(tile_autoinc, resource, number, nodes, edges)
            else:
                tile = LandTile(tile_autoinc, None, None, nodes, edges)  # desert
            all_tiles[coordinate] = tile
            tile_autoinc += 1
        elif tile_type == Water:
            water_tile = Water(nodes, edges)
            all_tiles[coordinate] = water_tile
        else:
            raise ValueError("Invalid tile")

    return all_tiles


def get_nodes_and_edges(tiles, coordinate: Coordinate, node_autoinc):
    """Get pre-existing nodes and edges in board for given tile coordinate"""
    nodes = {
        NodeRef.NORTH: None,
        NodeRef.NORTHEAST: None,
        NodeRef.SOUTHEAST: None,
        NodeRef.SOUTH: None,
        NodeRef.SOUTHWEST: None,
        NodeRef.NORTHWEST: None,
    }
    edges = {
        EdgeRef.EAST: None,
        EdgeRef.SOUTHEAST: None,
        EdgeRef.SOUTHWEST: None,
        EdgeRef.WEST: None,
        EdgeRef.NORTHWEST: None,
        EdgeRef.NORTHEAST: None,
    }

    # Find pre-existing ones
    neighbor_tiles = [(add(coordinate, UNIT_VECTORS[d]), d) for d in Direction]
    for coord, neighbor_direction in neighbor_tiles:
        if coord not in tiles:
            continue

        neighbor = tiles[coord]
        if neighbor_direction == Direction.EAST:
            nodes[NodeRef.NORTHEAST] = neighbor.nodes[NodeRef.NORTHWEST]
            nodes[NodeRef.SOUTHEAST] = neighbor.nodes[NodeRef.SOUTHWEST]
            edges[EdgeRef.EAST] = neighbor.edges[EdgeRef.WEST]
        elif neighbor_direction == Direction.SOUTHEAST:
            nodes[NodeRef.SOUTH] = neighbor.nodes[NodeRef.NORTHWEST]
            nodes[NodeRef.SOUTHEAST] = neighbor.nodes[NodeRef.NORTH]
            edges[EdgeRef.SOUTHEAST] = neighbor.edges[EdgeRef.NORTHWEST]
        elif neighbor_direction == Direction.SOUTHWEST:
            nodes[NodeRef.SOUTH] = neighbor.nodes[NodeRef.NORTHEAST]
            nodes[NodeRef.SOUTHWEST] = neighbor.nodes[NodeRef.NORTH]
            edges[EdgeRef.SOUTHWEST] = neighbor.edges[EdgeRef.NORTHEAST]
        elif neighbor_direction == Direction.WEST:
            nodes[NodeRef.NORTHWEST] = neighbor.nodes[NodeRef.NORTHEAST]
            nodes[NodeRef.SOUTHWEST] = neighbor.nodes[NodeRef.SOUTHEAST]
            edges[EdgeRef.WEST] = neighbor.edges[EdgeRef.EAST]
        elif neighbor_direction == Direction.NORTHWEST:
            nodes[NodeRef.NORTH] = neighbor.nodes[NodeRef.SOUTHEAST]
            nodes[NodeRef.NORTHWEST] = neighbor.nodes[NodeRef.SOUTH]
            edges[EdgeRef.NORTHWEST] = neighbor.edges[EdgeRef.SOUTHEAST]
        elif neighbor_direction == Direction.NORTHEAST:
            nodes[NodeRef.NORTH] = neighbor.nodes[NodeRef.SOUTHWEST]
            nodes[NodeRef.NORTHEAST] = neighbor.nodes[NodeRef.SOUTH]
            edges[EdgeRef.NORTHEAST] = neighbor.edges[EdgeRef.SOUTHWEST]
        else:
            raise Exception("Something went wrong")

    # Initializes new ones
    for noderef, value in nodes.items():
        if value is None:
            nodes[noderef] = node_autoinc
            node_autoinc += 1
    for edgeref, value in edges.items():
        if value is None:
            a_noderef, b_noderef = get_edge_nodes(edgeref)
            edge_nodes = (nodes[a_noderef], nodes[b_noderef])
            edges[edgeref] = edge_nodes  # type: ignore

    return (
        typing.cast(Dict[NodeRef, NodeId], nodes),
        typing.cast(Dict[EdgeRef, EdgeId], edges),
        node_autoinc,
    )


def get_edge_nodes(edge_ref):
    """returns pair of nodes at the "ends" of a given edge"""
    return {
        EdgeRef.EAST: (NodeRef.NORTHEAST, NodeRef.SOUTHEAST),
        EdgeRef.SOUTHEAST: (NodeRef.SOUTHEAST, NodeRef.SOUTH),
        EdgeRef.SOUTHWEST: (NodeRef.SOUTH, NodeRef.SOUTHWEST),
        EdgeRef.WEST: (NodeRef.SOUTHWEST, NodeRef.NORTHWEST),
        EdgeRef.NORTHWEST: (NodeRef.NORTHWEST, NodeRef.NORTH),
        EdgeRef.NORTHEAST: (NodeRef.NORTH, NodeRef.NORTHEAST),
    }[edge_ref]


# TODO: Could consolidate Direction with EdgeRef.
PORT_DIRECTION_TO_NODEREFS = {
    Direction.WEST: (NodeRef.NORTHWEST, NodeRef.SOUTHWEST),
    Direction.NORTHWEST: (NodeRef.NORTH, NodeRef.NORTHWEST),
    Direction.NORTHEAST: (NodeRef.NORTHEAST, NodeRef.NORTH),
    Direction.EAST: (NodeRef.SOUTHEAST, NodeRef.NORTHEAST),
    Direction.SOUTHEAST: (NodeRef.SOUTH, NodeRef.SOUTHEAST),
    Direction.SOUTHWEST: (NodeRef.SOUTHWEST, NodeRef.SOUTH),
}

TOURNAMENT_MAP_TILES = initialize_tiles(
    BASE_MAP_TEMPLATE,
    [10, 8, 3, 6, 2, 5, 10, 8, 4, 11, 12, 9, 5, 4, 9, 11, 3, 6],
    [
        None,
        SHEEP,
        None,
        ORE,
        WHEAT,
        None,
        WOOD,
        BRICK,
        None,
    ],
    [
        None,
        WOOD,
        SHEEP,
        SHEEP,
        WOOD,
        WHEAT,
        WOOD,
        WHEAT,
        BRICK,
        SHEEP,
        BRICK,
        SHEEP,
        WHEAT,
        WHEAT,
        ORE,
        BRICK,
        ORE,
        WOOD,
        ORE,
        None,
    ],
)
TOURNAMENT_MAP = CatanMap.from_tiles(TOURNAMENT_MAP_TILES)


def build_map(map_type: Literal["BASE", "TOURNAMENT", "MINI"]):
    if map_type == "TOURNAMENT":
        return TOURNAMENT_MAP  # this assumes map is read-only data struct
    elif map_type == "MINI":
        return CatanMap.from_template(MINI_MAP_TEMPLATE)
    else:
        return CatanMap.from_template(BASE_MAP_TEMPLATE)

--- catanatron_core/catanatron/models/player.py ---
import random
from enum import Enum


class Color(Enum):
    """Enum to represent the colors in the game"""

    RED = "RED"
    BLUE = "BLUE"
    ORANGE = "ORANGE"
    WHITE = "WHITE"


class Player:
    """Interface to represent a player's decision logic.

    Formulated as a class (instead of a function) so that players
    can have an initialization that can later be serialized to
    the database via pickle.
    """

    def __init__(self, color, is_bot=True):
        """Initialize the player

        Args:
            color(Color): the color of the player
            is_bot(bool): whether the player is controlled by the computer
        """
        self.color = color
        self.is_bot = is_bot

    def decide(self, game, playable_actions):
        """Should return one of the playable_actions or
        an OFFER_TRADE action if its your turn and you have already rolled.

        Args:
            game (Game): complete game state. read-only.
            playable_actions (Iterable[Action]): options right now
        """
        raise NotImplementedError

    def reset_state(self):
        """Hook for resetting state between games"""
        pass

    def __repr__(self):
        return f"{type(self).__name__}:{self.color.value}"


class SimplePlayer(Player):
    """Simple AI player that always takes the first action in the list of playable_actions"""

    def decide(self, game, playable_actions):
        return playable_actions[0]


class HumanPlayer(Player):
    """Human player that selects which action to take using standard input"""

    def decide(self, game, playable_actions):
        for i, action in enumerate(playable_actions):
            print(f"{i}: {action.action_type} {action.value}")
        i = None
        while i is None or (i < 0 or i >= len(playable_actions)):
            print("Please enter a valid index:")
            try:
                x = input(">>> ")
                i = int(x)
            except ValueError:
                pass

        return playable_actions[i]


class RandomPlayer(Player):
    """Random AI player that selects an action randomly from the list of playable_actions"""

    def decide(self, game, playable_actions):
        return random.choice(playable_actions)

--- catanatron_core/catanatron/models/__init__.py ---

--- catanatron_core/catanatron/players/search.py ---
import random

from catanatron.state_functions import (
    player_key,
)
from catanatron.models.player import Player
from catanatron.game import Game


class VictoryPointPlayer(Player):
    """
    Player that chooses actions by maximizing Victory Points greedily.
    If multiple actions lead to the same max-points-achievable
    in this turn, selects from them at random.
    """

    def decide(self, game: Game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]

        best_value = float("-inf")
        best_actions = []
        for action in playable_actions:
            game_copy = game.copy()
            game_copy.execute(action)

            key = player_key(game_copy.state, self.color)
            value = game_copy.state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"]
            if value == best_value:
                best_actions.append(action)
            if value > best_value:
                best_value = value
                best_actions = [action]

        return random.choice(best_actions)

--- catanatron_core/catanatron/players/weighted_random.py ---
import random

from catanatron.models.player import Player
from catanatron.models.actions import ActionType


WEIGHTS_BY_ACTION_TYPE = {
    ActionType.BUILD_CITY: 10000,
    ActionType.BUILD_SETTLEMENT: 1000,
    ActionType.BUY_DEVELOPMENT_CARD: 100,
}


class WeightedRandomPlayer(Player):
    """
    Player that decides at random, but skews distribution
    to actions that are likely better (cities > settlements > dev cards).
    """

    def decide(self, game, playable_actions):
        bloated_actions = []
        for action in playable_actions:
            weight = WEIGHTS_BY_ACTION_TYPE.get(action.action_type, 1)
            bloated_actions.extend([action] * weight)

        return random.choice(bloated_actions)

--- catanatron_core/catanatron/players/__init__.py ---

--- catanatron_core/catanatron.egg-info/dependency_links.txt ---


--- catanatron_core/catanatron.egg-info/PKG-INFO ---
Metadata-Version: 2.1
Name: catanatron
Version: 3.2.1
Summary: Fast Settlers of Catan Python Implementation
Home-page: https://github.com/bcollazo/catanatron
Author: Bryan Collazo
Author-email: bcollazo2010@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: networkx

# Catanatron

[![Coverage Status](https://coveralls.io/repos/github/bcollazo/catanatron/badge.svg?branch=master)](https://coveralls.io/github/bcollazo/catanatron?branch=master)
[![Documentation Status](https://readthedocs.org/projects/catanatron/badge/?version=latest)](https://catanatron.readthedocs.io/en/latest/?badge=latest)
[![Join the chat at https://gitter.im/bcollazo-catanatron/community](https://badges.gitter.im/bcollazo-catanatron/community.svg)](https://gitter.im/bcollazo-catanatron/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bcollazo/catanatron/blob/master/catanatron_experimental/catanatron_experimental/Overview.ipynb)

Settlers of Catan Bot and Bot Simulator. Test out bot strategies at scale (thousands of games per minutes). The goal of this project is to find the strongest Settlers of Catan bot possible.

See the motivation of the project here: [5 Ways NOT to Build a Catan AI](https://medium.com/@bcollazo2010/5-ways-not-to-build-a-catan-ai-e01bc491af17).

<p align="left">
 <img src="https://raw.githubusercontent.com/bcollazo/catanatron/master/docs/source/_static/cli.gif">
</p>

## Installation

Clone this repository and install dependencies. This will include the Catanatron bot implementation and the `catanatron-play` simulator.

```
git clone git@github.com:bcollazo/catanatron.git
cd catanatron/
```

Create a virtual environment with Python3.8 or higher. Then:

```
pip install -r all-requirements.txt
```

## Usage

Run simulations and generate datasets via the CLI:

```
catanatron-play --players=R,R,R,W --num=100
```

See more information with `catanatron-play --help`.

## Try Your Own Bots

Implement your own bots by creating a file (e.g. `myplayers.py`) with some `Player` implementations:

```python
from catanatron import Player
from catanatron_experimental.cli.cli_players import register_player

@register_player("FOO")
class FooPlayer(Player):
  def decide(self, game, playable_actions):
    """Should return one of the playable_actions.

    Args:
        game (Game): complete game state. read-only.
        playable_actions (Iterable[Action]): options to choose from
    Return:
        action (Action): Chosen element of playable_actions
    """
    # ===== YOUR CODE HERE =====
    # As an example we simply return the first action:
    return playable_actions[0]
    # ===== END YOUR CODE =====
```

Run it by passing the source code to `catanatron-play`:

```
catanatron-play --code=myplayers.py --players=R,R,R,FOO --num=10
```

## How to Make Catanatron Stronger?

The best bot right now is Alpha Beta Search with a hand-crafted value function. One of the most promising ways of improving Catanatron
is to have your custom player inhert from ([`AlphaBetaPlayer`](catanatron_experimental/catanatron_experimental/machine_learning/players/minimax.py)) and set a better set of weights for the value function. You can
also edit the value function and come up with your own innovative features!

For more sophisticated approaches, see example player implementations in [catanatron_core/catanatron/players](catanatron_core/catanatron/players)

If you find a bot that consistently beats the best bot right now, please submit a Pull Request! :)

## Advanced Usage

### Inspecting Games (Browser UI)

We provide a [docker-compose.yml](docker-compose.yml) with everything needed to watch games (useful for debugging). It contains all the web-server infrastructure needed to render a game in a browser.

<p align="left">
 <img src="https://raw.githubusercontent.com/bcollazo/catanatron/master/docs/source/_static/CatanatronUI.png">
</p>

To use, ensure you have [Docker Compose](https://docs.docker.com/compose/install/) installed, and run (from this repo's root):

```
docker-compose up
```

You can now use the `--db` flag to make the catanatron-play simulator save
the game in the database for inspection via the web server.

```
catanatron-play --players=W,W,W,W --db --num=1
```

NOTE: A great contribution would be to make the Web UI allow to step forwards and backwards in a game to inspect it (ala chess.com).

### Accumulators

The `Accumulator` class allows you to hook into important events during simulations.

For example, write a file like `mycode.py` and have:

```python
from catanatron import ActionType
from catanatron_experimental import SimulationAccumulator, register_accumulator

@register_accumulator
class PortTradeCounter(SimulationAccumulator):
  def before_all(self):
    self.num_trades = 0

  def step(self, game_before_action, action):
    if action.action_type == ActionType.MARITIME_TRADE:
      self.num_trades += 1

  def after_all(self):
    print(f'There were {self.num_trades} port trades!')
```

Then `catanatron-play --code=mycode.py` will count the number of trades in all simulations.

### As a Package / Library

You can also use `catanatron` package directly which provides a core
implementation of the Settlers of Catan game logic.

```python
from catanatron import Game, RandomPlayer, Color

# Play a simple 4v4 game
players = [
    RandomPlayer(Color.RED),
    RandomPlayer(Color.BLUE),
    RandomPlayer(Color.WHITE),
    RandomPlayer(Color.ORANGE),
]
game = Game(players)
print(game.play())  # returns winning color
```

You can use the `open_link` helper function to open up the game (useful for debugging):

```python
from catanatron_server.utils import open_link
open_link(game)  # opens game in browser
```

## Architecture

The code is divided in the following 5 components (folders):

- **catanatron**: A pure python implementation of the game logic. Uses `networkx` for fast graph operations. Is pip-installable (see `setup.py`) and can be used as a Python package. See the documentation for the package here: https://catanatron.readthedocs.io/.

- **catanatron_server**: Contains a Flask web server in order to serve
  game states from a database to a Web UI. The idea of using a database, is to ease watching games played in a different process. It defaults to using an ephemeral in-memory sqlite database. Also pip-installable (not publised in PyPi however).

- **catanatron_gym**: OpenAI Gym interface to Catan. Includes a 1v1 environment against a Random Bot and a vector-friendly representations of states and actions. This can be pip-installed independently with `pip install catanatron_gym`, for more information see [catanatron_gym/README.md](catanatron_gym/README.md).

- **catantron_experimental**: A collection of unorganized scripts with contain many failed attempts at finding the best possible bot. Its ok to break these scripts. Its pip-installable. Exposes a `catanatron-play` command-line script that can be used to play games in bulk, create machine learning datasets of games, and more!

- **ui**: A React web UI to render games. This is helpful for debugging the core implementation. We decided to use the browser as a randering engine (as opposed to the terminal or a desktop GUI) because of HTML/CSS's ubiquitousness and the ability to use modern animation libraries in the future (https://www.framer.com/motion/ or https://www.react-spring.io/).

## AI Bots Leaderboard

Catanatron will always be the best bot in this leaderboard.

The best bot right now is `AlphaBetaPlayer` with n = 2. Here a list of bots strength. Experiments
done by running 1000 (when possible) 1v1 games against previous in list.

| Player               | % of wins in 1v1 games      | num games used for result |
| -------------------- | --------------------------- | ------------------------- |
| AlphaBeta(n=2)       | 80% vs ValueFunction        | 25                        |
| ValueFunction        | 90% vs GreedyPlayouts(n=25) | 25                        |
| GreedyPlayouts(n=25) | 100% vs MCTS(n=100)         | 25                        |
| MCTS(n=100)          | 60% vs WeightedRandom       | 15                        |
| WeightedRandom       | 53% vs WeightedRandom       | 1000                      |
| VictoryPoint         | 60% vs Random               | 1000                      |
| Random               | -                           | -                         |

## Developing for Catanatron

To develop for Catanatron core logic you can use the following test suite:

```
coverage run --source=catanatron -m pytest tests/ && coverage report
```

Or you can run the suite in watch-mode with:

```
ptw --ignore=tests/integration_tests/ --nobeep
```

## Machine Learning

Generate JSON files with complete information about games and decisions by running:

```
catanatron-play --num=100 --output=my-data-path/ --json
```

Similarly (with Tensorflow installed) you can generate several GZIP CSVs of a basic set of features:

```
catanatron-play --num=100 --output=my-data-path/ --csv
```

You can then use this data to build a machine learning model, and then
implement a `Player` subclass that implements the corresponding "predict"
step of your model. There are some attempts of these type of
players in [reinforcement.py](catanatron_experimental/catanatron_experimental/machine_learning/players/reinforcement.py).

# Appendix

## Running Components Individually

As an alternative to running the project with Docker, you can run the following 3 components: a React UI, a Flask Web Server, and a PostgreSQL database in three separate Terminal tabs.

### React UI

```
cd ui/
npm install
npm start
```

This can also be run via Docker independetly like (after building):

```
docker build -t bcollazo/catanatron-react-ui:latest ui/
docker run -it -p 3000:3000 bcollazo/catanatron-react-ui
```

### Flask Web Server

Ensure you are inside a virtual environment with all dependencies installed and
use `flask run`.

```
python3.8 -m venv venv
source ./venv/bin/activate
pip install -r requirements.txt

cd catanatron_server/catanatron_server
flask run
```

This can also be run via Docker independetly like (after building):

```
docker build -t bcollazo/catanatron-server:latest . -f Dockerfile.web
docker run -it -p 5000:5000 bcollazo/catanatron-server
```

### PostgreSQL Database

Make sure you have `docker-compose` installed (https://docs.docker.com/compose/install/).

```
docker-compose up
```

Or run any other database deployment (locally or in the cloud).

## Other Useful Commands

### TensorBoard

For watching training progress, use `keras.callbacks.TensorBoard` and open TensorBoard:

```
tensorboard --logdir logs
```

### Docker GPU TensorFlow

```
docker run -it tensorflow/tensorflow:latest-gpu-jupyter bash
docker run -it --rm -v $(realpath ./notebooks):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter
```

### Testing Performance

```
python -m cProfile -o profile.pstats catanatron_experimental/catanatron_experimental/play.py --num=5
snakeviz profile.pstats
```

```
pytest --benchmark-compare=0001 --benchmark-compare-fail=mean:10% --benchmark-columns=min,max,mean,stddev
```

### Head Large Datasets with Pandas

```
In [1]: import pandas as pd
In [2]: x = pd.read_csv("data/mcts-playouts-labeling-2/labels.csv.gzip", compression="gzip", iterator=True)
In [3]: x.get_chunk(10)
```

### Publishing to PyPi

catanatron Package

```
make build PACKAGE=catanatron_core
make upload PACKAGE=catanatron_core
make upload-production PACKAGE=catanatron_core
```

catanatron_gym Package

```
make build PACKAGE=catanatron_gym
make upload PACKAGE=catanatron_gym
make upload-production PACKAGE=catanatron_gym
```

### Building Docs

```
sphinx-quickstart docs
sphinx-apidoc -o docs/source catanatron_core
sphinx-build -b html docs/source/ docs/build/html
```

# Contributing

I am new to Open Source Development, so open to suggestions on this section. The best contributions would be to make the core bot stronger.

Other than that here is also a list of ideas:

- Improve `catanatron` package running time performance.

  - Continue refactoring the State to be more and more like a primitive `dict` or `array`.
    (Copies are much faster if State is just a native python object).
  - Move RESOURCE to be ints. Python `enums` turned out to be slow for hashing and using.
  - Move .actions to a Game concept. (to avoid copying when copying State)
  - Remove .current_prompt. It seems its redundant with (is_moving_knight, etc...) and not needed.

- Improve AlphaBetaPlayer:

  - Explore and improve prunning
  - Use Bayesian Methods or SPSA to tune weights and find better ones.

- Experiment ideas:

  - DQN Render Method. Use models/mbs=64\_\_1619973412.model. Try to understand it.
  - DQN Two Layer Algo. With Simple Action Space.
  - Simple Alpha Go
  - Try Tensorforce with simple action space.
  - Try simple flat CSV approach but with AlphaBeta-generated games.
  - Visualize tree with graphviz. With colors per maximizing/minimizing.
  - Create simple entry-point notebook for this project. Runnable via Paperspace. (might be hard because catanatron requires Python 3.8 and I haven't seen a GPU-enabled tensorflow+jupyter+pyhon3.8 Docker Image out there).

- Bugs:

  - Shouldn't be able to use dev card just bought.
  - dev cards can't be played
  - order the trade options by input then output
  - robber position is autoselected
  - Make road highlighting more obvious to click
  - Ask if he's redeployed recently

- Features:

  - Continue implementing actions from the UI (not all implemented).
  - Chess.com-like UI for watching game replays (with Play/Pause and Back/Forward).
  - A terminal UI? (for ease of debugging)

--- catanatron_core/catanatron.egg-info/requires.txt ---
networkx

--- catanatron_core/catanatron.egg-info/SOURCES.txt ---
setup.py
catanatron/__init__.py
catanatron/game.py
catanatron/json.py
catanatron/state.py
catanatron/state_functions.py
catanatron.egg-info/PKG-INFO
catanatron.egg-info/SOURCES.txt
catanatron.egg-info/dependency_links.txt
catanatron.egg-info/requires.txt
catanatron.egg-info/top_level.txt
catanatron/models/__init__.py
catanatron/models/actions.py
catanatron/models/board.py
catanatron/models/coordinate_system.py
catanatron/models/decks.py
catanatron/models/enums.py
catanatron/models/map.py
catanatron/models/player.py
catanatron/players/__init__.py
catanatron/players/search.py
catanatron/players/weighted_random.py
--- catanatron_core/catanatron.egg-info/top_level.txt ---
catanatron

--- catanatron_experimental/catanatron_experimental/data_logger.py ---
from pathlib import Path

import pandas as pd

from catanatron_gym.features import (
    create_sample_vector,
    get_feature_ordering,
)
from catanatron_gym.board_tensor_features import (
    CHANNELS,
    HEIGHT,
    WIDTH,
    create_board_tensor,
)


class DataLogger:
    """
    Class to accumulate states, write to CSV files, and read them to TF Datasets
    """

    def __init__(self, output_path):
        self.output_path = Path(output_path)

        self.samples = []
        self.board_tensors = []
        # TODO: Implement, Actions and Rewards
        self.labels = []
        self.log_lines = []

    def consume(self, game, mcts_labels):
        import tensorflow as tf  # lazy import tf so that catanatron simulator is usable without tf

        for color in game.state.colors:
            sample = create_sample_vector(game, color)
            flattened_board_tensor = tf.reshape(
                create_board_tensor(game, color),
                (WIDTH * HEIGHT * CHANNELS,),
            ).numpy()
            label = mcts_labels.get(color, 0)

            self.samples.append(sample)
            self.board_tensors.append(flattened_board_tensor)
            self.labels.append(label)
            self.log_lines.append(
                [
                    game.id,
                    len(game.state.actions),
                    "http://localhost:3000/games/" + game.id,
                ]
            )

    def get_replay_buffer(self):
        return self.samples, self.board_tensors, self.labels

    def flush(self):
        print("Flushing...")
        # Convert to dataframes for writing
        samples_df = pd.DataFrame(self.samples, columns=get_feature_ordering()).astype(
            "float64"
        )
        board_tensors_df = pd.DataFrame(self.board_tensors).astype("float64")
        labels_df = pd.DataFrame(self.labels).astype("float64")
        logs_df = pd.DataFrame(
            self.log_lines, columns=["GAME_ID", "LEN(GAME.ACTIONS)", "LINK"]
        )

        # Write to disk
        if not self.output_path.exists():
            self.output_path.mkdir(parents=True)
        samples_path = Path(self.output_path, "samples.csv.gzip")
        board_tensors_path = Path(self.output_path, "board_tensors.csv.gzip")
        labels_path = Path(self.output_path, "labels.csv.gzip")
        logs_path = Path(self.output_path, "logs.csv.gzip")

        is_first_training = not samples_path.is_file()
        samples_df.to_csv(
            samples_path,
            mode="a",
            header=is_first_training,
            index=False,
            compression="gzip",
        )
        board_tensors_df.to_csv(
            board_tensors_path,
            mode="a",
            header=is_first_training,
            index=False,
            compression="gzip",
        )
        labels_df.to_csv(
            labels_path,
            mode="a",
            header=is_first_training,
            index=False,
            compression="gzip",
        )
        logs_df.to_csv(
            logs_path,
            mode="a",
            header=is_first_training,
            index=False,
            compression="gzip",
        )

        # Flush Memory
        self.samples = []
        self.board_tensors = []
        self.labels = []
        print("Done flushing data")

--- catanatron_experimental/catanatron_experimental/mcts_score_collector.py ---
import os
from typing import Iterable
from catanatron_experimental.machine_learning.utils import ensure_dir

import pandas as pd
import tensorflow as tf

from catanatron.game import Game
from catanatron.models.actions import Action
from catanatron.models.enums import SETTLEMENT, CITY
from catanatron.state_functions import (
    get_longest_road_length,
    get_played_dev_cards,
    player_key,
    player_num_dev_cards,
    player_num_resource_cards,
)
from catanatron_experimental.machine_learning.players.minimax import AlphaBetaPlayer
from catanatron_experimental.machine_learning.players.playouts import run_playouts
from catanatron_gym.features import (
    build_production_features,
    resource_hand_features,
)


def simple_feature_vector(game, p0_color):
    key = player_key(game.state, p0_color)
    f_public_vps = game.state.player_state[f"P0_VICTORY_POINTS"]
    f_enemy_public_vps = game.state.player_state[f"P1_VICTORY_POINTS"]

    production_features = build_production_features(True)
    our_production_sample = production_features(game, p0_color)
    enemy_production_sample = production_features(game, p0_color)

    f_longest_road_length = game.state.player_state["P0_LONGEST_ROAD_LENGTH"]
    f_enemy_longest_road_length = game.state.player_state["P1_LONGEST_ROAD_LENGTH"]

    hand_sample = resource_hand_features(game, p0_color)
    distance_to_city = (
        max(2 - hand_sample["P0_WHEAT_IN_HAND"], 0)
        + max(3 - hand_sample["P0_ORE_IN_HAND"], 0)
    ) / 5.0  # 0 means good. 1 means bad.
    distance_to_settlement = (
        max(1 - hand_sample["P0_WHEAT_IN_HAND"], 0)
        + max(1 - hand_sample["P0_SHEEP_IN_HAND"], 0)
        + max(1 - hand_sample["P0_BRICK_IN_HAND"], 0)
        + max(1 - hand_sample["P0_WOOD_IN_HAND"], 0)
    ) / 4.0  # 0 means good. 1 means bad.
    f_hand_synergy = (2 - distance_to_city - distance_to_settlement) / 2

    f_num_in_hand = player_num_resource_cards(game.state, p0_color)

    # blockability
    buildings = game.state.buildings_by_color[p0_color]
    owned_nodes = buildings[SETTLEMENT] + buildings[CITY]
    owned_tiles = set()
    for n in owned_nodes:
        owned_tiles.update(game.state.board.map.adjacent_tiles[n])
    # f_num_tiles = len(owned_tiles)

    # f_num_buildable_nodes = len(game.state.board.buildable_node_ids(p0_color))
    # f_hand_devs = player_num_dev_cards(game.state, p0_color)

    f_army_size = game.state.player_state[f"P1_PLAYED_KNIGHT"]
    f_enemy_army_size = game.state.player_state[f"P0_PLAYED_KNIGHT"]

    vector = {
        # Where to place. Note winning is best at all costs
        "PUBLIC_VPS": f_public_vps,
        "ENEMY_PUBLIC_VPS": f_enemy_public_vps,
        # "NUM_TILES": f_num_tiles,
        # "BUILDABLE_NODES": f_num_buildable_nodes,
        # Hand, when to hold and when to use.
        "HAND_SYNERGY": f_hand_synergy,
        "HAND_RESOURCES": f_num_in_hand,
        # "HAND_DEVS": f_hand_devs,
        # Other
        "ROAD_LENGTH": f_longest_road_length,
        "ENEMY_ROAD_LENGTH": f_enemy_longest_road_length,
        "ARMY_SIZE": f_army_size,
        "ENEMY_ARMY_SIZE": f_enemy_army_size,
    }
    vector = {**vector, **our_production_sample}
    vector = {**vector, **enemy_production_sample}
    return vector


NUM_SIMULATIONS = 100
RECORDS = []
DATA_DIRECTORY = "data/mcts-collector"
DATASET_PATH = os.path.join(DATA_DIRECTORY, "simple.csv.gzip")


class MCTSScoreCollector(AlphaBetaPlayer):
    def reset_state(self):
        global RECORDS
        super().reset_state()

        if len(RECORDS) > 0:  # Flush data to disk
            ensure_dir(DATA_DIRECTORY)
            is_first_training = not os.path.isfile(DATASET_PATH)
            df = pd.DataFrame.from_records(RECORDS).astype("float64")
            df.to_csv(
                DATASET_PATH,
                mode="a",
                header=is_first_training,
                index=False,
                compression="gzip",
            )
            RECORDS = []
            print("Flushed dataset of shape:", df.shape)

    def decide(self, game: Game, playable_actions: Iterable[Action]):
        """Should return one of the playable_actions.

        Args:
            game (Game): complete game state. read-only.
            playable_actions (Iterable[Action]): options to choose from
        Return:
            action (Action): Chosen element of playable_actions
        """
        decided_action = super().decide(game, playable_actions)

        # Log simple dataset of simple features and MCTS Score
        results = run_playouts(game.copy(), NUM_SIMULATIONS)
        vector = simple_feature_vector(game, self.color)
        vector["LABEL"] = results[self.color] / float(NUM_SIMULATIONS)
        RECORDS.append(vector)

        return decided_action


# Singleton-pattern
MCTS_PREDICTOR_MODEL = None


class MCTSPredictor(AlphaBetaPlayer):
    def __init__(self, *params, **kwargs):
        super().__init__(*params, **kwargs)
        self.use_value_function = True

    def value_function(self, game, p0_color):
        global MCTS_PREDICTOR_MODEL
        if MCTS_PREDICTOR_MODEL is None:
            MCTS_PREDICTOR_MODEL = tf.keras.models.load_model(
                "catanatron_experimental/catanatron_experimental/notebooks/models/simple-mcts-score-predictor"
            )
        model = MCTS_PREDICTOR_MODEL

        vector = simple_feature_vector(game, p0_color)
        df = pd.DataFrame.from_records([vector])
        score = model.call(df)[0][0].numpy()

        return score

    def decide(self, game: Game, playable_actions):
        decided_action = super().decide(game, playable_actions)

        return decided_action

--- catanatron_experimental/catanatron_experimental/my_player.py ---
from typing import Iterable

from catanatron.game import Game
from catanatron.models.actions import Action
from catanatron.models.player import Player


class MyPlayer(Player):
    def decide(self, game: Game, playable_actions: Iterable[Action]):
        """Should return one of the playable_actions.

        Args:
            game (Game): complete game state. read-only.
            playable_actions (Iterable[Action]): options to choose from
        Return:
            action (Action): Chosen element of playable_actions
        """
        # ===== YOUR CODE HERE =====
        # As an example we simply return the first action:
        return playable_actions[0]
        # ===== END YOUR CODE =====

--- catanatron_experimental/catanatron_experimental/optunation.py ---
import optuna

from catanatron.models.player import Color
from catanatron_experimental.machine_learning.players.value import (
    DEFAULT_WEIGHTS,
    ValueFunctionPlayer,
)

from catanatron_experimental.catanatron_experimental.play import play_batch


def objective(trial):
    weights = {
        # Where to place. Note winning is best at all costs
        "public_vps": trial.suggest_float("public_vps", 0.0, 100.0),
        "production": trial.suggest_float("production", 0.0, 100.0),
        "enemy_production": -trial.suggest_float("enemy_production", 0.0, 100.0),
        "num_tiles": trial.suggest_float("num_tiles", 0.0, 100.0),
        # Towards where to expand and when
        "reachable_production_0": trial.suggest_float(
            "reachable_production_0", 0.0, 100.0
        ),
        "reachable_production_1": trial.suggest_float(
            "reachable_production_1", 0.0, 100.0
        ),
        "buildable_nodes": trial.suggest_float("buildable_nodes", 0.0, 100.0),
        "longest_road": trial.suggest_float("longest_road", 0.0, 100.0),
        # Hand, when to hold and when to use.
        "hand_synergy": trial.suggest_float("hand_synergy", 0.0, 100.0),
        "hand_resources": trial.suggest_float("hand_resources", 0.0, 100.0),
        "discard_penalty": -trial.suggest_float("discard_penalty", 0.0, 100.0),
        "hand_devs": trial.suggest_float("hand_devs", 0.0, 100.0),
        "army_size": trial.suggest_float("army_size", 0.0, 100.0),
    }

    players = [
        # AlphaBetaPlayer(Color.RED, 2, True),
        # AlphaBetaPlayer(Color.BLUE, 2, True, "C", weights),
        ValueFunctionPlayer(Color.RED, "C", params=DEFAULT_WEIGHTS),
        ValueFunctionPlayer(Color.BLUE, "C", params=weights),
    ]
    wins, results_by_player = play_batch(200, players)
    vps = results_by_player[players[1].color]
    avg_vps = sum(vps) / len(vps)
    return 1000 * wins[players[1].color] + avg_vps


if __name__ == "__main__":
    study = optuna.create_study(
        study_name="optunatan",
        direction="maximize",
        load_if_exists=True,
        storage="sqlite:///optunatan.db",
    )
    study.optimize(
        objective,
        n_trials=100,
    )  # Invoke optimization of the objective function.

--- catanatron_experimental/catanatron_experimental/Overview.ipynb ---
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38540cf7-9b4f-4c98-9abb-952c84443f1d",
   "metadata": {},
   "source": [
    "# Catanatron Introduction\n",
    "This shows example usage of Catanatron. First, clone the repo and install requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be394e4-9bcd-46bb-892b-7538ad3b2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bcollazo/catanatron.git\n",
    "!pip install -r catanatron/dev-requirements.txt\n",
    "!pip install -e catanatron/catanatron_core\n",
    "!pip install -e catanatron/catanatron_server\n",
    "!pip install -e catanatron/catanatron_gym\n",
    "!pip install -e catanatron/catanatron_experimental\n",
    "exit() # Forcefully restart runtime to picks up installed requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8f5a2-feb0-49d3-a2b5-a9f1c462db5d",
   "metadata": {},
   "source": [
    "Then, you can implement your own bot strategy and pit against some benchmark bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40e33f-8937-4918-b626-d70a2615e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from catanatron.game import Game\n",
    "from catanatron.models.player import Player, RandomPlayer, Color\n",
    "from catanatron.players.weighted_random import WeightedRandomPlayer\n",
    "\n",
    "class MyPlayer(Player):\n",
    "    def decide(self, game, playable_actions):\n",
    "        \"\"\"Should return one of the playable_actions.\n",
    "\n",
    "        Args:\n",
    "            game (Game): complete game state. read-only.\n",
    "            playable_actions (Iterable[Action]): options to choose from\n",
    "        Return:\n",
    "            action (Action): Chosen element of playable_actions\n",
    "        \"\"\"\n",
    "        # ===== YOUR CODE HERE =====\n",
    "        # As an example we simply choose a valid action at random:\n",
    "        return random.choice(playable_actions)\n",
    "        # ===== END YOUR CODE =====\n",
    "\n",
    "# Play a simple 4v4 game. Edit MyPlayer with your logic!\n",
    "players = [\n",
    "    MyPlayer(Color.RED),\n",
    "    WeightedRandomPlayer(Color.BLUE),\n",
    "    RandomPlayer(Color.WHITE),\n",
    "    RandomPlayer(Color.ORANGE),\n",
    "]\n",
    "game = Game(players)\n",
    "print(game.play())  # returns winning color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd529f61-6de7-4de1-8e0c-273db6a2de9f",
   "metadata": {},
   "source": [
    "You can also simulate thousands of games to get more statistically significant results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b3b9c-aa9c-4ec3-9b05-74c5d389d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from catanatron_experimental.play import play_batch\n",
    "\n",
    "wins, results_by_player, games = play_batch(10, players)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e64f53-26dc-40d4-ae7c-1410355617e8",
   "metadata": {},
   "source": [
    "You can inspect the game states in a variety of ways and compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34effc30-5cad-4031-aab8-fa91e2d0d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catanatron.json import GameEncoder\n",
    "from catanatron_gym.features import create_sample_vector, create_sample\n",
    "from catanatron_gym.board_tensor_features import (\n",
    "    create_board_tensor,\n",
    ")\n",
    "\n",
    "game = games[0]  # pick say the first one\n",
    "\n",
    "# 1. Feature dictionary of last state before game ended from REDs perspective. \n",
    "#   See https://catanatron.readthedocs.io/en/latest/catanatron_gym.envs.html#catanatron_gym.envs.catanatron_env.CatanatronEnv.observation_space\n",
    "#   for more information on this representation.\n",
    "# record = create_sample(game, Color.RED)\n",
    "# pprint(record)\n",
    "\n",
    "# 2. Vector (similar to 1) of last state before game ended\n",
    "# vector = create_sample_vector(game, Color.RED)\n",
    "# print(vector)\n",
    "\n",
    "# 3. Board Tensor representation, similar to the one described in https://arxiv.org/abs/2008.07079\n",
    "# tensor = create_board_tensor(game, Color.RED)\n",
    "# print(tensor)\n",
    "\n",
    "# 4. Inspect Python catanatron.state.State class\n",
    "# print(game.state)\n",
    "\n",
    "# 5. JSON Representation (with full action history)\n",
    "game_json = GameEncoder().default(game)\n",
    "pprint(game_json)  # inspect a game state representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

--- catanatron_experimental/catanatron_experimental/play.py ---
import os
import importlib.util
from dataclasses import dataclass
from typing import Literal, Union

import click
from rich.console import Console
from rich.table import Table
from rich.progress import Progress
from rich.progress import Progress, BarColumn, TimeRemainingColumn
from rich import box
from rich.console import Console
from rich.theme import Theme
from rich.text import Text

from catanatron.game import Game
from catanatron.models.player import Color
from catanatron.models.map import build_map
from catanatron.state_functions import get_actual_victory_points

# try to suppress TF output before any potentially tf-importing modules
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
from catanatron_experimental.utils import ensure_dir, formatSecs
from catanatron_experimental.cli.cli_players import (
    CUSTOM_ACCUMULATORS,
    player_help_table,
    CLI_PLAYERS,
)
from catanatron_experimental.cli.accumulators import (
    JsonDataAccumulator,
    CsvDataAccumulator,
    DatabaseAccumulator,
    StatisticsAccumulator,
    VpDistributionAccumulator,
)
from catanatron_experimental.cli.simulation_accumulator import SimulationAccumulator


custom_theme = Theme(
    {
        "progress.remaining": "",
        "progress.percentage": "",
        "bar.complete": "green",
        "bar.finished": "green",
    }
)
console = Console(theme=custom_theme)


class CustomTimeRemainingColumn(TimeRemainingColumn):
    """Renders estimated time remaining according to show_time field."""

    def render(self, task):
        """Show time remaining."""
        show = task.fields.get("show_time", True)
        if not show:
            return Text("")
        return super().render(task)


@click.command()
@click.option("-n", "--num", default=5, help="Number of games to play.")
@click.option(
    "--players",
    default="R,R,R,R",
    help="""
    Comma-separated players to use. Use ':' to set player-specific params.
    (e.g. --players=R,G:25,AB:2:C,W).\n
    See player legend with '--help-players'.
    """,
)
@click.option(
    "--code",
    default=None,
    help="Path to file with custom Players and Accumulators to import and use.",
)
@click.option(
    "-o",
    "--output",
    default=None,
    help="Directory where to save game data.",
)
@click.option(
    "--json",
    default=None,
    is_flag=True,
    help="Save game data in JSON format.",
)
@click.option(
    "--csv", default=False, is_flag=True, help="Save game data in CSV format."
)
@click.option(
    "--db",
    default=False,
    is_flag=True,
    help="""
        Save game in PGSQL database.
        Expects docker-compose provided database to be up and running.
        This allows games to be watched.
        """,
)
@click.option(
    "--config-discard-limit",
    default=7,
    help="Sets Discard Limit to use in games.",
)
@click.option(
    "--config-vps-to-win",
    default=10,
    help="Sets Victory Points needed to win games.",
)
@click.option(
    "--config-map",
    default="BASE",
    type=click.Choice(["BASE", "MINI", "TOURNAMENT"], case_sensitive=False),
    help="Sets Map to use. MINI is a 7-tile smaller version. TOURNAMENT uses a fixed balanced map.",
)
@click.option(
    "--quiet",
    default=False,
    is_flag=True,
    help="Silence console output. Useful for debugging.",
)
@click.option(
    "--help-players",
    default=False,
    type=bool,
    help="Show player codes and exits.",
    is_flag=True,
)
def simulate(
    num,
    players,
    code,
    output,
    json,
    csv,
    db,
    config_discard_limit,
    config_vps_to_win,
    config_map,
    quiet,
    help_players,
):
    """
    Catan Bot Simulator.
    Catanatron allows you to simulate millions of games at scale
    and test bot strategies against each other.

    Examples:\n\n
        catanatron-play --players=R,R,R,R --num=1000\n
        catanatron-play --players=W,W,R,R --num=50000 --output=data/ --csv\n
        catanatron-play --players=VP,F --num=10 --output=data/ --json\n
        catanatron-play --players=W,F,AB:3 --num=1 --csv --json --db --quiet
    """
    if code:
        abspath = os.path.abspath(code)
        spec = importlib.util.spec_from_file_location("module.name", abspath)
        if spec is not None and spec.loader is not None:
            user_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(user_module)

    if help_players:
        return Console().print(player_help_table())
    if output and not (json or csv):
        return print("--output requires either --json or --csv to be set")

    player_keys = players.split(",")
    players = []
    colors = [c for c in Color]
    for i, key in enumerate(player_keys):
        parts = key.split(":")
        code = parts[0]
        for cli_player in CLI_PLAYERS:
            if cli_player.code == code:
                params = [colors[i]] + parts[1:]
                player = cli_player.import_fn(*params)
                players.append(player)
                break

    output_options = OutputOptions(output, csv, json, db)
    game_config = GameConfigOptions(config_discard_limit, config_vps_to_win, config_map)
    play_batch(
        num,
        players,
        output_options,
        game_config,
        quiet,
    )


@dataclass(frozen=True)
class OutputOptions:
    """Class to keep track of output CLI flags"""

    output: Union[str, None] = None  # path to store files
    csv: bool = False
    json: bool = False
    db: bool = False


@dataclass(frozen=True)
class GameConfigOptions:
    discard_limit: int = 7
    vps_to_win: int = 10
    catan_map: Literal["BASE", "TOURNAMENT", "MINI"] = "BASE"


COLOR_TO_RICH_STYLE = {
    Color.RED: "red",
    Color.BLUE: "blue",
    Color.ORANGE: "yellow",
    Color.WHITE: "white",
}


def rich_player_name(player):
    style = COLOR_TO_RICH_STYLE[player.color]
    return f"[{style}]{player}[/{style}]"


def rich_color(color):
    if color is None:
        return ""
    style = COLOR_TO_RICH_STYLE[color]
    return f"[{style}]{color.value}[/{style}]"


def play_batch_core(num_games, players, game_config, accumulators=[]):
    for accumulator in accumulators:
        if isinstance(accumulator, SimulationAccumulator):
            accumulator.before_all()

    for _ in range(num_games):
        for player in players:
            player.reset_state()
        catan_map = build_map(game_config.catan_map)
        game = Game(
            players,
            discard_limit=game_config.discard_limit,
            vps_to_win=game_config.vps_to_win,
            catan_map=catan_map,
        )
        game.play(accumulators)
        yield game

    for accumulator in accumulators:
        if isinstance(accumulator, SimulationAccumulator):
            accumulator.after_all()


def play_batch(
    num_games,
    players,
    output_options=None,
    game_config=None,
    quiet=False,
):
    output_options = output_options or OutputOptions()
    game_config = game_config or GameConfigOptions()

    statistics_accumulator = StatisticsAccumulator()
    vp_accumulator = VpDistributionAccumulator()
    accumulators = [statistics_accumulator, vp_accumulator]
    if output_options.output:
        ensure_dir(output_options.output)
    if output_options.output and output_options.csv:
        accumulators.append(CsvDataAccumulator(output_options.output))
    if output_options.output and output_options.json:
        accumulators.append(JsonDataAccumulator(output_options.output))
    if output_options.db:
        accumulators.append(DatabaseAccumulator())
    for accumulator_class in CUSTOM_ACCUMULATORS:
        accumulators.append(accumulator_class(players=players, game_config=game_config))

    if quiet:
        for _ in play_batch_core(num_games, players, game_config, accumulators):
            pass
        return (
            dict(statistics_accumulator.wins),
            dict(statistics_accumulator.results_by_player),
            statistics_accumulator.games,
        )

    # ===== Game Details
    last_n = 10
    actual_last_n = min(last_n, num_games)
    table = Table(title=f"Last {actual_last_n} Games", box=box.MINIMAL)
    table.add_column("#", justify="right", no_wrap=True)
    table.add_column("SEATING")
    table.add_column("TURNS", justify="right")
    for player in players:
        table.add_column(f"{player.color.value} VP", justify="right")
    table.add_column("WINNER")
    if output_options.db:
        table.add_column("LINK", overflow="fold")

    with Progress(
        "[progress.description]{task.description}",
        BarColumn(),
        "[progress.percentage]{task.percentage:>3.0f}%",
        CustomTimeRemainingColumn(),
        console=console,
    ) as progress:
        main_task = progress.add_task(f"Playing {num_games} games...", total=num_games)
        player_tasks = [
            progress.add_task(
                rich_player_name(player), total=num_games, show_time=False
            )
            for player in players
        ]

        for i, game in enumerate(
            play_batch_core(num_games, players, game_config, accumulators)
        ):
            winning_color = game.winning_color()

            if (num_games - last_n) < (i + 1):
                seating = ",".join([rich_color(c) for c in game.state.colors])
                row = [
                    str(i + 1),
                    seating,
                    str(game.state.num_turns),
                ]
                for player in players:  # should be in column order
                    points = get_actual_victory_points(game.state, player.color)
                    row.append(str(points))
                row.append(rich_color(winning_color))
                if output_options.db:
                    row.append(accumulators[-1].link)

                table.add_row(*row)

            progress.update(main_task, advance=1)
            if winning_color is not None:
                winning_index = list(map(lambda p: p.color, players)).index(
                    winning_color
                )
                winner_task = player_tasks[winning_index]
                progress.update(winner_task, advance=1)
        progress.refresh()
    console.print(table)

    # ===== PLAYER SUMMARY
    table = Table(title="Player Summary", box=box.MINIMAL)
    table.add_column("", no_wrap=True)
    table.add_column("WINS", justify="right")
    table.add_column("AVG VP", justify="right")
    table.add_column("AVG SETTLES", justify="right")
    table.add_column("AVG CITIES", justify="right")
    table.add_column("AVG ROAD", justify="right")
    table.add_column("AVG ARMY", justify="right")
    table.add_column("AVG DEV VP", justify="right")
    for player in players:
        vps = statistics_accumulator.results_by_player[player.color]
        avg_vps = sum(vps) / len(vps)
        avg_settlements = vp_accumulator.get_avg_settlements(player.color)
        avg_cities = vp_accumulator.get_avg_cities(player.color)
        avg_largest = vp_accumulator.get_avg_largest(player.color)
        avg_longest = vp_accumulator.get_avg_longest(player.color)
        avg_devvps = vp_accumulator.get_avg_devvps(player.color)
        table.add_row(
            rich_player_name(player),
            str(statistics_accumulator.wins[player.color]),
            f"{avg_vps:.2f}",
            f"{avg_settlements:.2f}",
            f"{avg_cities:.2f}",
            f"{avg_longest:.2f}",
            f"{avg_largest:.2f}",
            f"{avg_devvps:.2f}",
        )
    console.print(table)

    # ===== GAME SUMMARY
    avg_ticks = f"{statistics_accumulator.get_avg_ticks():.2f}"
    avg_turns = f"{statistics_accumulator.get_avg_turns():.2f}"
    avg_duration = formatSecs(statistics_accumulator.get_avg_duration())
    table = Table(box=box.MINIMAL, title="Game Summary")
    table.add_column("AVG TICKS", justify="right")
    table.add_column("AVG TURNS", justify="right")
    table.add_column("AVG DURATION", justify="right")
    table.add_row(avg_ticks, avg_turns, avg_duration)
    console.print(table)

    if output_options.output and output_options.csv:
        console.print(f"GZIP CSVs saved at: [green]{output_options.output}[/green]")

    return (
        dict(statistics_accumulator.wins),
        dict(statistics_accumulator.results_by_player),
        statistics_accumulator.games,
    )


if __name__ == "__main__":
    simulate()

--- catanatron_experimental/catanatron_experimental/rayopt.py ---
from ray import tune

from catanatron.models.player import Color
from catanatron_experimental.machine_learning.players.value import (
    DEFAULT_WEIGHTS,
    ValueFunctionPlayer,
)
from ray.tune.suggest.bayesopt import BayesOptSearch
from ray.tune.suggest.suggestion import ConcurrencyLimiter

from catanatron_experimental.catanatron_experimental.play import play_batch


def objective(config):
    players = [
        # AlphaBetaPlayer(Color.RED, 2, True),
        # AlphaBetaPlayer(Color.BLUE, 2, True, "C", weights),
        ValueFunctionPlayer(Color.RED, "C", params=DEFAULT_WEIGHTS),
        ValueFunctionPlayer(Color.BLUE, "C", params=config),
    ]
    wins, results_by_player = play_batch(100, players)
    vps = results_by_player[players[1].color]
    avg_vps = sum(vps) / len(vps)
    score = 100 * wins[players[1].color] + avg_vps

    tune.report(score=score)  # This sends the score to Tune.


def trainable(config):
    # config (dict): A dict of hyperparameters.
    for _ in range(20):
        score = objective(config)

        tune.report(score=score)  # This sends the score to Tune.


analysis = tune.run(
    trainable,
    config={
        # Where to place. Note winning is best at all costs
        "public_vps": tune.uniform(0.0, 100.0),
        "production": tune.uniform(0.0, 100.0),
        "enemy_production": tune.uniform(-100.0, 0.0),
        "num_tiles": tune.uniform(0.0, 100.0),
        # Towards where to expand and when
        "reachable_production_0": tune.uniform(0.0, 100.0),
        "reachable_production_1": tune.uniform(0.0, 100.0),
        "buildable_nodes": tune.uniform(0.0, 100.0),
        "longest_road": tune.uniform(0.0, 100.0),
        # Hand, when to hold and when to use.
        "hand_synergy": tune.uniform(0.0, 100.0),
        "hand_resources": tune.uniform(0.0, 100.0),
        "discard_penalty": tune.uniform(-100.0, 0.0),
        "hand_devs": tune.uniform(0.0, 100.0),
        "army_size": tune.uniform(0.0, 100.0),
    },
    metric="score",
    mode="max",
    # Limit to two concurrent trials (otherwise we end up with random search)
    search_alg=ConcurrencyLimiter(
        BayesOptSearch(random_search_steps=4), max_concurrent=2
    ),
    num_samples=20,
    stop={"training_iteration": 20},
    verbose=2,
)

print("Best config: ", analysis.get_best_config(metric="score", mode="max"))

# Get a dataframe for analyzing trial results.
df = analysis.results_df
breakpoint()

--- catanatron_experimental/catanatron_experimental/rllibtest.py ---
from ray import tune
from ray.rllib.models.tf.tf_modelv2 import TFModelV2
from ray.rllib.models.tf.fcnet import FullyConnectedNetwork

import ray
from ray.rllib.agents.ppo import PPOTrainer
from ray.rllib import agents
from ray import tune
from ray.rllib.models import ModelCatalog
from ray.rllib.models.tf.tf_modelv2 import TFModelV2
from ray.rllib.models.tf.fcnet import FullyConnectedNetwork
from ray.rllib.utils import try_import_tf

tf = try_import_tf()

import tensorflow as tf

from catanatron_gym.envs.catanatron_env import CatanatronEnv


# https://towardsdatascience.com/action-masking-with-rllib-5e4bec5e7505
class KP0ActionMaskModel(TFModelV2):
    def __init__(
        self,
        obs_space,
        action_space,
        num_outputs,
        model_config,
        name,
        true_obs_shape=(11,),
        action_embed_size=5,
        *args,
        **kwargs
    ):
        super(KP0ActionMaskModel, self).__init__(
            obs_space, action_space, num_outputs, model_config, name, *args, **kwargs
        )

        self.action_embed_model = FullyConnectedNetwork(
            CatanatronEnv.observation_space,
            action_space,
            action_embed_size,
            model_config,
            name + "_action_embedding",
        )
        self.register_variables(self.action_embed_model.variables())

    def forward(self, input_dict, state, seq_lens):
        avail_actions = input_dict["obs"]["avail_actions"]
        action_mask = input_dict["obs"]["action_mask"]
        action_embedding, _ = self.action_embed_model(
            {"obs": input_dict["obs"]["state"]}
        )
        intent_vector = tf.expand_dims(action_embedding, 1)
        action_logits = tf.reduce_sum(avail_actions * intent_vector, axis=1)
        inf_mask = tf.maximum(tf.log(action_mask), tf.float32.min)
        return action_logits + inf_mask, state

    def value_function(self):
        return self.action_embed_model.value_function()


ModelCatalog.register_custom_model("kp_mask", KP0ActionMaskModel)

# ray.init(ignore_reinit_error=True)

# trainer_config = {"model": {"custom_model": "kp_mask"}, "env_config": env_config}
# trainer = agents.ppo.PPOTrainer(env="Knapsack-v0", config=trainer_config)


# Using: https://github.com/ray-project/ray/issues/7983
def train_ppo(config, reporter):
    agent = PPOTrainer(config)
    # agent.restore("/path/checkpoint_41/checkpoint-41")  # continue training
    i = 0
    while True:
        result = agent.train()
        if reporter is None:
            continue
        else:
            reporter(**result)
        if i % 10 == 0:  # save every 10th training iteration
            checkpoint_path = agent.save()
            print(checkpoint_path)
        i += 1
        # you can also change the curriculum here


config = {
    "env": CatanatronEnv,
    "num_workers": 4,
    # "model": {"custom_model": "kp_mask"},
}
print(config)
# trainingSteps = 1000000
# trainingSteps = 1000
# trials = tune.run(
#     train_ppo,
#     config=config,
#     stop={
#         "training_iteration": trainingSteps,
#     },
# )
# breakpoint()
import ray
import ray.rllib.agents.ppo as ppo
from ray.tune.logger import pretty_print

ray.init()
trainer = ppo.PPOTrainer(config=config)

# Can optionally call trainer.restore(path) to load a checkpoint.
for i in range(1000):
    # Perform one iteration of training the policy with PPO
    result = trainer.train()
    print(i, pretty_print(result))

    if i % 100 == 0:
        checkpoint = trainer.save()
        print("checkpoint saved at", checkpoint)
# tune.run(
#     "PPO",
#     config=config,
# )

--- catanatron_experimental/catanatron_experimental/spsa.py ---
"""
Implements https://www.chessprogramming.org/SPSA

This seems to work!  - November 7, 2021
"""
import random
import numpy as np

from catanatron.models.player import Color
from catanatron_experimental.machine_learning.players.value import (
    DEFAULT_WEIGHTS,
    ValueFunctionPlayer,
)
from catanatron_experimental.play import play_batch

# for (k=0; k < N; k++) {
#   ak = a / (k + 1 + A)^alpha;
#   ck = c / (k + 1)^γ;
#   for each p
#     Δp = 2 * round ( rand() / (RAND_MAX + 1.0) ) - 1.0;
#   Θ+ = Θ + ck*Δ;
#   Θ- = Θ - ck*Δ;
#   Θ +=  ak * match(Θ+, Θ-) / (ck*Δ);
# }

N = 1000
a = 1
c = 1
A = 100

p = len(DEFAULT_WEIGHTS.copy())
r = 10.0

alpha = 0.602
gamma = 0.101


def main():
    theta = np.array([1.0 for i in range(p)])
    for k in range(N):
        print("Iteration", k)
        ak = a / ((k + 1 + A) ** alpha)
        ck = c / ((k + 1) ** gamma)

        delta = np.array([random.choice((-r, r)) for _ in range(p)])

        theta_plus = theta + ck * delta
        theta_minus = theta - ck * delta
        theta += ak * match(theta_plus, theta_minus) / (ck * delta)

    print(theta)


def match(theta_plus, theta_minus):
    print(theta_plus, "vs", theta_minus)
    games_played = 200

    weights_plus = {
        k: v + theta_plus[i] for i, (k, v) in enumerate(DEFAULT_WEIGHTS.items())
    }
    weights_minus = {
        k: v + theta_minus[i] for i, (k, v) in enumerate(DEFAULT_WEIGHTS.items())
    }
    players = [
        ValueFunctionPlayer(Color.RED, "C", params=weights_plus),
        ValueFunctionPlayer(Color.BLUE, "C", params=weights_minus),
    ]
    wins, _ = play_batch(games_played, players)

    result = (wins[Color.RED] / games_played - 0.5) * 4  # normalized to [-2,+2] range
    print(result, wins)
    return result


if __name__ == "__main__":
    main()

--- catanatron_experimental/catanatron_experimental/utils.py ---
import os


def formatSecs(secs):
    return "{0:.3f} secs".format(secs)


def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

--- catanatron_experimental/catanatron_experimental/__init__.py ---
from catanatron_experimental.cli.simulation_accumulator import SimulationAccumulator
from catanatron_experimental.cli.cli_players import (
    register_player,
    register_accumulator,
)

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark.py ---
from catanatron.models.board import STATIC_GRAPH
import pickle
import timeit
import time
import sys
import numpy as np
import copy
import networkx as nx

from catanatron.game import Game
from catanatron.models.player import RandomPlayer, Color

import sys
from types import ModuleType, FunctionType
from gc import get_referents

# Custom objects know their class.
# Function objects seem to know way too much, including modules.
# Exclude modules as well.
BLACKLIST = type, ModuleType, FunctionType


def getsize(obj):
    """sum size of object & members."""
    if isinstance(obj, BLACKLIST):
        raise TypeError("getsize() does not take argument of type: " + str(type(obj)))
    seen_ids = set()
    size = 0
    objects = [obj]
    while objects:
        need_referents = []
        for obj in objects:
            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:
                seen_ids.add(id(obj))
                size += sys.getsizeof(obj)
                need_referents.append(obj)
        objects = get_referents(*need_referents)
    return size


game = Game(
    [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
)
game.play()
print(sys.getsizeof(game))
print(getsize(game))
print(game)

start = time.time()
copy.deepcopy(game)
end = time.time()
print("copy.deepcopy(game) took", end - start, "seconds")

start = time.time()
game.copy()
end = time.time()
print("game.copy() took", end - start, "seconds")

start = time.time()
state = np.random.random((1500,))
end = time.time()
print("Create Numpy Vector", end - start, "seconds")
print(sys.getsizeof(state), getsize(state))

start = time.time()
np.copy(state)
end = time.time()
print("np.copy(a) took", end - start, "seconds")

a = np.random.randint(0, 2, size=(500, 500))
start = time.time()
graph = nx.DiGraph(a)
end = time.time()
print("graph = nx.DiGraph(a)", end - start, "seconds")

start = time.time()
STATIC_GRAPH.copy()
end = time.time()
print("graph.copy()", end - start, "seconds")

# ==== Whats faster to hydrate 4 attributes or 1 numpy array attribute?
NUMBER = 1000
setup = """
import numpy as np

class Container:
    def __init__(self, initialize=True):
        if initialize:
            self.a = 1
            self.b = 3
            self.c = 4
            self.d = 1

class FaseContainer:
    def __init__(self, initialize=True):
        if initialize:
            self.a = np.array([1,3,4,1])

state = Container()
fast = FaseContainer()
"""
result = timeit.timeit(
    """
copy = Container(initialize=False)
copy.a = state.a
copy.b = state.b
copy.c = state.c
copy.d = state.d
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")
result = timeit.timeit(
    """
copy = FaseContainer(initialize=False)
copy.a = fast.a.copy()
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")
result = timeit.timeit(
    """
{'a': fast.a.copy()}
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")
# ==== END. creating new dict of 1 numpy array is fastest. 4 attrs is faster.

# === Its faster to copy dict than numpy array
setup = """
import numpy as np
x = {i: (i, i) for i in range(54)}
x[1] = (3,3)
y = np.zeros((54,2))
"""
result = timeit.timeit(
    "x.copy()",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")
result = timeit.timeit(
    "y.copy()",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")

# ===== its faster to .get('1', None)  than try catch
setup = """
x = {i: (i, i) for i in range(54)}
"""
result = timeit.timeit(
    "x.get(80, None)",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")
result = timeit.timeit(
    """
try:
    x[80]
except KeyError as e:
    None
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs")

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_bot_strength.py ---
from catanatron_experimental.play import simulate

simulate(50, "AB:2,F", None, False, False)

# Results:
# AVG Ticks: 235.28
# AVG Turns: 76.78
# AVG Duration: 88.40695652484894
# AVG VPS: ValueFunctionPlayer:Foo[RED]value_fn2 5.98
# AVG VPS: AlphaBetaPlayer:Bar[BLUE] 9.02
# ValueFunctionPlayer:Foo[RED]value_fn2 [11] ███████████▎
# AlphaBetaPlayer:Bar[BLUE] [39] ████████████████████████████████████████

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_create_sample_vector.py ---
import timeit

setup = """
from catanatron.game import Game
from catanatron.models.player import RandomPlayer, Color
from catanatron_gym.features import (
    create_sample_vector, expansion_features, reachability_features,
    graph_features, tile_features
)

game = Game(
    [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
)
game.play()
"""

NUMBER = 1000  # usually a game has around 300 turns and 1000 ticks
result = timeit.timeit(
    "create_sample_vector(game, game.state.colors[0])",
    setup=setup,
    number=NUMBER,
)
print("create_sample_vector\t", result / NUMBER, "secs")

result = timeit.timeit(
    "expansion_features(game, game.state.colors[0])",
    setup=setup,
    number=NUMBER,
)
print("expansion_features\t", result / NUMBER, "secs")

result = timeit.timeit(
    "reachability_features(game, game.state.colors[0])",
    setup=setup,
    number=NUMBER,
)
print("reachability_features\t", result / NUMBER, "secs")

result = timeit.timeit(
    "graph_features(game, game.state.colors[0])",
    setup=setup,
    number=NUMBER,
)
print("graph_features\t\t", result / NUMBER, "secs")


result = timeit.timeit(
    "tile_features(game, game.state.colors[0])",
    setup=setup,
    number=NUMBER,
)
print("tile_features\t\t", result / NUMBER, "secs")

# Notes:
# road seems to add 0.0025 secs
# production_features don't seem to add much.
# expansion_features seem to add 0.009

# Results:
# create_sample_vector	 0.0002994296670076437 secs
# expansion_features	 0.0009035729159950278 secs
# reachability_features	 0.00039436871399811934 secs
# graph_features		 1.5904047002550214e-05 secs
# tile_features		     3.960479953093454e-07 secs

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_deck.py ---
import timeit

setup = """
from catanatron.models.decks import (
    starting_resource_bank, freqdeck_count, freqdeck_draw, freqdeck_can_draw,
    freqdeck_replenish, freqdeck_subtract, freqdeck_add, starting_devcard_bank,
    freqdeck_from_listdeck)
from catanatron.models.enums import WOOD, BRICK, SHEEP, WHEAT, ORE, KNIGHT
"""

code = """
deck = starting_resource_bank()
assert freqdeck_count(deck, WOOD) == 19

deck = starting_resource_bank()
assert freqdeck_can_draw(deck, 10, BRICK)
assert not freqdeck_can_draw(deck, 20, BRICK)

deck = starting_resource_bank()
assert freqdeck_count(deck, WHEAT) == 19
assert sum(deck) == 19 * 5

assert freqdeck_can_draw(deck, 10, WHEAT)
freqdeck_draw(deck, 10, WHEAT)
assert freqdeck_count(deck, WHEAT) == 9

freqdeck_draw(deck, 9, WHEAT)
assert freqdeck_count(deck, WHEAT) == 0

freqdeck_replenish(deck, 2, WHEAT)
assert freqdeck_count(deck, WHEAT) == 2

freqdeck_draw(deck, 1, WHEAT)
assert freqdeck_count(deck, WHEAT) == 1

a = [0,0,0,0,0]
b = [0,0,0,0,0]

freqdeck_replenish(a, 10, ORE)
freqdeck_replenish(b, 1, ORE)

assert freqdeck_count(a, ORE) == 10
assert freqdeck_count(b, ORE) == 1
b = freqdeck_add(b, a)
assert freqdeck_count(a, ORE) == 10
assert freqdeck_count(b, ORE) == 11

a = [0,0,0,0,0]
b = [0,0,0,0,0]

freqdeck_replenish(a, 13, SHEEP)
freqdeck_replenish(b, 4, SHEEP)

assert freqdeck_count(a, SHEEP) == 13
assert freqdeck_count(b, SHEEP) == 4

freqdeck_replenish(b, 11, SHEEP)  # now has 15
b = freqdeck_subtract(b, a)
assert freqdeck_count(a, SHEEP) == 13
assert freqdeck_count(b, SHEEP) == 2

a = [0,0,0,0,0]

freqdeck_replenish(a, 3, SHEEP)
freqdeck_replenish(a, 2, BRICK)

a = starting_devcard_bank()
num_cards = len(a)

a.pop()

a = freqdeck_from_listdeck(
    [
        BRICK,
        BRICK,
        WOOD,
    ]
)
assert sum(a) == 3
assert freqdeck_count(a, BRICK) == 2
assert freqdeck_count(a, WOOD) == 1
"""

NUMBER = 10000
result = timeit.timeit(
    code,
    setup=setup,
    number=NUMBER,
)
print("deck integration", result / NUMBER, "secs")

# Results:
# deck integration 4.865029100000001e-06 secs

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_edge_id.py ---
import timeit


result = timeit.timeit("tuple(sorted((a,b)))", setup="a = 20; b = 45", number=2_000_000)
print("TODAY", result)

result = timeit.timeit(
    "(a,b) if a < b else (b,a)", setup="a = 20; b = 45", number=2_000_000
)
print("TERNARY", result)

result = timeit.timeit(
    "edge_id((a, b))",
    setup="a = 20; b = 45; edge_id = lambda x: (x[0],x[1]) if x[0] < x[1] else (x[1],x[0])",
    number=2_000_000,
)
print("FUNC TERNARY", result)

result = timeit.timeit(
    "edge_id(a, b)",
    setup="a = 20; b = 45; edge_id = lambda x, y: (x,y) if x < y else (y,x)",
    number=2_000_000,
)
print("FUNC TERNARY 2 PARAMS", result)

result = timeit.timeit(
    "(min(a, b), max(a, b))", setup="a = 20; b = 45", number=2_000_000
)
print("MIN MAX", result)

# I like map lookup because makes it easy to change to INT ids in the future (a more
# compact representation of an edge)
result = timeit.timeit(
    "edge_id[(a,b)]", setup="a = 20; b = 45; edge_id = {(a,b): 1}", number=2_000_000
)
print("MAP LOOKUP", result)

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_game_copy.py ---
import timeit

setup = """
import numpy as np
import pickle
from catanatron.game import Game, State
from catanatron.models.player import RandomPlayer, Color
from catanatron.models.enums import CITY, SETTLEMENT, Action, ActionType

game = Game(
    [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
)
game.play()
array_state = np.random.random((14,))
player_state = np.random.random((28 * 4,))
cost = np.array([0,0,2,3,0])
action_space = np.array([i for i in range(5000)])
"""

# 1 =====
NUMBER = 1000
result = timeit.timeit("game.copy()", setup=setup, number=NUMBER)
print(result / NUMBER, "secs; game.copy()")

# 2 =====
# Next step
result = timeit.timeit(
    """
board = dict()
board['map'] = game.state.board.map  # for caching speedups
board['buildings'] = game.state.board.buildings.copy()
board['roads'] = game.state.board.roads.copy()
board['connected_components'] = game.state.board.connected_components.copy()

state_copy = dict()
state_copy['colors'] = game.state.colors.copy()
state_copy['board'] = board
state_copy['actions'] = game.state.actions.copy()
state_copy['resource_freqdeck'] = game.state.resource_freqdeck.copy()
state_copy['development_listdeck'] = game.state.development_listdeck.copy()
state_copy['current_player_index'] = game.state.current_player_index
state_copy['num_turns'] = game.state.num_turns

game_copy = Game([], None, None, initialize=False)
game_copy.seed = game.seed
game_copy.id = game.id
game_copy.state = state_copy
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs; hand-hydrated")

# 3 =====
# Theoretical Python limit on state.copy(?) (Using numpy arrays)
result = timeit.timeit(
    """
# Players are 24-length array of numbers.
players = player_state.copy()

# Graph is tensor board(?)
board = {
    'map': game.state.board.map,
    'buildings': game.state.board.buildings.copy(),
    'roads': game.state.board.roads.copy(),
    'connected_components': game.state.board.connected_components.copy(),
}

state_copy = {
'players': players,
'board': board,
'array_state': array_state.copy(),
'actions': game.state.actions.copy(),
}
""",
    setup=setup,
    number=NUMBER,
)
print(result / NUMBER, "secs; theoretical-limit? (arrays + dicts + map-reuse)")


# Results:
# 3.558104199999998e-05 secs; game.copy()
# 5.459833999999997e-06 secs; hand-hydrated
# 2.3131659999999776e-06 secs; theoretical-limit? (arrays + dicts + map-reuse)

--- catanatron_experimental/catanatron_experimental/benchmarks/benchmark_game_ops.py ---
import timeit

setup = """
from catanatron.game import Game
from catanatron.models.player import RandomPlayer, Color


game = Game(
    [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
)
game.play()
"""


NUMBER = 1000  # usually a game has around 300 turns and 1000 ticks
result = timeit.timeit(
    "game.state.board.buildable_edges(Color.RED)",
    setup=setup,
    number=NUMBER,
)
print("buildable_edges", result / NUMBER, "secs")

--- catanatron_experimental/catanatron_experimental/cli/accumulators.py ---
import time
import os
import json
from collections import defaultdict

import numpy as np

from catanatron.game import GameAccumulator, Game
from catanatron.json import GameEncoder
from catanatron.state_functions import (
    get_actual_victory_points,
    get_dev_cards_in_hand,
    get_largest_army,
    get_longest_road_color,
    get_player_buildings,
)
from catanatron.models.enums import VICTORY_POINT, SETTLEMENT, CITY
from catanatron_server.models import database_session, upsert_game_state
from catanatron_server.utils import ensure_link
from catanatron_experimental.utils import formatSecs
from catanatron_experimental.machine_learning.utils import (
    get_discounted_return,
    get_tournament_return,
    get_victory_points_return,
    populate_matrices,
    DISCOUNT_FACTOR,
)
from catanatron_gym.features import create_sample
from catanatron_gym.envs.catanatron_env import to_action_space, to_action_type_space
from catanatron_gym.board_tensor_features import (
    create_board_tensor,
)


class VpDistributionAccumulator(GameAccumulator):
    """
    Accumulates CITIES,SETTLEMENTS,DEVVPS,LONGEST,LARGEST
    in each game per player.
    """

    def __init__(self):
        # These are all per-player. e.g. self.cities['RED']
        self.cities = defaultdict(int)
        self.settlements = defaultdict(int)
        self.devvps = defaultdict(int)
        self.longest = defaultdict(int)
        self.largest = defaultdict(int)

        self.num_games = 0

    def after(self, game: Game):
        winner = game.winning_color()
        if winner is None:
            return  # throw away data

        for color in game.state.colors:
            cities = len(get_player_buildings(game.state, color, CITY))
            settlements = len(get_player_buildings(game.state, color, SETTLEMENT))
            longest = get_longest_road_color(game.state) == color
            largest = get_largest_army(game.state)[0] == color
            devvps = get_dev_cards_in_hand(game.state, color, VICTORY_POINT)

            self.cities[color] += cities
            self.settlements[color] += settlements
            self.longest[color] += longest
            self.largest[color] += largest
            self.devvps[color] += devvps

        self.num_games += 1

    def get_avg_cities(self, color=None):
        if color is None:
            return sum(self.cities.values()) / self.num_games
        else:
            return self.cities[color] / self.num_games

    def get_avg_settlements(self, color=None):
        if color is None:
            return sum(self.settlements.values()) / self.num_games
        else:
            return self.settlements[color] / self.num_games

    def get_avg_longest(self, color=None):
        if color is None:
            return sum(self.longest.values()) / self.num_games
        else:
            return self.longest[color] / self.num_games

    def get_avg_largest(self, color=None):
        if color is None:
            return sum(self.largest.values()) / self.num_games
        else:
            return self.largest[color] / self.num_games

    def get_avg_devvps(self, color=None):
        if color is None:
            return sum(self.devvps.values()) / self.num_games
        else:
            return self.devvps[color] / self.num_games


class StatisticsAccumulator(GameAccumulator):
    def __init__(self):
        self.wins = defaultdict(int)
        self.turns = []
        self.ticks = []
        self.durations = []
        self.games = []
        self.results_by_player = defaultdict(list)

    def before(self, game):
        self.start = time.time()

    def after(self, game):
        duration = time.time() - self.start
        winning_color = game.winning_color()
        if winning_color is None:
            return  # do not track

        self.wins[winning_color] += 1
        self.turns.append(game.state.num_turns)
        self.ticks.append(len(game.state.actions))
        self.durations.append(duration)
        self.games.append(game)

        for color in game.state.colors:
            points = get_actual_victory_points(game.state, color)
            self.results_by_player[color].append(points)

    def get_avg_ticks(self):
        return sum(self.ticks) / len(self.ticks)

    def get_avg_turns(self):
        return sum(self.turns) / len(self.turns)

    def get_avg_duration(self):
        return sum(self.durations) / len(self.durations)


class StepDatabaseAccumulator(GameAccumulator):
    """
    Saves a game state to database for each tick.
    Slows game ~1s per tick.
    """

    def before(self, game):
        with database_session() as session:
            upsert_game_state(game, session)

    def step(self, game):
        with database_session() as session:
            upsert_game_state(game, session)


class DatabaseAccumulator(GameAccumulator):
    """Saves last game state to database"""

    def after(self, game):
        self.link = ensure_link(game)


class JsonDataAccumulator(GameAccumulator):
    def __init__(self, output):
        self.output = output

    def after(self, game):
        filepath = os.path.join(self.output, f"{game.id}.json")
        with open(filepath, "w") as f:
            f.write(json.dumps(game, cls=GameEncoder))


class CsvDataAccumulator(GameAccumulator):
    def __init__(self, output):
        self.output = output

    def before(self, game):
        self.data = defaultdict(
            lambda: {"samples": [], "actions": [], "board_tensors": [], "games": []}
        )

    def step(self, game, action):
        import tensorflow as tf  # lazy import tf so that catanatron simulator is usable without tf

        self.data[action.color]["samples"].append(create_sample(game, action.color))
        self.data[action.color]["actions"].append(
            [to_action_space(action), to_action_type_space(action)]
        )
        self.data[action.color]["games"].append(game.copy())
        board_tensor = create_board_tensor(game, action.color)
        shape = board_tensor.shape
        flattened_tensor = tf.reshape(
            board_tensor, (shape[0] * shape[1] * shape[2],)
        ).numpy()
        self.data[action.color]["board_tensors"].append(flattened_tensor)

    def after(self, game):
        import pandas as pd

        if game.winning_color() is None:
            return  # drop game

        print("Flushing to matrices...")
        t1 = time.time()
        samples = []
        actions = []
        board_tensors = []
        labels = []
        for color in game.state.colors:
            player_data = self.data[color]
            # TODO: return label, 2-ply search label, 1-play value function.

            # Make matrix of (RETURN, DISCOUNTED_RETURN, TOURNAMENT_RETURN, DISCOUNTED_TOURNAMENT_RETURN)
            episode_return = get_discounted_return(game, color, 1)
            discounted_return = get_discounted_return(game, color, DISCOUNT_FACTOR)
            tournament_return = get_tournament_return(game, color, 1)
            vp_return = get_victory_points_return(game, color)
            discounted_tournament_return = get_tournament_return(
                game, color, DISCOUNT_FACTOR
            )

            samples.extend(player_data["samples"])
            actions.extend(player_data["actions"])
            board_tensors.extend(player_data["board_tensors"])
            return_matrix = np.tile(
                [
                    [
                        episode_return,
                        discounted_return,
                        tournament_return,
                        discounted_tournament_return,
                        vp_return,
                    ]
                ],
                (len(player_data["samples"]), 1),
            )
            labels.extend(return_matrix)

        # Build Q-learning Design Matrix
        samples_df = (
            pd.DataFrame.from_records(samples, columns=sorted(samples[0].keys()))
            .astype("float64")
            .add_prefix("F_")
        )
        board_tensors_df = (
            pd.DataFrame(board_tensors).astype("float64").add_prefix("BT_")
        )
        actions_df = pd.DataFrame(actions, columns=["ACTION", "ACTION_TYPE"]).astype(
            "int"
        )
        rewards_df = pd.DataFrame(
            labels,
            columns=[
                "RETURN",
                "DISCOUNTED_RETURN",
                "TOURNAMENT_RETURN",
                "DISCOUNTED_TOURNAMENT_RETURN",
                "VICTORY_POINTS_RETURN",
            ],
        ).astype("float64")
        main_df = pd.concat(
            [samples_df, board_tensors_df, actions_df, rewards_df], axis=1
        )

        print(
            "Collected DataFrames. Data size:",
            "Main:",
            main_df.shape,
            "Samples:",
            samples_df.shape,
            "Board Tensors:",
            board_tensors_df.shape,
            "Actions:",
            actions_df.shape,
            "Rewards:",
            rewards_df.shape,
        )
        populate_matrices(
            samples_df,
            board_tensors_df,
            actions_df,
            rewards_df,
            main_df,
            self.output,
        )
        print(
            "Saved to matrices at:",
            self.output,
            ". Took",
            formatSecs(time.time() - t1),
        )
        return samples_df, board_tensors_df, actions_df, rewards_df

--- catanatron_experimental/catanatron_experimental/cli/cli_players.py ---
from collections import namedtuple

from rich.table import Table

from catanatron.models.player import RandomPlayer
from catanatron.players.weighted_random import WeightedRandomPlayer

# from catanatron_experimental.mcts_score_collector import (
#     MCTSScoreCollector,
#     MCTSPredictor,
# )
# from catanatron_experimental.machine_learning.players.reinforcement import (
#     QRLPlayer,
#     TensorRLPlayer,
#     VRLPlayer,
#     PRLPlayer,
# )
from catanatron_experimental.machine_learning.players.value import ValueFunctionPlayer
from catanatron_experimental.machine_learning.players.minimax import (
    AlphaBetaPlayer,
    SameTurnAlphaBetaPlayer,
)
from catanatron.players.search import VictoryPointPlayer
from catanatron_experimental.machine_learning.players.mcts import MCTSPlayer
from catanatron_experimental.machine_learning.players.playouts import (
    GreedyPlayoutsPlayer,
)

# from catanatron_experimental.machine_learning.players.online_mcts_dqn import (
#     OnlineMCTSDQNPlayer,
# )

# PLAYER_CLASSES = {
#     "O": OnlineMCTSDQNPlayer,
#     "S": ScikitPlayer,
#     "Y": MyPlayer,
#     # Used like: --players=V:path/to/model.model,T:path/to.model
#     "C": ForcePlayer,
#     "VRL": VRLPlayer,
#     "Q": QRLPlayer,
#     "P": PRLPlayer,
#     "T": TensorRLPlayer,
#     "D": DQNPlayer,
#     "CO": MCTSScoreCollector,
#     "COP": MCTSPredictor,
# }

# Player must have a CODE, NAME, DESCRIPTION, CLASS.
CliPlayer = namedtuple("CliPlayer", ["code", "name", "description", "import_fn"])
CLI_PLAYERS = [
    CliPlayer("R", "RandomPlayer", "Chooses actions at random.", RandomPlayer),
    CliPlayer(
        "W",
        "WeightedRandomPlayer",
        "Like RandomPlayer, but favors buying cities, settlements, and dev cards when possible.",
        WeightedRandomPlayer,
    ),
    CliPlayer(
        "VP",
        "VictoryPointPlayer",
        "Chooses randomly from actions that increase victory points immediately if possible, else at random.",
        VictoryPointPlayer,
    ),
    CliPlayer(
        "G",
        "GreedyPlayoutsPlayer",
        "For each action, will play N random 'playouts'. "
        + "Takes the action that led to best winning percent. "
        + "First param is NUM_PLAYOUTS",
        GreedyPlayoutsPlayer,
    ),
    CliPlayer(
        "M",
        "MCTSPlayer",
        "Decides according to the MCTS algorithm. First param is NUM_SIMULATIONS.",
        MCTSPlayer,
    ),
    CliPlayer(
        "F",
        "ValueFunctionPlayer",
        "Chooses the action that leads to the most immediate reward, based on a hand-crafted value function.",
        ValueFunctionPlayer,
    ),
    CliPlayer(
        "AB",
        "AlphaBetaPlayer",
        "Implements alpha-beta algorithm. That is, looks ahead a couple "
        + "levels deep evaluating leafs with hand-crafted value function. "
        + "Params are DEPTH, PRUNNING",
        AlphaBetaPlayer,
    ),
    CliPlayer(
        "SAB",
        "SameTurnAlphaBetaPlayer",
        "AlphaBeta but searches only within turn",
        SameTurnAlphaBetaPlayer,
    ),
]


def register_player(code):
    def decorator(player_class):
        CLI_PLAYERS.append(
            CliPlayer(
                code,
                player_class.__name__,
                player_class.__doc__,
                player_class,
            ),
        )

    return decorator


CUSTOM_ACCUMULATORS = []


def register_accumulator(accumulator_class):
    CUSTOM_ACCUMULATORS.append(accumulator_class)


def player_help_table():
    table = Table(title="Player Legend")
    table.add_column("CODE", justify="center", style="cyan", no_wrap=True)
    table.add_column("PLAYER")
    table.add_column("DESCRIPTION")
    for player in CLI_PLAYERS:
        table.add_row(player.code, player.name, player.description)
    return table

--- catanatron_experimental/catanatron_experimental/cli/simulation_accumulator.py ---
from catanatron.game import GameAccumulator


class SimulationAccumulator(GameAccumulator):
    def before_all(self):
        """Called before all games in a catanatron-play simulation."""
        pass

    def after_all(self):
        """Called after all games in a catanatron-play simulation."""
        pass

--- catanatron_experimental/catanatron_experimental/machine_learning/plot.py ---
import pickle
from pathlib import Path

import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from autosklearn.classification import AutoSklearnClassifier

mpl.rcParams["figure.figsize"] = (12, 10)
colors = plt.rcParams["axes.prop_cycle"].by_key()["color"]


def plot_feature_importances(X, y):
    columns = X.columns
    # Build a forest and compute the impurity-based feature importances
    forest = ExtraTreesClassifier(n_estimators=250, random_state=0)

    forest.fit(X, y)
    importances = forest.feature_importances_
    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)
    indices = np.argsort(importances)[::-1]

    # Print the feature ranking
    print("Feature ranking:")
    for f in range(X.shape[1]):
        print(
            "%d. feature %s (%f)"
            % (f + 1, columns[indices[f]], importances[indices[f]])
        )

    # Plot the impurity-based feature importances of the forest
    plt.figure()
    plt.title("Feature importances")
    plt.bar(
        range(X.shape[1]),
        importances[indices],
        color="r",
        yerr=std[indices],
        align="center",
    )
    plt.xticks(range(X.shape[1]), [columns[i] for i in indices], rotation=90)
    plt.xlim([-1, X.shape[1]])
    plt.tight_layout()
    plt.show()


def train(X, y):
    """example of auto-sklearn for a classification dataset"""
    # split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.33, random_state=1
    )
    # define search
    model = AutoSklearnClassifier(
        time_left_for_this_task=30,
        # per_run_time_limit=30,
        # n_jobs=8,
    )
    # perform the search
    model.fit(X_train, y_train)
    # summarize
    print(model.sprint_statistics())
    # evaluate best model
    y_hat = model.predict(X_test)
    acc = accuracy_score(y_test, y_hat)
    print("Accuracy: %.3f" % acc)

    model_path = Path("./catanatron/players/estimator.pickle").resolve()
    with open(model_path, "wb") as f:
        pickle.dump(model, f)


def plot_metrics(history):
    metrics = ["loss", "auc", "precision", "recall"]
    for n, metric in enumerate(metrics):
        name = metric.replace("_", " ").capitalize()
        plt.subplot(2, 2, n + 1)
        plt.plot(history.epoch, history.history[metric], color=colors[0], label="Train")
        plt.plot(
            history.epoch,
            history.history["val_" + metric],
            color=colors[0],
            linestyle="--",
            label="Val",
        )
        plt.xlabel("Epoch")
        plt.ylabel(name)
        if metric == "loss":
            plt.ylim([0, plt.ylim()[1]])
        elif metric == "auc":
            plt.ylim([0.8, 1])
        else:
            plt.ylim([0, 1])

        plt.legend()

--- catanatron_experimental/catanatron_experimental/machine_learning/utils.py ---
import os

import numpy as np

from catanatron.state import player_key
from catanatron_experimental.utils import ensure_dir

DISCOUNT_FACTOR = 0.99
DATA_DIRECTORY = "data"


def get_samples_path(games_directory):
    return os.path.join(games_directory, "samples.csv.gzip")


def get_board_tensors_path(games_directory):
    return os.path.join(games_directory, "board_tensors.csv.gzip")


def get_actions_path(games_directory):
    return os.path.join(games_directory, "actions.csv.gzip")


def get_rewards_path(games_directory):
    return os.path.join(games_directory, "rewards.csv.gzip")


def get_main_path(games_directory):
    return os.path.join(games_directory, "main.csv.gzip")


def get_matrices_path(games_directory):
    samples_path = get_samples_path(games_directory)
    board_tensors_path = get_board_tensors_path(games_directory)
    actions_path = get_actions_path(games_directory)
    rewards_path = get_rewards_path(games_directory)
    main_path = get_main_path(games_directory)
    return samples_path, board_tensors_path, actions_path, rewards_path, main_path


def get_games_directory(key=None, version=None):
    if key in set(["V", "P", "Q"]):
        return os.path.join(DATA_DIRECTORY, key, str(version))
    else:
        return os.path.join(DATA_DIRECTORY, "random_games")


def estimate_num_samples(games_directory):
    samples_path = get_samples_path(games_directory)
    file_size = os.path.getsize(samples_path)
    size_per_sample_estimate = 3906.25  # in bytes
    estimate = file_size // size_per_sample_estimate
    print(
        "Training via generator. File Size:",
        file_size,
        "Num Samples Estimate:",
        estimate,
    )
    return estimate


def generate_arrays_from_file(
    games_directory,
    batchsize,
    label_column,
    learning="Q",
    label_threshold=None,
):
    inputs = []
    targets = []
    batchcount = 0

    (
        samples_path,
        board_tensors_path,
        actions_path,
        rewards_path,
        main_path,
    ) = get_matrices_path(games_directory)
    while True:
        with open(samples_path) as s, open(actions_path) as a, open(rewards_path) as r:
            next(s)  # skip header
            next(a)  # skip header
            rewards_header = next(r)  # skip header
            label_index = rewards_header.rstrip().split(",").index(label_column)
            for i, sline in enumerate(s):
                try:
                    srecord = sline.rstrip().split(",")
                    arecord = a.readline().rstrip().split(",")
                    rrecord = r.readline().rstrip().split(",")

                    state = [float(n) for n in srecord[:]]
                    action = [float(n) for n in arecord[:]]
                    reward = float(rrecord[label_index])
                    if label_threshold is not None and reward < label_threshold:
                        continue

                    if learning == "Q":
                        sample = state + action
                        label = reward
                    elif learning == "V":
                        sample = state
                        label = reward
                    else:  # learning == "P"
                        sample = state
                        label = action

                    inputs.append(sample)
                    targets.append(label)
                    batchcount += 1
                except Exception as e:
                    print(i)
                    print(s)
                    print(e)
                if batchcount > batchsize:
                    X = np.array(inputs, dtype="float32")
                    y = np.array(targets, dtype="float32")
                    yield (X, y)
                    inputs = []
                    targets = []
                    batchcount = 0


def get_discounted_return(game, p0_color, discount_factor):
    """G_t = d**1*r_1 + d**2*r_2 + ... + d**T*r_T.

    Taking r_i = 0 for all i < T. And r_T = 1 if wins
    """
    assert discount_factor <= 1
    episode_return = p0_color == game.winning_color()
    return episode_return * discount_factor**game.state.num_turns


def get_tournament_return(game, p0_color, discount_factor):
    """A way to say winning is important, no matter how long it takes, and
    getting close to winning is a secondary metric"""
    episode_return = p0_color == game.winning_color()
    key = player_key(game.state, p0_color)
    points = game.state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"]
    episode_return = episode_return * 1000 + min(points, 10)
    return episode_return * discount_factor**game.state.num_turns


def get_victory_points_return(game, p0_color):
    # This discount factor (0.9999) ensures a game won in less turns
    #   is better, and still a Game with 9vps is less than 10vps,
    #   no matter turns.
    key = player_key(game.state, p0_color)
    points = game.state.player_state[f"{key}_ACTUAL_VICTORY_POINTS"]
    episode_return = min(points, 10)
    return episode_return * 0.9999**game.state.num_turns


def populate_matrices(
    samples_df, board_tensors_df, actions_df, rewards_df, main_df, games_directory
):
    (
        samples_path,
        board_tensors_path,
        actions_path,
        rewards_path,
        main_path,
    ) = get_matrices_path(games_directory)

    ensure_dir(games_directory)

    is_first_training = not os.path.isfile(samples_path)
    samples_df.to_csv(
        samples_path,
        mode="a",
        header=is_first_training,
        index=False,
        compression="gzip",
    )
    board_tensors_df.to_csv(
        board_tensors_path,
        mode="a",
        header=is_first_training,
        index=False,
        compression="gzip",
    )
    actions_df.to_csv(
        actions_path,
        mode="a",
        header=is_first_training,
        index=False,
        compression="gzip",
    )
    rewards_df.to_csv(
        rewards_path,
        mode="a",
        header=is_first_training,
        index=False,
        compression="gzip",
    )
    main_df.to_csv(
        main_path,
        mode="a",
        header=is_first_training,
        index=False,
        compression="gzip",
    )

--- catanatron_experimental/catanatron_experimental/machine_learning/__init__.py ---

--- catanatron_experimental/catanatron_experimental/machine_learning/players/mcts.py ---
import math
import time
from collections import defaultdict

import numpy as np

from catanatron.game import Game
from catanatron.models.player import Player
from catanatron_experimental.machine_learning.players.playouts import run_playout
from catanatron_experimental.machine_learning.players.tree_search_utils import (
    execute_spectrum,
    list_prunned_actions,
)

SIMULATIONS = 10
epsilon = 1e-8
EXP_C = 2**0.5


class StateNode:
    def __init__(self, color, game, parent, prunning=False):
        self.level = 0 if parent is None else parent.level + 1
        self.color = color  # color of player carrying out MCTS
        self.parent = parent
        self.game = game  # state
        self.children = []
        self.prunning = prunning

        self.wins = 0
        self.visits = 0
        self.result = None  # set if terminal

    def run_simulation(self):
        # select
        tmp = self
        tmp.visits += 1
        while not tmp.is_leaf():
            tmp = tmp.select()
            tmp.visits += 1

        if not tmp.is_terminal():
            # expand
            tmp.expand()
            tmp = tmp.select()
            tmp.visits += 1

            # playout
            result = tmp.playout()
        else:
            result = self.game.winning_color()

        # backpropagate
        tmp.backpropagate(result == self.color)

    def is_leaf(self):
        return len(self.children) == 0

    def is_terminal(self):
        return self.game.winning_color() is not None

    def expand(self):
        children = defaultdict(list)
        playable_actions = self.game.state.playable_actions
        actions = list_prunned_actions(self.game) if self.prunning else playable_actions
        for action in actions:
            outcomes = execute_spectrum(self.game, action)
            for state, proba in outcomes:
                children[action].append(
                    (StateNode(self.color, state, self, self.prunning), proba)
                )
        self.children = children

    def select(self):
        """select a child StateNode"""
        action = self.choose_best_action()

        # Idea: Allow randomness to guide to next children too
        children = self.children[action]
        children_states = list(map(lambda c: c[0], children))
        children_probas = list(map(lambda c: c[1], children))
        return np.random.choice(children_states, 1, p=children_probas)[0]

    def choose_best_action(self):
        scores = []
        for action in self.game.state.playable_actions:
            score = self.action_children_expected_score(action)
            scores.append(score)

        idx = max(range(len(scores)), key=lambda i: scores[i])
        action = self.game.state.playable_actions[idx]
        return action

    def action_children_expected_score(self, action):
        score = 0
        for child, proba in self.children[action]:
            score += proba * (
                child.wins / (child.visits + epsilon)
                + EXP_C
                * (math.log(self.visits + epsilon) / (child.visits + epsilon)) ** 0.5
            )
        return score

    def playout(self):
        return run_playout(self.game)

    def backpropagate(self, value):
        self.wins += value

        tmp = self
        while tmp.parent is not None:
            tmp = tmp.parent

            tmp.wins += value


class MCTSPlayer(Player):
    def __init__(self, color, num_simulations=SIMULATIONS, prunning=False):
        super().__init__(color)
        self.num_simulations = int(num_simulations)
        self.prunning = bool(prunning)

    def decide(self, game: Game, playable_actions):
        # if len(game.state.actions) > 10:
        #     import sys

        #     sys.exit(1)
        actions = list_prunned_actions(game) if self.prunning else playable_actions
        if len(actions) == 1:
            return actions[0]

        start = time.time()
        root = StateNode(self.color, game.copy(), None, self.prunning)
        for _ in range(self.num_simulations):
            root.run_simulation()

        print(
            f"{str(self)} took {time.time() - start} secs to decide {len(playable_actions)}"
        )

        return root.choose_best_action()

    def __repr__(self):
        return super().__repr__() + f"({self.num_simulations}:{self.prunning})"

--- catanatron_experimental/catanatron_experimental/machine_learning/players/minimax.py ---
import time
import random
from typing import Any

from catanatron.game import Game
from catanatron.models.player import Player
from catanatron_experimental.machine_learning.players.tree_search_utils import (
    expand_spectrum,
    list_prunned_actions,
)
from catanatron_experimental.machine_learning.players.value import (
    DEFAULT_WEIGHTS,
    get_value_fn,
)


ALPHABETA_DEFAULT_DEPTH = 2
MAX_SEARCH_TIME_SECS = 20


class AlphaBetaPlayer(Player):
    """
    Player that executes an AlphaBeta Search where the value of each node
    is taken to be the expected value (using the probability of rolls, etc...)
    of its children. At leafs we simply use the heuristic function given.

    NOTE: More than 3 levels seems to take much longer, it would be
    interesting to see this with prunning.
    """

    def __init__(
        self,
        color,
        depth=ALPHABETA_DEFAULT_DEPTH,
        prunning=False,
        value_fn_builder_name=None,
        params=DEFAULT_WEIGHTS,
        epsilon=None,
    ):
        super().__init__(color)
        self.depth = int(depth)
        self.prunning = str(prunning).lower() != "false"
        self.value_fn_builder_name = (
            "contender_fn" if value_fn_builder_name == "C" else "base_fn"
        )
        self.params = params
        self.use_value_function = None
        self.epsilon = epsilon

    def value_function(self, game, p0_color):
        raise NotImplementedError

    def get_actions(self, game):
        if self.prunning:
            return list_prunned_actions(game)
        return game.state.playable_actions

    def decide(self, game: Game, playable_actions):
        actions = self.get_actions(game)
        if len(actions) == 1:
            return actions[0]

        if self.epsilon is not None and random.random() < self.epsilon:
            return random.choice(playable_actions)

        start = time.time()
        state_id = str(len(game.state.actions))
        node = DebugStateNode(state_id, self.color)  # i think it comes from outside
        deadline = start + MAX_SEARCH_TIME_SECS
        result = self.alphabeta(
            game.copy(), self.depth, float("-inf"), float("inf"), deadline, node
        )
        # print("Decision Results:", self.depth, len(actions), time.time() - start)
        # if game.state.num_turns > 10:
        #     render_debug_tree(node)
        #     breakpoint()
        if result[0] is None:
            return playable_actions[0]
        return result[0]

    def __repr__(self) -> str:
        return (
            super().__repr__()
            + f"(depth={self.depth},value_fn={self.value_fn_builder_name},prunning={self.prunning})"
        )

    def alphabeta(self, game, depth, alpha, beta, deadline, node):
        """AlphaBeta MiniMax Algorithm.

        NOTE: Sometimes returns a value, sometimes an (action, value). This is
        because some levels are state=>action, some are action=>state and in
        action=>state would probably need (action, proba, value) as return type.

        {'value', 'action'|None if leaf, 'node' }
        """
        if depth == 0 or game.winning_color() is not None or time.time() >= deadline:
            value_fn = get_value_fn(
                self.value_fn_builder_name,
                self.params,
                self.value_function if self.use_value_function else None,
            )
            value = value_fn(game, self.color)

            node.expected_value = value
            return None, value

        maximizingPlayer = game.state.current_color() == self.color
        actions = self.get_actions(game)  # list of actions.
        action_outcomes = expand_spectrum(game, actions)  # action => (game, proba)[]

        if maximizingPlayer:
            best_action = None
            best_value = float("-inf")
            for i, (action, outcomes) in enumerate(action_outcomes.items()):
                action_node = DebugActionNode(action)

                expected_value = 0
                for j, (outcome, proba) in enumerate(outcomes):
                    out_node = DebugStateNode(
                        f"{node.label} {i} {j}", outcome.state.current_color()
                    )

                    result = self.alphabeta(
                        outcome, depth - 1, alpha, beta, deadline, out_node
                    )
                    value = result[1]
                    expected_value += proba * value

                    action_node.children.append(out_node)
                    action_node.probas.append(proba)

                action_node.expected_value = expected_value
                node.children.append(action_node)

                if expected_value > best_value:
                    best_action = action
                    best_value = expected_value
                alpha = max(alpha, best_value)
                if alpha >= beta:
                    break  # beta cutoff

            node.expected_value = best_value
            return best_action, best_value
        else:
            best_action = None
            best_value = float("inf")
            for i, (action, outcomes) in enumerate(action_outcomes.items()):
                action_node = DebugActionNode(action)

                expected_value = 0
                for j, (outcome, proba) in enumerate(outcomes):
                    out_node = DebugStateNode(
                        f"{node.label} {i} {j}", outcome.state.current_color()
                    )

                    result = self.alphabeta(
                        outcome, depth - 1, alpha, beta, deadline, out_node
                    )
                    value = result[1]
                    expected_value += proba * value

                    action_node.children.append(out_node)
                    action_node.probas.append(proba)

                action_node.expected_value = expected_value
                node.children.append(action_node)

                if expected_value < best_value:
                    best_action = action
                    best_value = expected_value
                beta = min(beta, best_value)
                if beta <= alpha:
                    break  # alpha cutoff

            node.expected_value = best_value
            return best_action, best_value


class DebugStateNode:
    def __init__(self, label, color):
        self.label = label
        self.children = []  # DebugActionNode[]
        self.expected_value = None
        self.color = color


class DebugActionNode:
    def __init__(self, action):
        self.action = action
        self.expected_value: Any = None
        self.children = []  # DebugStateNode[]
        self.probas = []


def render_debug_tree(node):
    from graphviz import Digraph

    dot = Digraph("AlphaBetaSearch")

    agenda = [node]

    while len(agenda) != 0:
        tmp = agenda.pop()
        dot.node(
            tmp.label,
            label=f"<{tmp.label}<br /><font point-size='10'>{tmp.expected_value}</font>>",
            style="filled",
            fillcolor=tmp.color.value,
        )
        for child in tmp.children:
            action_label = (
                f"{tmp.label} - {str(child.action).replace('<', '').replace('>', '')}"
            )
            dot.node(
                action_label,
                label=f"<{action_label}<br /><font point-size='10'>{child.expected_value}</font>>",
                shape="box",
            )
            dot.edge(tmp.label, action_label)
            for action_child, proba in zip(child.children, child.probas):
                dot.node(
                    action_child.label,
                    label=f"<{action_child.label}<br /><font point-size='10'>{action_child.expected_value}</font>>",
                )
                dot.edge(action_label, action_child.label, label=str(proba))
                agenda.append(action_child)
    print(dot.render())


class SameTurnAlphaBetaPlayer(AlphaBetaPlayer):
    """
    Same like AlphaBeta but only within turn
    """

    def alphabeta(self, game, depth, alpha, beta, deadline, node):
        """AlphaBeta MiniMax Algorithm.

        NOTE: Sometimes returns a value, sometimes an (action, value). This is
        because some levels are state=>action, some are action=>state and in
        action=>state would probably need (action, proba, value) as return type.

        {'value', 'action'|None if leaf, 'node' }
        """
        if (
            depth == 0
            or game.state.current_color() != self.color
            or game.winning_color() is not None
            or time.time() >= deadline
        ):
            value_fn = get_value_fn(
                self.value_fn_builder_name,
                self.params,
                self.value_function if self.use_value_function else None,
            )
            value = value_fn(game, self.color)

            node.expected_value = value
            return None, value

        actions = self.get_actions(game)  # list of actions.
        action_outcomes = expand_spectrum(game, actions)  # action => (game, proba)[]

        best_action = None
        best_value = float("-inf")
        for i, (action, outcomes) in enumerate(action_outcomes.items()):
            action_node = DebugActionNode(action)

            expected_value = 0
            for j, (outcome, proba) in enumerate(outcomes):
                out_node = DebugStateNode(
                    f"{node.label} {i} {j}", outcome.state.current_color()
                )

                result = self.alphabeta(
                    outcome, depth - 1, alpha, beta, deadline, out_node
                )
                value = result[1]
                expected_value += proba * value

                action_node.children.append(out_node)
                action_node.probas.append(proba)

            action_node.expected_value = expected_value
            node.children.append(action_node)

            if expected_value > best_value:
                best_action = action
                best_value = expected_value
            alpha = max(alpha, best_value)
            if alpha >= beta:
                break  # beta cutoff

        node.expected_value = best_value
        return best_action, best_value

--- catanatron_experimental/catanatron_experimental/machine_learning/players/online_mcts_dqn.py ---
from collections import deque
from catanatron_experimental.data_logger import DataLogger
import os
import random
import time
from pathlib import Path

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import Input, Model
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Conv2D,
    Activation,
    MaxPooling2D,
    Dropout,
    Dense,
    Flatten,
)
from tensorflow.keras.layers.experimental.preprocessing import Normalization
from tensorflow.keras.optimizers import Adam

from catanatron.game import Game
from catanatron.models.player import Player
from catanatron_experimental.machine_learning.players.playouts import run_playouts
from catanatron_gym.features import (
    create_sample_vector,
    get_feature_ordering,
)
from catanatron_gym.board_tensor_features import (
    WIDTH,
    HEIGHT,
    CHANNELS,
    create_board_tensor,
)

# ===== CONFIGURATION
NUM_FEATURES = len(get_feature_ordering())
NUM_PLAYOUTS = 100
MIN_REPLAY_BUFFER_LENGTH = 100
BATCH_SIZE = 64
FLUSH_EVERY = 1  # decisions. what takes a while is to generate samples via MCTS
TRAIN = True
OVERWRITE_MODEL = False
DATA_PATH = "data/mcts-playouts-validation"
NORMALIZATION_MEAN_PATH = Path(DATA_PATH, "mean.npy")
NORMALIZATION_VARIANCE_PATH = Path(DATA_PATH, "variance.npy")

# ===== PLAYER STATE (here to allow pickle-serialization of player)
# MODEL_NAME = "online-mcts-dqn-3.0"
# MODEL_PATH = str(Path("data/models/", MODEL_NAME))
# MODEL_SINGLETON = None
DATA_LOGGER = DataLogger(DATA_PATH)


# def get_model():
#     global MODEL_SINGLETON
#     if MODEL_SINGLETON is None:
#         if os.path.isdir(MODEL_PATH):
#             MODEL_SINGLETON = tf.keras.models.load_model(MODEL_PATH)
#         else:
#             MODEL_SINGLETON = create_model()
#     return MODEL_SINGLETON


# def create_model():
#     inputs = Input(shape=(NUM_FEATURES,))
#     outputs = inputs

#     # mean = np.load(NORMALIZATION_MEAN_PATH)
#     # variance = np.load(NORMALIZATION_VARIANCE_PATH)
#     # normalizer_layer = Normalization(mean=mean, variance=variance)
#     # outputs = normalizer_layer(outputs)

#     # outputs = Dense(8, activation="relu")(outputs)

#     # TODO: We may want to change infra to predict all 4 winning probas.
#     #   So that mini-max makes more sense? Enemies wont min you, they'll max
#     #   themselves.
#     outputs = Dense(units=1, activation="linear")(outputs)
#     model = Model(inputs=inputs, outputs=outputs)
#     model.compile(loss="mse", optimizer=Adam(learning_rate=0.001), metrics=["mae"])
#     return model


class OnlineMCTSDQNPlayer(Player):
    def __init__(self, color):
        super().__init__(color)
        self.step = 0

    def decide(self, game: Game, playable_actions):
        """
        For each move, will run N playouts, get statistics, and save into replay buffer.
        Every M decisions, will:
            - flush replay buffer to disk (for offline experiments)
            - report progress on games thus far to TensorBoard (tf.summary module)
            - update model by choosing L random samples from replay buffer
                and train model. do we need stability check? i think not.
                and override model path.
        Decision V1 looks like, predict and choose the one that creates biggest
            'distance' against enemies. Actually this is the same as maximizing wins.
        Decision V2 looks the same as V1, but minimaxed some turns in the future.
        """
        if len(playable_actions) == 1:  # this avoids imbalance (if policy-learning)
            return playable_actions[0]

        start = time.time()

        # Run MCTS playouts for each possible action, save results for training.
        samples = []
        scores = []
        print(playable_actions)
        for action in playable_actions:
            print("Considering", action)
            action_applied_game_copy = game.copy()
            action_applied_game_copy.execute(action)
            sample = create_sample_vector(action_applied_game_copy, self.color)
            samples.append(sample)

            if TRAIN:
                # Save snapshots from the perspective of each player (more training!)
                counter = run_playouts(action_applied_game_copy, NUM_PLAYOUTS)
                mcts_labels = {k: v / NUM_PLAYOUTS for k, v in counter.items()}
                DATA_LOGGER.consume(action_applied_game_copy, mcts_labels)

                scores.append(mcts_labels.get(self.color, 0))

        # TODO: if M step, do all 4 things.
        if TRAIN and self.step % FLUSH_EVERY == 0:
            self.update_model_and_flush_samples()

        # scores = get_model().call(tf.convert_to_tensor(samples))
        best_idx = np.argmax(scores)
        best_action = playable_actions[best_idx]

        if TRAIN:
            print("Decision took:", time.time() - start)
        self.step += 1
        return best_action

    def update_model_and_flush_samples(self):
        """Trains using NN, and saves to disk"""
        global MIN_REPLAY_BUFFER_LENGTH, BATCH_SIZE, MODEL_PATH, OVERWRITE_MODEL

        samples, board_tensors, labels = DATA_LOGGER.get_replay_buffer()
        if len(samples) < MIN_REPLAY_BUFFER_LENGTH:
            return

        # print("Training...")
        # model = get_model()
        # model.fit(
        #     tf.convert_to_tensor(samples),
        #     tf.convert_to_tensor(labels),
        #     batch_size=BATCH_SIZE,
        #     verbose=0,
        #     shuffle=True,
        # )
        # print("DONE training")
        # if OVERWRITE_MODEL:
        #     model.save(MODEL_PATH)

        DATA_LOGGER.flush()

--- catanatron_experimental/catanatron_experimental/machine_learning/players/playouts.py ---
import time
import random
import multiprocessing
from collections import Counter

from catanatron.game import Game
from catanatron.models.player import Player

DEFAULT_NUM_PLAYOUTS = 25
USE_MULTIPROCESSING = True
NUM_WORKERS = multiprocessing.cpu_count()

PLAYOUTS_BUDGET = 100


# Single threaded NUM_PLAYOUTS=25 takes ~185.3893163204193 secs on initial placement
#   10.498431205749512 secs to do initial road (3 playable actions)
# Multithreaded, dividing the NUM_PLAYOUTS only (actions serially), takes ~52.22048330307007 secs
#   on intial placement. 4.187309980392456 secs on initial road.
# Multithreaded, on different actions
class GreedyPlayoutsPlayer(Player):
    """For each playable action, play N random playouts."""

    def __init__(self, color, num_playouts=DEFAULT_NUM_PLAYOUTS):
        super().__init__(color)
        self.num_playouts = int(num_playouts)

    def decide(self, game: Game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]

        start = time.time()
        # num_playouts = PLAYOUTS_BUDGET // len(playable_actions)
        num_playouts = self.num_playouts

        best_action = None
        max_wins = None
        for action in playable_actions:
            action_applied_game_copy = game.copy()
            action_applied_game_copy.execute(action)

            counter = run_playouts(action_applied_game_copy, num_playouts)

            wins = counter[self.color]
            if max_wins is None or wins > max_wins:
                best_action = action
                max_wins = wins

        print(
            f"Greedy took {time.time() - start} secs to decide "
            + f"{len(playable_actions)} at {num_playouts} per action"
        )
        return best_action


def run_playouts(action_applied_game_copy, num_playouts):
    start = time.time()
    params = []
    for _ in range(num_playouts):
        params.append(action_applied_game_copy)
    if USE_MULTIPROCESSING:
        with multiprocessing.Pool(NUM_WORKERS) as p:
            counter = Counter(p.map(run_playout, params))
    else:
        counter = Counter(map(run_playout, params))
    duration = time.time() - start
    # print(f"{num_playouts} playouts took: {duration}. Results: {counter}")
    return counter


def run_playout(action_applied_game_copy):
    game_copy = action_applied_game_copy.copy()
    game_copy.play(decide_fn=decide_fn)
    return game_copy.winning_color()


def decide_fn(self, game, playable_actions):
    index = random.randrange(0, len(playable_actions))
    return playable_actions[index]

--- catanatron_experimental/catanatron_experimental/machine_learning/players/reinforcement.py ---
import os

import numpy as np
import tensorflow as tf
from tensorflow import keras

from catanatron.models.player import Player
from catanatron.models.enums import Action, ActionType
from catanatron_gym.features import (
    create_sample,
    create_sample_vector,
    get_feature_ordering,
)
from catanatron_gym.envs.catanatron_env import ACTIONS_ARRAY, ACTION_SPACE_SIZE
from catanatron_gym.board_tensor_features import (
    NUMERIC_FEATURES,
    create_board_tensor,
)

# from catanatron_experimental.rep_b_model import build_model

# Taken from correlation analysis
FEATURES = [
    "P0_HAS_ROAD",
    "P1_HAS_ROAD",
    "P0_HAS_ARMY",
    "P1_HAS_ARMY",
    "P0_ORE_PRODUCTION",
    "P0_WOOD_PRODUCTION",
    "P0_WHEAT_PRODUCTION",
    "P0_SHEEP_PRODUCTION",
    "P0_BRICK_PRODUCTION",
    "P0_LONGEST_ROAD_LENGTH",
    "P1_ORE_PRODUCTION",
    "P1_WOOD_PRODUCTION",
    "P1_WHEAT_PRODUCTION",
    "P1_SHEEP_PRODUCTION",
    "P1_BRICK_PRODUCTION",
    "P1_LONGEST_ROAD_LENGTH",
    "P0_PUBLIC_VPS",
    "P1_PUBLIC_VPS",
    "P0_SETTLEMENTS_LEFT",
    "P1_SETTLEMENTS_LEFT",
    "P0_CITIES_LEFT",
    "P1_CITIES_LEFT",
    "P0_KNIGHT_PLAYED",
    "P1_KNIGHT_PLAYED",
]


def allow_feature(feature_name):
    return (
        "2_ROAD" not in feature_name
        and "HAND" not in feature_name
        and "BANK" not in feature_name
        and "P0_ACTUAL_VPS" != feature_name
        and "PLAYABLE" not in feature_name
        and "LEFT" not in feature_name
        and "ROLLED" not in feature_name
        and "PLAYED" not in feature_name
        and "PUBLIC_VPS" not in feature_name
        and not ("TOTAL" in feature_name and "P1" in feature_name)
        and not ("EFFECTIVE" in feature_name and "P0" in feature_name)
        and (feature_name[-6:] != "PLAYED" or "KNIGHT" in feature_name)
    )


ALL_FEATURES = get_feature_ordering(num_players=2)
FEATURES = list(filter(allow_feature, ALL_FEATURES))
FEATURES = get_feature_ordering(2)
FEATURE_INDICES = [ALL_FEATURES.index(f) for f in FEATURES]

EPSILON = 0.20  # for epsilon-greedy action selection
# singleton for model. lazy-initialize to easy dependency graph and stored
#   here instead of class attribute to skip saving model in CatanatronDB.
P_MODEL = None
Q_MODEL = None
V_MODEL = None
T_MODEL = None


def v_model_path(version):
    return os.path.join(os.path.dirname(__file__), "v_models", str(version))


def q_model_path(version):
    return os.path.join(os.path.dirname(__file__), "q_models", str(version))


def p_model_path(version):
    return os.path.join(os.path.dirname(__file__), "p_models", str(version))


def get_v_model(model_path):
    global V_MODEL
    if V_MODEL is None:
        custom_objects = None if model_path[:2] != "ak" else ak.CUSTOM_OBJECTS
        V_MODEL = keras.models.load_model(model_path, custom_objects=custom_objects)
    return V_MODEL


def get_t_model(model_path):
    global T_MODEL
    if T_MODEL is None:
        T_MODEL = keras.models.load_model(model_path)
        # T_MODEL = build_model()
    return T_MODEL


def hot_one_encode_action(action):
    normalized = normalize_action(action)
    index = ACTIONS_ARRAY.index((normalized.action_type, normalized.value))
    vector = np.zeros(ACTION_SPACE_SIZE, dtype=int)
    vector[index] = 1
    return vector


def normalize_action(action):
    normalized = action
    if normalized.action_type == ActionType.ROLL:
        return Action(action.color, action.action_type, None)
    elif normalized.action_type == ActionType.MOVE_ROBBER:
        return Action(action.color, action.action_type, action.value[0])
    elif normalized.action_type == ActionType.BUILD_ROAD:
        return Action(action.color, action.action_type, tuple(sorted(action.value)))
    elif normalized.action_type == ActionType.BUY_DEVELOPMENT_CARD:
        return Action(action.color, action.action_type, None)
    elif normalized.action_type == ActionType.DISCARD:
        return Action(action.color, action.action_type, None)

    return normalized


class PRLPlayer(Player):
    def __init__(self, color, model_path):
        super(PRLPlayer, self).__init__(color)
        global P_MODEL
        P_MODEL = keras.models.load_model(model_path)

    def decide(self, game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]
        # epsilon-greedy: with EPSILON probability play at random.
        # if random.random() < EPSILON:
        #     print("DOING EPSILON GUESS")
        #     index = random.randrange(0, len(playable_actions))
        #     return playable_actions[index]

        # Create array like [0,0,1,0,0,0,1,...] representing possible actions
        normalized_playable = [normalize_action(a) for a in playable_actions]
        possibilities = [(a.action_type, a.value) for a in normalized_playable]
        possible_indices = [ACTIONS_ARRAY.index(x) for x in possibilities]
        mask = np.zeros(ACTION_SPACE_SIZE, dtype=np.int)
        mask[possible_indices] = 1

        # possibilities = [(a.action_type, a.value) for a in playable_actions]
        # possible_indices = [ACTIONS_ARRAY.index(x) for x in possibilities]
        # mask = np.zeros(ACTION_SPACE_SIZE, dtype=int)
        # mask[possible_indices] = 1

        # Get action probabilities with neural network.
        X = [create_sample_vector(game, self.color, FEATURES)]
        result = P_MODEL.call(tf.convert_to_tensor(X))

        # Multiply mask with output, and take max.
        clipped_probabilities = np.multiply(mask, result[0])
        action_index = np.argmax(clipped_probabilities)
        playable_actions_index = possibilities.index(ACTIONS_ARRAY[action_index])
        return playable_actions[playable_actions_index]


class QRLPlayer(Player):
    def __init__(self, color, model_path):
        super(QRLPlayer, self).__init__(color)
        self.model_path = model_path
        global Q_MODEL
        Q_MODEL = keras.models.load_model(model_path)

    def decide(self, game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]
        # epsilon-greedy: with EPSILON probability play at random.
        # if random.random() < EPSILON:
        #     index = random.randrange(0, len(playable_actions))
        #     return playable_actions[index]

        # Create sample matrix of state + action vectors.
        state = create_sample_vector(game, self.color, FEATURES)
        samples = []
        for action in playable_actions:
            samples.append(np.concatenate((state, hot_one_encode_action(action))))
        X = np.array(samples)

        # Predict on all samples
        result = Q_MODEL.predict(X)
        index = np.argmax(result)
        return playable_actions[index]


# Incremental Value Function Approximation
# Play game, take reward G (discounted by num turns), then for each
#   state S (sample): change params by delta_w = alpha * (G - v(S)) grad_w(S)
class VRLPlayer(Player):
    def __init__(self, color, model_path):
        super(VRLPlayer, self).__init__(color)
        self.model_path = model_path

    def decide(self, game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]
        # epsilon-greedy: with EPSILON probability play at random.
        # if random.random() < EPSILON:
        #     index = random.randrange(0, len(playable_actions))
        #     return playable_actions[index]

        # Make copy of each action, and take one that takes to most value.
        samples = []
        for action in playable_actions:
            game_copy = game.copy()
            game_copy.execute(action)

            sample = create_sample(game_copy, self.color)
            state = [float(sample[i]) for i in FEATURES]
            samples.append(state)

        scores = get_v_model(self.model_path).call(tf.convert_to_tensor(samples))

        # We do this instead of np.argmax(scores), because often all have same
        #   value, at which point we want random instead of first (end turn).
        best_score = np.max(scores)
        max_indices = np.where(scores == best_score)
        best_idx = np.random.choice(max_indices[0])

        # pprint(list(zip(FEATURES, get_v_model(self.model_path).get_weights()[-2])))
        # pprint(list(zip(playable_actions, scores)))
        # breakpoint()
        return playable_actions[best_idx]

    def __repr__(self):
        return super(VRLPlayer, self).__repr__() + f"({self.model_path})"


class TensorRLPlayer(Player):
    def __init__(self, color, model_path):
        super(TensorRLPlayer, self).__init__(color)
        self.model_path = model_path

    def decide(self, game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]

        # epsilon-greedy: with EPSILON probability play at random.
        # if random.random() < EPSILON:
        #     index = random.randrange(0, len(playable_actions))
        #     return playable_actions[index]

        # Make copy of each action, and take one that takes to most value.
        inputs1 = []
        inputs2 = []
        for action in playable_actions:
            game_copy = game.copy()
            game_copy.execute(action)

            board_tensor = create_board_tensor(game_copy, self.color)
            inputs1.append(board_tensor)

            sample = create_sample(game_copy, self.color)
            input2 = [float(sample[i]) for i in NUMERIC_FEATURES]
            inputs2.append(input2)

        scores = get_t_model(self.model_path).call(
            [tf.convert_to_tensor(inputs1), tf.convert_to_tensor(inputs2)]
        )
        best_idx = np.argmax(scores)
        # breakpoint()
        return playable_actions[best_idx]

    def __repr__(self):
        return super(TensorRLPlayer, self).__repr__() + f"({self.model_path})"

--- catanatron_experimental/catanatron_experimental/machine_learning/players/tree_search_utils.py ---
import math
from collections import defaultdict

from catanatron.models.map import number_probability
from catanatron.models.enums import (
    DEVELOPMENT_CARDS,
    RESOURCES,
    SETTLEMENT,
    CITY,
    Action,
    ActionType,
)

from catanatron.state_functions import (
    get_player_buildings,
    get_dev_cards_in_hand,
    get_player_freqdeck,
    get_enemy_colors,
)
from catanatron_gym.features import (
    build_production_features,
)
from catanatron_experimental.machine_learning.players.value import value_production

DETERMINISTIC_ACTIONS = set(
    [
        ActionType.END_TURN,
        ActionType.BUILD_SETTLEMENT,
        ActionType.BUILD_ROAD,
        ActionType.BUILD_CITY,
        ActionType.PLAY_KNIGHT_CARD,
        ActionType.PLAY_YEAR_OF_PLENTY,
        ActionType.PLAY_ROAD_BUILDING,
        ActionType.MARITIME_TRADE,
        ActionType.DISCARD,  # for simplicity... ok if reality is slightly different
        ActionType.PLAY_MONOPOLY,  # for simplicity... we assume good card-counting and bank is visible...
    ]
)


def execute_deterministic(game, action):
    copy = game.copy()
    copy.execute(action, validate_action=False)
    return [(copy, 1)]


def execute_spectrum(game, action):
    """Returns [(game_copy, proba), ...] tuples for result of given action.
    Result probas should add up to 1. Does not modify self"""
    if action.action_type in DETERMINISTIC_ACTIONS:
        return execute_deterministic(game, action)
    elif action.action_type == ActionType.BUY_DEVELOPMENT_CARD:
        results = []

        # Get the possible deck from the perspective of the current player
        # by getting all face down cards
        current_deck = game.state.development_listdeck.copy()
        for color in get_enemy_colors(game.state.colors, action.color):
            for card in DEVELOPMENT_CARDS:
                number = get_dev_cards_in_hand(game.state, color, card)
                current_deck += [card] * number

        for card in set(current_deck):
            option_action = Action(action.color, action.action_type, card)
            option_game = game.copy()
            try:
                option_game.execute(option_action, validate_action=False)
            except Exception:
                # ignore exceptions, since player might imagine impossible outcomes.
                # ignoring means the value function of this node will be flattened,
                # to the one before.
                pass
            results.append((option_game, current_deck.count(card) / len(current_deck)))
        return results
    elif action.action_type == ActionType.ROLL:
        results = []
        for roll in range(2, 13):
            outcome = (roll // 2, math.ceil(roll / 2))

            option_action = Action(action.color, action.action_type, outcome)
            option_game = game.copy()
            option_game.execute(option_action, validate_action=False)
            results.append((option_game, number_probability(roll)))
        return results
    elif action.action_type == ActionType.MOVE_ROBBER:
        (coordinate, robbed_color, _) = action.value
        if robbed_color is None:  # no one to steal, then deterministic
            return execute_deterministic(game, action)

        results = []
        opponent_hand = get_player_freqdeck(game.state, robbed_color)
        opponent_hand_size = sum(opponent_hand)
        if opponent_hand_size == 0:
            # Nothing to steal
            return execute_deterministic(game, action)

        for card in RESOURCES:
            option_action = Action(
                action.color,
                action.action_type,
                (coordinate, robbed_color, card),
            )
            option_game = game.copy()
            try:
                option_game.execute(option_action, validate_action=False)
            except Exception:
                # ignore exceptions, since player might imagine impossible outcomes.
                # ignoring means the value function of this node will be flattened,
                # to the one before.
                pass
            results.append((option_game, 1 / 5.0))
        return results
    else:
        raise RuntimeError("Unknown ActionType " + str(action.action_type))


def expand_spectrum(game, actions):
    """Consumes game if playable_actions not specified"""
    children = defaultdict(list)
    for action in actions:
        outprobas = execute_spectrum(game, action)
        children[action] = outprobas
    return children  # action => (game, proba)[]


def list_prunned_actions(game):
    current_color = game.state.current_color()
    playable_actions = game.state.playable_actions
    actions = playable_actions.copy()
    types = set(map(lambda a: a.action_type, playable_actions))

    # Prune Initial Settlements at 1-tile places
    if ActionType.BUILD_SETTLEMENT in types and game.state.is_initial_build_phase:
        actions = filter(
            lambda a: len(game.state.board.map.adjacent_tiles[a.value]) != 1, actions
        )

    # Prune Trading if can hold for resources. Only for rare resources.
    if ActionType.MARITIME_TRADE in types:
        port_resources = game.state.board.get_player_port_resources(current_color)
        has_three_to_one = None in port_resources
        # TODO: for 2:1 ports, skip any 3:1 or 4:1 trades
        # TODO: if can_safely_hold, prune all
        tmp_actions = []
        for action in actions:
            if action.action_type != ActionType.MARITIME_TRADE:
                tmp_actions.append(action)
                continue
            # has 3:1, skip any 4:1 trades
            if has_three_to_one and action.value[3] is not None:
                continue
            tmp_actions.append(action)
        actions = tmp_actions

    if ActionType.MOVE_ROBBER in types:
        actions = prune_robber_actions(current_color, game, actions)

    return list(actions)


def prune_robber_actions(current_color, game, actions):
    """Eliminate all but the most impactful tile"""
    enemy_color = next(filter(lambda c: c != current_color, game.state.colors))
    enemy_owned_tiles = set()
    for node_id in get_player_buildings(game.state, enemy_color, SETTLEMENT):
        enemy_owned_tiles.update(game.state.board.map.adjacent_tiles[node_id])
    for node_id in get_player_buildings(game.state, enemy_color, CITY):
        enemy_owned_tiles.update(game.state.board.map.adjacent_tiles[node_id])

    robber_moves = set(
        filter(
            lambda a: a.action_type == ActionType.MOVE_ROBBER
            and game.state.board.map.tiles[a.value[0]] in enemy_owned_tiles,
            actions,
        )
    )

    production_features = build_production_features(True)

    def impact(action):
        game_copy = game.copy()
        game_copy.execute(action)

        our_production_sample = production_features(game_copy, current_color)
        enemy_production_sample = production_features(game_copy, current_color)
        production = value_production(our_production_sample, "P0")
        enemy_production = value_production(enemy_production_sample, "P1")

        return enemy_production - production

    most_impactful_robber_action = max(
        robber_moves, key=impact
    )  # most production and variety producing
    actions = filter(
        lambda a: a.action_type != ActionType.MOVE_ROBBER
        or a == most_impactful_robber_action,
        # lambda a: a.action_type != ActionType.MOVE_ROBBER or a in robber_moves,
        actions,
    )
    return actions

--- catanatron_experimental/catanatron_experimental/machine_learning/players/value.py ---
import random

from catanatron.state_functions import (
    get_longest_road_length,
    get_played_dev_cards,
    player_key,
    player_num_dev_cards,
    player_num_resource_cards,
)
from catanatron.models.player import Player
from catanatron.models.enums import RESOURCES, SETTLEMENT, CITY
from catanatron_gym.features import (
    build_production_features,
    reachability_features,
    resource_hand_features,
)

TRANSLATE_VARIETY = 4  # i.e. each new resource is like 4 production points

DEFAULT_WEIGHTS = {
    # Where to place. Note winning is best at all costs
    "public_vps": 3e14,
    "production": 1e8,
    "enemy_production": -1e8,
    "num_tiles": 1,
    # Towards where to expand and when
    "reachable_production_0": 0,
    "reachable_production_1": 1e4,
    "buildable_nodes": 1e3,
    "longest_road": 10,
    # Hand, when to hold and when to use.
    "hand_synergy": 1e2,
    "hand_resources": 1,
    "discard_penalty": -5,
    "hand_devs": 10,
    "army_size": 10.1,
}

# Change these to play around with new values
CONTENDER_WEIGHTS = {
    "public_vps": 300000000000001.94,
    "production": 100000002.04188395,
    "enemy_production": -99999998.03389844,
    "num_tiles": 2.91440418,
    "reachable_production_0": 2.03820085,
    "reachable_production_1": 10002.018773150001,
    "buildable_nodes": 1001.86278466,
    "longest_road": 12.127388499999999,
    "hand_synergy": 102.40606877,
    "hand_resources": 2.43644327,
    "discard_penalty": -3.00141993,
    "hand_devs": 10.721669799999999,
    "army_size": 12.93844622,
}


def base_fn(params=DEFAULT_WEIGHTS):
    def fn(game, p0_color):
        production_features = build_production_features(True)
        our_production_sample = production_features(game, p0_color)
        enemy_production_sample = production_features(game, p0_color)
        production = value_production(our_production_sample, "P0")
        enemy_production = value_production(enemy_production_sample, "P1", False)

        key = player_key(game.state, p0_color)
        longest_road_length = get_longest_road_length(game.state, p0_color)

        reachability_sample = reachability_features(game, p0_color, 2)
        features = [f"P0_0_ROAD_REACHABLE_{resource}" for resource in RESOURCES]
        reachable_production_at_zero = sum([reachability_sample[f] for f in features])
        features = [f"P0_1_ROAD_REACHABLE_{resource}" for resource in RESOURCES]
        reachable_production_at_one = sum([reachability_sample[f] for f in features])

        hand_sample = resource_hand_features(game, p0_color)
        features = [f"P0_{resource}_IN_HAND" for resource in RESOURCES]
        distance_to_city = (
            max(2 - hand_sample["P0_WHEAT_IN_HAND"], 0)
            + max(3 - hand_sample["P0_ORE_IN_HAND"], 0)
        ) / 5.0  # 0 means good. 1 means bad.
        distance_to_settlement = (
            max(1 - hand_sample["P0_WHEAT_IN_HAND"], 0)
            + max(1 - hand_sample["P0_SHEEP_IN_HAND"], 0)
            + max(1 - hand_sample["P0_BRICK_IN_HAND"], 0)
            + max(1 - hand_sample["P0_WOOD_IN_HAND"], 0)
        ) / 4.0  # 0 means good. 1 means bad.
        hand_synergy = (2 - distance_to_city - distance_to_settlement) / 2

        num_in_hand = player_num_resource_cards(game.state, p0_color)
        discard_penalty = params["discard_penalty"] if num_in_hand > 7 else 0

        # blockability
        buildings = game.state.buildings_by_color[p0_color]
        owned_nodes = buildings[SETTLEMENT] + buildings[CITY]
        owned_tiles = set()
        for n in owned_nodes:
            owned_tiles.update(game.state.board.map.adjacent_tiles[n])
        num_tiles = len(owned_tiles)

        # TODO: Simplify to linear(?)
        num_buildable_nodes = len(game.state.board.buildable_node_ids(p0_color))
        longest_road_factor = (
            params["longest_road"] if num_buildable_nodes == 0 else 0.1
        )

        return float(
            game.state.player_state[f"{key}_VICTORY_POINTS"] * params["public_vps"]
            + production * params["production"]
            + enemy_production * params["enemy_production"]
            + reachable_production_at_zero * params["reachable_production_0"]
            + reachable_production_at_one * params["reachable_production_1"]
            + hand_synergy * params["hand_synergy"]
            + num_buildable_nodes * params["buildable_nodes"]
            + num_tiles * params["num_tiles"]
            + num_in_hand * params["hand_resources"]
            + discard_penalty
            + longest_road_length * longest_road_factor
            + player_num_dev_cards(game.state, p0_color) * params["hand_devs"]
            + get_played_dev_cards(game.state, p0_color, "KNIGHT") * params["army_size"]
        )

    return fn


def value_production(sample, player_name="P0", include_variety=True):
    proba_point = 2.778 / 100
    features = [
        f"EFFECTIVE_{player_name}_WHEAT_PRODUCTION",
        f"EFFECTIVE_{player_name}_ORE_PRODUCTION",
        f"EFFECTIVE_{player_name}_SHEEP_PRODUCTION",
        f"EFFECTIVE_{player_name}_WOOD_PRODUCTION",
        f"EFFECTIVE_{player_name}_BRICK_PRODUCTION",
    ]
    prod_sum = sum([sample[f] for f in features])
    prod_variety = (
        sum([sample[f] != 0 for f in features]) * TRANSLATE_VARIETY * proba_point
    )
    return prod_sum + (0 if not include_variety else prod_variety)


def contender_fn(params):
    return base_fn(params or CONTENDER_WEIGHTS)


class ValueFunctionPlayer(Player):
    """
    Player that selects the move that maximizes a heuristic value function.

    For now, the base value function only considers 1 enemy player.
    """

    def __init__(
        self, color, value_fn_builder_name=None, params=None, is_bot=True, epsilon=None
    ):
        super().__init__(color, is_bot)
        self.value_fn_builder_name = (
            "contender_fn" if value_fn_builder_name == "C" else "base_fn"
        )
        self.params = params
        self.epsilon = epsilon

    def decide(self, game, playable_actions):
        if len(playable_actions) == 1:
            return playable_actions[0]

        if self.epsilon is not None and random.random() < self.epsilon:
            return random.choice(playable_actions)

        best_value = float("-inf")
        best_action = None
        for action in playable_actions:
            game_copy = game.copy()
            game_copy.execute(action)

            value_fn = get_value_fn(self.value_fn_builder_name, self.params)
            value = value_fn(game_copy, self.color)
            if value > best_value:
                best_value = value
                best_action = action

        return best_action

    def __str__(self):
        return super().__str__() + f"(value_fn={self.value_fn_builder_name})"


def get_value_fn(name, params, value_function=None):
    if value_function is not None:
        return value_function
    elif name == "base_fn":
        return base_fn(DEFAULT_WEIGHTS)
    elif name == "contender_fn":
        return contender_fn(params)
    else:
        raise ValueError

--- catanatron_experimental/catanatron_experimental.egg-info/dependency_links.txt ---


--- catanatron_experimental/catanatron_experimental.egg-info/entry_points.txt ---
[console_scripts]
catanatron-play = catanatron_experimental.play:simulate

--- catanatron_experimental/catanatron_experimental.egg-info/PKG-INFO ---
Metadata-Version: 2.1
Name: catanatron_experimental
Version: 1.0.0
Summary: Experimental scripts
Home-page: https://github.com/bcollazo/catanatron
Author: Bryan Collazo
Author-email: bcollazo2010@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Requires-Dist: rich

--- catanatron_experimental/catanatron_experimental.egg-info/requires.txt ---
rich

--- catanatron_experimental/catanatron_experimental.egg-info/SOURCES.txt ---
setup.py
catanatron_experimental/__init__.py
catanatron_experimental/data_logger.py
catanatron_experimental/mcts_score_collector.py
catanatron_experimental/my_player.py
catanatron_experimental/optunation.py
catanatron_experimental/play.py
catanatron_experimental/rayopt.py
catanatron_experimental/rllibtest.py
catanatron_experimental/spsa.py
catanatron_experimental/utils.py
catanatron_experimental.egg-info/PKG-INFO
catanatron_experimental.egg-info/SOURCES.txt
catanatron_experimental.egg-info/dependency_links.txt
catanatron_experimental.egg-info/entry_points.txt
catanatron_experimental.egg-info/requires.txt
catanatron_experimental.egg-info/top_level.txt
catanatron_experimental/machine_learning/__init__.py
catanatron_experimental/machine_learning/plot.py
catanatron_experimental/machine_learning/utils.py
--- catanatron_experimental/catanatron_experimental.egg-info/top_level.txt ---
catanatron_experimental

--- catanatron_gym/catanatron_gym/board_tensor_features.py ---
import networkx as nx
import numpy as np

from catanatron.state_functions import get_player_buildings
from catanatron.models.player import Color
from catanatron.game import Game
from catanatron.models.enums import (
    RESOURCES,
    SETTLEMENT,
    CITY,
    ROAD,
)
from catanatron.models.coordinate_system import offset_to_cube
from catanatron.models.board import STATIC_GRAPH
from catanatron.models.map import number_probability
from catanatron_gym.features import get_feature_ordering, iter_players

# These assume 4 players
WIDTH = 21
HEIGHT = 11
# CHANNELS = 16  # 4 color multiplier, 5 resource probas, 1 robber, 6 port
# CHANNELS = 9  # 4 color multiplier, 5 resource probas
# CHANNELS = 13  # 8 color multiplier, 5 resource probas
CHANNELS = 20  # 8 color multiplier, 5 resource probas, 1 robber, 6 port


def get_channels(num_players):
    return num_players * 2 + 5 + 1 + 6


NODE_ID_MAP = None
EDGE_MAP = None
TILE_COORDINATE_MAP = None


def is_graph_feature(feature_name):
    return (
        feature_name.startswith("TILE")
        or feature_name.startswith("PORT")
        or feature_name.startswith("NODE")
        or feature_name.startswith("EDGE")
    )


def get_numeric_features(num_players):
    features = get_feature_ordering(num_players)
    return [f for f in features if not is_graph_feature(f)]


NUMERIC_FEATURES = get_numeric_features(4)
NUM_NUMERIC_FEATURES = len(NUMERIC_FEATURES)


def get_node_and_edge_maps():
    global NODE_ID_MAP, EDGE_MAP
    if NODE_ID_MAP is None or EDGE_MAP is None:
        NODE_ID_MAP, EDGE_MAP = init_board_tensor_map()
    return NODE_ID_MAP, EDGE_MAP


def get_tile_coordinate_map():
    global TILE_COORDINATE_MAP
    if TILE_COORDINATE_MAP is None:
        TILE_COORDINATE_MAP = init_tile_coordinate_map()
    return TILE_COORDINATE_MAP


# Create mapping of node_id => i,j and edge => i,j. Respecting (WIDTH, HEIGHT)
def init_board_tensor_map():
    # These are node-pairs (start,end) for the lines that go from left to right
    pairs = [
        (82, 93),
        (79, 94),
        (42, 25),
        (41, 26),
        (73, 59),
        (72, 60),
    ]
    paths = [nx.shortest_path(STATIC_GRAPH, a, b) for (a, b) in pairs]

    node_map = {}
    edge_map = {}
    for i, path in enumerate(paths):
        for j, node in enumerate(path):
            node_map[node] = (2 * j, 2 * i)

            node_has_down_edge = (i + j) % 2 == 0
            if node_has_down_edge and i + 1 < len(pairs):
                next_path = paths[i + 1]
                edge_map[(node, next_path[j])] = (2 * j, 2 * i + 1)
                edge_map[(next_path[j], node)] = (
                    2 * j,
                    2 * i + 1,
                )

            if j + 1 < len(path):
                edge_map[(node, path[j + 1])] = (2 * j + 1, 2 * i)
                edge_map[(path[j + 1], node)] = (2 * j + 1, 2 * i)

    return node_map, edge_map


def init_tile_coordinate_map():
    """Creates a tile (x,y,z) => i,j mapping,
    where i,j is top-left of 3x6 matrix and respect (WIDTH, HEIGHT) ordering
    """
    tile_map = {}

    width_step = 4  # its really 5, but tiles overlap a column
    height_step = 2  # same here, height is 3, but they overlap a row
    for i in range(HEIGHT // height_step):
        for j in range(WIDTH // width_step):  # +1 b.c. width includes 1/2 water
            (offset_x, offset_y) = (-2 + j, -2 + i)
            cube_coordinate = offset_to_cube((offset_x, offset_y))

            maybe_odd_offset = (i % 2) * 2
            tile_map[cube_coordinate] = (
                height_step * i,
                width_step * j + maybe_odd_offset,
            )
    return tile_map


def create_board_tensor(game: Game, p0_color: Color, channels_first=False):
    """Creates a tensor of shape (WIDTH=21, HEIGHT=11, CHANNELS).

    1 x n hot-encoded planes (2 and 1s for city/settlements).
    1 x n planes for the roads built by each player.
    5 tile resources planes, one per resource.
    1 robber plane (to note nodes blocked by robber).
    6 port planes (one for each resource and one for the 3:1 ports)

    Example:
        - To see WHEAT plane: tf.transpose(board_tensor[:,:,3])
    """
    # add n hot-encoded color multiplier planes (nodes), and n edge planes. 2*n planes
    n = len(game.state.colors)
    channels = 2 * n + 5 + 1 + 6
    planes = [
        [[0.0 for i in range(HEIGHT)] for j in range(WIDTH)] for _ in range(channels)
    ]
    node_map, edge_map = get_node_and_edge_maps()
    for i, color in iter_players(tuple(game.state.colors), p0_color):
        for node_id in get_player_buildings(game.state, color, SETTLEMENT):
            indices = node_map[node_id]
            planes[2 * i][indices[0]][indices[1]] = 1.0
        for node_id in get_player_buildings(game.state, color, CITY):
            indices = node_map[node_id]
            planes[2 * i][indices[0]][indices[1]] = 2.0

        for edge in get_player_buildings(game.state, color, ROAD):
            indices = edge_map[edge]
            planes[2 * i + 1][indices[0]][indices[1]] = 1.0

    # set 5 node-resource probas
    resources = [i for i in RESOURCES]
    tile_map = get_tile_coordinate_map()
    for coordinate, tile in game.state.board.map.land_tiles.items():
        if tile.resource is None:
            continue  # there is already a 3x5 zeros matrix there (everything started as a 0!).

        # Tile looks like:
        # [0.33, 0, 0.33, 0, 0.33]
        # [   0, 0,    0, 0,    0]
        # [0.33, 0, 0.33, 0, 0.33]
        proba = 0 if tile.number is None else number_probability(tile.number)
        (y, x) = tile_map[coordinate]  # returns values in (row, column) math def
        channel_idx = 2 * n + resources.index(tile.resource)
        planes[channel_idx][x][y] += proba
        planes[channel_idx][x + 2][y] += proba
        planes[channel_idx][x + 4][y] += proba
        planes[channel_idx][x][y + 2] += proba
        planes[channel_idx][x + 2][y + 2] += proba
        planes[channel_idx][x + 4][y + 2] += proba

    # set 1 robber channel
    (y, x) = tile_map[game.state.board.robber_coordinate]
    planes[2 * n + 5][x][y] = 1
    planes[2 * n + 5][x + 2][y] = 1
    planes[2 * n + 5][x + 4][y] = 1
    planes[2 * n + 5][x][y + 2] = 1
    planes[2 * n + 5][x + 2][y + 2] = 1
    planes[2 * n + 5][x + 4][y + 2] = 1

    # Q: Would this be simpler as boolean features for each player?
    # add 6 port channels (5 resources + 1 for 3:1 ports)
    # for each port, take index and take node_id coordinates
    for resource, node_ids in game.state.board.map.port_nodes.items():
        channel_idx_delta = 5 if resource is None else resources.index(resource)
        channel_idx = 2 * n + 5 + 1 + channel_idx_delta
        for node_id in node_ids:
            (x, y) = node_map[node_id]
            planes[channel_idx][x][y] = 1

    result = np.array(planes)
    if not channels_first:
        return np.transpose(result, (1, 2, 0))
    return result

--- catanatron_gym/catanatron_gym/features.py ---
from typing import Any, List, Literal, Tuple
import functools
from collections import Counter
from catanatron.models.decks import freqdeck_count

import networkx as nx

from catanatron.state_functions import (
    get_player_buildings,
    player_key,
    player_num_dev_cards,
    player_num_resource_cards,
)
from catanatron.models.board import STATIC_GRAPH, get_edges, get_node_distances
from catanatron.models.map import NUM_TILES, CatanMap, build_map
from catanatron.models.player import Color, SimplePlayer
from catanatron.models.enums import (
    DEVELOPMENT_CARDS,
    RESOURCES,
    SETTLEMENT,
    CITY,
    ROAD,
    ActionType,
    VICTORY_POINT,
)
from catanatron.game import Game
from catanatron.models.map import number_probability


# ===== Helpers
def is_building(game, node_id, color, building_type):
    building = game.state.board.buildings.get(node_id, None)
    if building is None:
        return False
    else:
        return building[0] == color and building[1] == building_type


def is_road(game, edge, color):
    return game.state.board.get_edge_color(edge) == color


@functools.lru_cache(1024)
def iter_players(colors: Tuple[Color], p0_color: Color):
    """Iterator: for i, player in iter_players(game, p0.color)"""
    start_index = colors.index(p0_color)
    result = []
    for i in range(len(colors)):
        actual_index = (start_index + i) % len(colors)
        result.append((i, colors[actual_index]))
    return result


# ===== Extractors
def player_features(game: Game, p0_color: Color):
    # P0_ACTUAL_VPS
    # P{i}_PUBLIC_VPS, P1_PUBLIC_VPS, ...
    # P{i}_HAS_ARMY, P{i}_HAS_ROAD, P1_HAS_ARMY, ...
    # P{i}_ROADS_LEFT, P{i}_SETTLEMENTS_LEFT, P{i}_CITIES_LEFT, P1_...
    # P{i}_HAS_ROLLED, P{i}_LONGEST_ROAD_LENGTH
    features = dict()
    for i, color in iter_players(game.state.colors, p0_color):
        key = player_key(game.state, color)
        if color == p0_color:
            features["P0_ACTUAL_VPS"] = game.state.player_state[
                key + "_ACTUAL_VICTORY_POINTS"
            ]

        features[f"P{i}_PUBLIC_VPS"] = game.state.player_state[key + "_VICTORY_POINTS"]
        features[f"P{i}_HAS_ARMY"] = game.state.player_state[key + "_HAS_ARMY"]
        features[f"P{i}_HAS_ROAD"] = game.state.player_state[key + "_HAS_ROAD"]
        features[f"P{i}_ROADS_LEFT"] = game.state.player_state[key + "_ROADS_AVAILABLE"]
        features[f"P{i}_SETTLEMENTS_LEFT"] = game.state.player_state[
            key + "_SETTLEMENTS_AVAILABLE"
        ]
        features[f"P{i}_CITIES_LEFT"] = game.state.player_state[
            key + "_CITIES_AVAILABLE"
        ]
        features[f"P{i}_HAS_ROLLED"] = game.state.player_state[key + "_HAS_ROLLED"]
        features[f"P{i}_LONGEST_ROAD_LENGTH"] = game.state.player_state[
            key + "_LONGEST_ROAD_LENGTH"
        ]

    return features


def resource_hand_features(game: Game, p0_color: Color):
    # P0_WHEATS_IN_HAND, P0_WOODS_IN_HAND, ...
    # P0_ROAD_BUILDINGS_IN_HAND, P0_KNIGHT_IN_HAND, ..., P0_VPS_IN_HAND
    # P0_ROAD_BUILDINGS_PLAYABLE, P0_KNIGHT_PLAYABLE, ...
    # P0_ROAD_BUILDINGS_PLAYED, P0_KNIGHT_PLAYED, ...

    # P1_ROAD_BUILDINGS_PLAYED, P1_KNIGHT_PLAYED, ...
    # TODO: P1_WHEATS_INFERENCE, P1_WOODS_INFERENCE, ...
    # TODO: P1_ROAD_BUILDINGS_INFERENCE, P1_KNIGHT_INFERENCE, ...

    state = game.state
    player_state = state.player_state

    features = {}
    for i, color in iter_players(game.state.colors, p0_color):
        key = player_key(game.state, color)

        if color == p0_color:
            for resource in RESOURCES:
                features[f"P0_{resource}_IN_HAND"] = player_state[
                    key + f"_{resource}_IN_HAND"
                ]
            for card in DEVELOPMENT_CARDS:
                features[f"P0_{card}_IN_HAND"] = player_state[key + f"_{card}_IN_HAND"]
            features[f"P0_HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN"] = player_state[
                key + "_HAS_PLAYED_DEVELOPMENT_CARD_IN_TURN"
            ]

        for card in DEVELOPMENT_CARDS:
            if card == VICTORY_POINT:
                continue  # cant play VPs
            features[f"P{i}_{card}_PLAYED"] = player_state[key + f"_PLAYED_{card}"]

        features[f"P{i}_NUM_RESOURCES_IN_HAND"] = player_num_resource_cards(
            state, color
        )
        features[f"P{i}_NUM_DEVS_IN_HAND"] = player_num_dev_cards(state, color)

    return features


@functools.lru_cache(NUM_TILES * 2)  # one for each robber, and acount for Minimap
def map_tile_features(catan_map: CatanMap, robber_coordinate):
    # Returns list of functions that take a game and output a feature.
    # build features like tile0_is_wood, tile0_is_wheat, ..., tile0_proba, tile0_hasrobber
    features = {}

    for tile_id, tile in catan_map.tiles_by_id.items():
        for resource in RESOURCES:
            features[f"TILE{tile_id}_IS_{resource}"] = tile.resource == resource
        features[f"TILE{tile_id}_IS_DESERT"] = tile.resource == None
        features[f"TILE{tile_id}_PROBA"] = (
            0 if tile.resource is None else number_probability(tile.number)
        )
        features[f"TILE{tile_id}_HAS_ROBBER"] = (
            catan_map.tiles[robber_coordinate] == tile
        )
    return features


def tile_features(game: Game, p0_color: Color):
    # Returns list of functions that take a game and output a feature.
    # build features like tile0_is_wood, tile0_is_wheat, ..., tile0_proba, tile0_hasrobber
    return map_tile_features(game.state.board.map, game.state.board.robber_coordinate)


@functools.lru_cache(1)
def map_port_features(catan_map):
    features = {}
    for port_id, port in catan_map.ports_by_id.items():
        for resource in RESOURCES:
            features[f"PORT{port_id}_IS_{resource}"] = port.resource == resource
        features[f"PORT{port_id}_IS_THREE_TO_ONE"] = port.resource is None
    return features


def port_features(game, p0_color):
    # PORT0_WOOD, PORT0_THREE_TO_ONE, ...
    return map_port_features(game.state.board.map)


@functools.lru_cache(4)
def initialize_graph_features_template(num_players, catan_map: CatanMap):
    features = {}
    for i in range(num_players):
        for node_id in range(len(catan_map.land_nodes)):
            for building in [SETTLEMENT, CITY]:
                features[f"NODE{node_id}_P{i}_{building}"] = False
        for edge in get_edges(catan_map.land_nodes):
            features[f"EDGE{edge}_P{i}_ROAD"] = False
    return features


@functools.lru_cache(1024 * 2 * 2 * 2)
def get_node_hot_encoded(player_index, colors, settlements, cities, roads):
    features = {}

    for node_id in settlements:
        features[f"NODE{node_id}_P{player_index}_SETTLEMENT"] = True
    for node_id in cities:
        features[f"NODE{node_id}_P{player_index}_CITY"] = True
    for edge in roads:
        features[f"EDGE{tuple(sorted(edge))}_P{player_index}_ROAD"] = True

    return features


def graph_features(game: Game, p0_color: Color):
    features = initialize_graph_features_template(
        len(game.state.colors), game.state.board.map
    ).copy()

    for i, color in iter_players(game.state.colors, p0_color):
        settlements = tuple(game.state.buildings_by_color[color][SETTLEMENT])
        cities = tuple(game.state.buildings_by_color[color][CITY])
        roads = tuple(game.state.buildings_by_color[color][ROAD])
        to_update = get_node_hot_encoded(
            i, game.state.colors, settlements, cities, roads
        )
        features.update(to_update)

    return features


def build_production_features(consider_robber):
    prefix = "EFFECTIVE_" if consider_robber else "TOTAL_"

    def production_features(game: Game, p0_color: Color):
        # P0_WHEAT_PRODUCTION, P0_ORE_PRODUCTION, ..., P1_WHEAT_PRODUCTION, ...
        features = {}
        board = game.state.board
        robbed_nodes = set(board.map.tiles[board.robber_coordinate].nodes.values())
        for resource in RESOURCES:
            for i, color in iter_players(game.state.colors, p0_color):
                production = 0
                for node_id in get_player_buildings(game.state, color, SETTLEMENT):
                    if consider_robber and node_id in robbed_nodes:
                        continue
                    production += get_node_production(
                        game.state.board.map, node_id, resource
                    )
                for node_id in get_player_buildings(game.state, color, CITY):
                    if consider_robber and node_id in robbed_nodes:
                        continue
                    production += 2 * get_node_production(
                        game.state.board.map, node_id, resource
                    )
                features[f"{prefix}P{i}_{resource}_PRODUCTION"] = production

        return features

    return production_features


@functools.lru_cache(maxsize=1000)
def get_node_production(catan_map, node_id, resource):
    tiles = catan_map.adjacent_tiles[node_id]
    return sum([number_probability(t.number) for t in tiles if t.resource == resource])


def get_player_expandable_nodes(game: Game, color: Color):
    node_sets = game.state.board.find_connected_components(color)
    enemy_colors = [
        enemy_color for enemy_color in game.state.colors if enemy_color != color
    ]
    enemy_node_ids = set()
    for enemy_color in enemy_colors:
        enemy_node_ids.update(get_player_buildings(game.state, enemy_color, SETTLEMENT))
        enemy_node_ids.update(get_player_buildings(game.state, enemy_color, CITY))

    expandable_node_ids = [
        node_id
        for node_set in node_sets
        for node_id in node_set
        if node_id not in enemy_node_ids  # not plowed
    ]  # not exactly "buildable_node_ids" b.c. we could expand from non-buildable nodes
    return expandable_node_ids


REACHABLE_FEATURES_MAX = 2  # inclusive


def get_zero_nodes(game, color):
    zero_nodes = set()
    for component in game.state.board.connected_components[color]:
        for node_id in component:
            zero_nodes.add(node_id)
    return zero_nodes


@functools.lru_cache(maxsize=2000)
def iter_level_nodes(enemy_nodes, enemy_roads, num_roads, zero_nodes):
    """Iterates over possible expansion paths.

    Args:
        enemy_nodes (frozenset[NodeId]): node_ids owned by enemy colors
        enemy_roads (frozenset[EdgeId]): edge_ids owned by enemy colors
        num_roads (int): Max-depth of BFS (inclusive). e.g. 2 will yield
            possible expansions with up to 2 roads.
        zero_nodes (frozenset[NodeId]): Nodes reachable per board.connected_components

    Yields:
        Tuple[int, Set[NodeId], Dict[NodeId, List[EdgeId]]:
            First element is level (roads needed to get there).
            Second element is set of node_ids reachable at this level.
            Third is mapping of NodeId to the list of edges
            that leads to shortest path to that NodeId.
    """
    last_layer_nodes = zero_nodes
    paths = {i: [] for i in zero_nodes}
    results = []
    for level in range(1, num_roads + 1):
        level_nodes = set(last_layer_nodes)
        for node_id in last_layer_nodes:
            if node_id in enemy_nodes:
                continue  # not expandable.

            # here we can assume node is empty or owned
            expandable = []
            for neighbor_id in STATIC_GRAPH.neighbors(node_id):
                edge = (node_id, neighbor_id)
                can_follow_edge = edge not in enemy_roads
                if can_follow_edge:
                    expandable.append(neighbor_id)
                    if neighbor_id not in paths:
                        paths[neighbor_id] = paths[node_id] + [(node_id, neighbor_id)]

            level_nodes.update(expandable)

        results.append((level, level_nodes, paths))

        last_layer_nodes = level_nodes

    return results


def get_owned_or_buildable(game, color, board_buildable):
    return frozenset(
        get_player_buildings(game.state, color, SETTLEMENT)
        + get_player_buildings(game.state, color, CITY)
        + board_buildable
    )


def reachability_features(game: Game, p0_color: Color, levels=REACHABLE_FEATURES_MAX):
    features = {}

    board_buildable = game.state.board.buildable_node_ids(p0_color, True)
    for i, color in iter_players(game.state.colors, p0_color):
        owned_or_buildable = get_owned_or_buildable(game, color, board_buildable)

        # do layer 0
        zero_nodes = get_zero_nodes(game, color)
        production = count_production(
            frozenset(owned_or_buildable.intersection(zero_nodes)),
            game.state.board.map,
        )
        for resource in RESOURCES:
            features[f"P{i}_0_ROAD_REACHABLE_{resource}"] = production[resource]

        # do rest of layers
        enemy_nodes = frozenset(
            k
            for k, v in game.state.board.buildings.items()
            if v is not None and v[0] != color
        )
        enemy_roads = frozenset(
            k for k, v in game.state.board.roads.items() if v is not None and v != color
        )
        for level, level_nodes, paths in iter_level_nodes(
            enemy_nodes, enemy_roads, levels, frozenset(zero_nodes)
        ):
            production = count_production(
                frozenset(owned_or_buildable.intersection(level_nodes)),
                game.state.board.map,
            )
            for resource in RESOURCES:
                features[f"P{i}_{level}_ROAD_REACHABLE_{resource}"] = production[
                    resource
                ]

    return features


@functools.lru_cache(maxsize=1000)
def count_production(nodes, catan_map):
    production = Counter()
    for node_id in nodes:
        production += catan_map.node_production[node_id]
    return production


def expansion_features(game: Game, p0_color: Color):
    MAX_EXPANSION_DISTANCE = 3  # exclusive

    features = {}

    # For each connected component node, bfs_edges (skipping enemy edges and nodes nodes)
    empty_edges = set(get_edges(game.state.board.map.land_nodes))
    for i, color in iter_players(game.state.colors, p0_color):
        empty_edges.difference_update(get_player_buildings(game.state, color, ROAD))
    searchable_subgraph = STATIC_GRAPH.edge_subgraph(empty_edges)

    board_buildable_node_ids = game.state.board.buildable_node_ids(
        p0_color, True
    )  # this should be the same for all players. TODO: Can maintain internally (instead of re-compute).

    for i, color in iter_players(game.state.colors, p0_color):
        expandable_node_ids = get_player_expandable_nodes(game, color)

        def skip_blocked_by_enemy(neighbor_ids):
            for node_id in neighbor_ids:
                node_color = game.state.board.get_node_color(node_id)
                if node_color is None or node_color == color:
                    yield node_id  # not owned by enemy, can explore

        # owned_edges = get_player_buildings(state, color, ROAD)
        dis_res_prod = {
            distance: {k: 0 for k in RESOURCES}
            for distance in range(MAX_EXPANSION_DISTANCE)
        }
        for node_id in expandable_node_ids:
            if node_id in board_buildable_node_ids:  # node itself is buildable
                for resource in RESOURCES:
                    production = get_node_production(
                        game.state.board.map, node_id, resource
                    )
                    dis_res_prod[0][resource] = max(
                        production, dis_res_prod[0][resource]
                    )

            if node_id not in searchable_subgraph.nodes():
                continue  # must be internal node, no need to explore

            bfs_iteration = nx.bfs_edges(
                searchable_subgraph,
                node_id,
                depth_limit=MAX_EXPANSION_DISTANCE - 1,
                sort_neighbors=skip_blocked_by_enemy,
            )

            paths = {node_id: []}
            for edge in bfs_iteration:
                a, b = edge
                path_until_now = paths[a]
                distance = len(path_until_now) + 1
                paths[b] = paths[a] + [b]

                if b not in board_buildable_node_ids:
                    continue

                # means we can get to node b, at distance=d, starting from path[0]
                for resource in RESOURCES:
                    production = get_node_production(game.state.board.map, b, resource)
                    dis_res_prod[distance][resource] = max(
                        production, dis_res_prod[distance][resource]
                    )

        for distance, res_prod in dis_res_prod.items():
            for resource, prod in res_prod.items():
                features[f"P{i}_{resource}_AT_DISTANCE_{int(distance)}"] = prod

    return features


def port_distance_features(game: Game, p0_color: Color):
    # P0_HAS_WHEAT_PORT, P0_WHEAT_PORT_DISTANCE, ..., P1_HAS_WHEAT_PORT,
    features = {}
    ports = game.state.board.map.port_nodes
    distances = get_node_distances()
    resources_and_none: List[Any] = RESOURCES.copy()
    resources_and_none += [None]
    for resource_or_none in resources_and_none:
        port_name = resource_or_none or "3:1"
        for i, color in iter_players(game.state.colors, p0_color):
            expandable_node_ids = get_player_expandable_nodes(game, color)
            if len(expandable_node_ids) == 0:
                features[f"P{i}_HAS_{port_name}_PORT"] = False
                features[f"P{i}_{port_name}_PORT_DISTANCE"] = float("inf")
            else:
                min_distance = min(
                    [
                        distances[port_node_id][my_node]
                        for my_node in expandable_node_ids
                        for port_node_id in ports[resource_or_none]
                    ]
                )
                features[f"P{i}_HAS_{port_name}_PORT"] = min_distance == 0
                features[f"P{i}_{port_name}_PORT_DISTANCE"] = min_distance
    return features


def game_features(game: Game, p0_color: Color):
    # BANK_WOODS, BANK_WHEATS, ..., BANK_DEV_CARDS
    possibilities = set([a.action_type for a in game.state.playable_actions])
    features = {
        "BANK_DEV_CARDS": len(game.state.development_listdeck),
        "IS_MOVING_ROBBER": ActionType.MOVE_ROBBER in possibilities,
        "IS_DISCARDING": ActionType.DISCARD in possibilities,
    }
    for resource in RESOURCES:
        features[f"BANK_{resource}"] = freqdeck_count(
            game.state.resource_freqdeck, resource
        )
    return features


feature_extractors = [
    # PLAYER FEATURES =====
    player_features,
    resource_hand_features,
    # TRANSFERABLE BOARD FEATURES =====
    # build_production_features(True),
    # build_production_features(False),
    # expansion_features,
    # reachability_features,
    # RAW BASE-MAP FEATURES =====
    tile_features,
    port_features,
    graph_features,
    # GAME FEATURES =====
    game_features,
]


# TODO: Use OrderedDict instead? To minimize mis-aligned features errors.
def create_sample(game, p0_color):
    record = {}
    for extractor in feature_extractors:
        record.update(extractor(game, p0_color))
    return record


def create_sample_vector(game, p0_color, features=None):
    features = features or get_feature_ordering(len(game.state.colors))
    sample_dict = create_sample(game, p0_color)
    return [float(sample_dict[i]) for i in features if i in sample_dict]


@functools.lru_cache(4 * 3)
def get_feature_ordering(
    num_players=4, map_type: Literal["BASE", "MINI", "TOURNAMENT"] = "BASE"
):
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    players = players[:num_players]
    game = Game(players, catan_map=build_map(map_type))
    sample = create_sample(game, players[0].color)
    return sorted(sample.keys())

--- catanatron_gym/catanatron_gym/__init__.py ---
from gymnasium.envs.registration import register

register(
    id="catanatron-v1",
    entry_point="catanatron_gym.envs:CatanatronEnv",
)

--- catanatron_gym/catanatron_gym/envs/catanatron_env.py ---
import gymnasium as gym
from gymnasium import spaces
import numpy as np

from catanatron.game import Game, TURNS_LIMIT
from catanatron.models.player import Color, Player, RandomPlayer
from catanatron.models.map import BASE_MAP_TEMPLATE, NUM_NODES, LandTile, build_map
from catanatron.models.enums import RESOURCES, Action, ActionType
from catanatron.models.board import get_edges
from catanatron_gym.features import (
    create_sample,
    get_feature_ordering,
)
from catanatron_gym.board_tensor_features import (
    create_board_tensor,
    get_channels,
    is_graph_feature,
)


BASE_TOPOLOGY = BASE_MAP_TEMPLATE.topology
TILE_COORDINATES = [x for x, y in BASE_TOPOLOGY.items() if y == LandTile]
ACTIONS_ARRAY = [
    (ActionType.ROLL, None),
    # TODO: One for each tile (and abuse 1v1 setting).
    *[(ActionType.MOVE_ROBBER, tile) for tile in TILE_COORDINATES],
    (ActionType.DISCARD, None),
    *[(ActionType.BUILD_ROAD, tuple(sorted(edge))) for edge in get_edges()],
    *[(ActionType.BUILD_SETTLEMENT, node_id) for node_id in range(NUM_NODES)],
    *[(ActionType.BUILD_CITY, node_id) for node_id in range(NUM_NODES)],
    (ActionType.BUY_DEVELOPMENT_CARD, None),
    (ActionType.PLAY_KNIGHT_CARD, None),
    *[
        (ActionType.PLAY_YEAR_OF_PLENTY, (first_card, RESOURCES[j]))
        for i, first_card in enumerate(RESOURCES)
        for j in range(i, len(RESOURCES))
    ],
    *[(ActionType.PLAY_YEAR_OF_PLENTY, (first_card,)) for first_card in RESOURCES],
    (ActionType.PLAY_ROAD_BUILDING, None),
    *[(ActionType.PLAY_MONOPOLY, r) for r in RESOURCES],
    # 4:1 with bank
    *[
        (ActionType.MARITIME_TRADE, tuple(4 * [i] + [j]))
        for i in RESOURCES
        for j in RESOURCES
        if i != j
    ],
    # 3:1 with port
    *[
        (ActionType.MARITIME_TRADE, tuple(3 * [i] + [None, j]))  # type: ignore
        for i in RESOURCES
        for j in RESOURCES
        if i != j
    ],
    # 2:1 with port
    *[
        (ActionType.MARITIME_TRADE, tuple(2 * [i] + [None, None, j]))  # type: ignore
        for i in RESOURCES
        for j in RESOURCES
        if i != j
    ],
    (ActionType.END_TURN, None),
]
ACTION_SPACE_SIZE = len(ACTIONS_ARRAY)
ACTION_TYPES = [i for i in ActionType]


def to_action_type_space(action):
    return ACTION_TYPES.index(action.action_type)


def normalize_action(action):
    normalized = action
    if normalized.action_type == ActionType.ROLL:
        return Action(action.color, action.action_type, None)
    elif normalized.action_type == ActionType.MOVE_ROBBER:
        return Action(action.color, action.action_type, action.value[0])
    elif normalized.action_type == ActionType.BUILD_ROAD:
        return Action(action.color, action.action_type, tuple(sorted(action.value)))
    elif normalized.action_type == ActionType.BUY_DEVELOPMENT_CARD:
        return Action(action.color, action.action_type, None)
    elif normalized.action_type == ActionType.DISCARD:
        return Action(action.color, action.action_type, None)
    return normalized


def to_action_space(action):
    """maps action to space_action equivalent integer"""
    normalized = normalize_action(action)
    return ACTIONS_ARRAY.index((normalized.action_type, normalized.value))


def from_action_space(action_int, playable_actions):
    """maps action_int to catantron.models.actions.Action"""
    # Get "catan_action" based on space action.
    # i.e. Take first action in playable that matches ACTIONS_ARRAY blueprint
    (action_type, value) = ACTIONS_ARRAY[action_int]
    catan_action = None
    for action in playable_actions:
        normalized = normalize_action(action)
        if normalized.action_type == action_type and normalized.value == value:
            catan_action = action
            break  # return the first one
    assert catan_action is not None
    return catan_action


FEATURES = get_feature_ordering(num_players=2)
NUM_FEATURES = len(FEATURES)

# Highest features is NUM_RESOURCES_IN_HAND which in theory is all resource cards
HIGH = 19 * 5


def simple_reward(game, p0_color):
    winning_color = game.winning_color()
    if p0_color == winning_color:
        return 1
    elif winning_color is None:
        return 0
    else:
        return -1


class CatanatronEnv(gym.Env):
    metadata = {"render_modes": []}

    action_space = spaces.Discrete(ACTION_SPACE_SIZE)
    # TODO: This could be smaller (there are many binary features). float b.c. TILE0_PROBA
    observation_space = spaces.Box(low=0, high=HIGH, shape=(NUM_FEATURES,), dtype=float)
    reward_range = (-1, 1)

    def __init__(self, config=None):
        self.config = config or dict()
        self.invalid_action_reward = self.config.get("invalid_action_reward", -1)
        self.reward_function = self.config.get("reward_function", simple_reward)
        self.map_type = self.config.get("map_type", "BASE")
        self.vps_to_win = self.config.get("vps_to_win", 10)
        self.enemies = self.config.get("enemies", [RandomPlayer(Color.RED)])
        self.representation = self.config.get("representation", "vector")

        assert all(p.color != Color.BLUE for p in self.enemies)
        assert self.representation in ["mixed", "vector"]
        self.p0 = Player(Color.BLUE)
        self.players = [self.p0] + self.enemies  # type: ignore
        self.representation = "mixed" if self.representation == "mixed" else "vector"
        self.features = get_feature_ordering(len(self.players), self.map_type)
        self.invalid_actions_count = 0
        self.max_invalid_actions = 10

        # TODO: Make self.action_space smaller if possible (per map_type)
        # self.action_space = spaces.Discrete(ACTION_SPACE_SIZE)

        if self.representation == "mixed":
            channels = get_channels(len(self.players))
            board_tensor_space = spaces.Box(
                low=0, high=1, shape=(channels, 21, 11), dtype=float
            )
            self.numeric_features = [
                f for f in self.features if not is_graph_feature(f)
            ]
            numeric_space = spaces.Box(
                low=0, high=HIGH, shape=(len(self.numeric_features),), dtype=float
            )
            mixed = spaces.Dict(
                {
                    "board": board_tensor_space,
                    "numeric": numeric_space,
                }
            )
            self.observation_space = mixed
        else:
            self.observation_space = spaces.Box(
                low=0, high=HIGH, shape=(len(self.features),), dtype=float
            )

        self.reset()

    def get_valid_actions(self):
        """
        Returns:
            List[int]: valid actions
        """
        return list(map(to_action_space, self.game.state.playable_actions))

    def step(self, action):
        try:
            catan_action = from_action_space(action, self.game.state.playable_actions)
        except Exception as e:
            self.invalid_actions_count += 1

            observation = self._get_observation()
            winning_color = self.game.winning_color()
            done = (
                winning_color is not None
                or self.invalid_actions_count > self.max_invalid_actions
            )
            terminated = winning_color is not None
            truncated = (
                self.invalid_actions_count > self.max_invalid_actions
                or self.game.state.num_turns >= TURNS_LIMIT
            )
            info = dict(valid_actions=self.get_valid_actions())
            return observation, self.invalid_action_reward, terminated, truncated, info

        self.game.execute(catan_action)
        self._advance_until_p0_decision()

        observation = self._get_observation()
        info = dict(valid_actions=self.get_valid_actions())

        winning_color = self.game.winning_color()
        terminated = winning_color is not None
        truncated = self.game.state.num_turns >= TURNS_LIMIT
        reward = self.reward_function(self.game, self.p0.color)

        return observation, reward, terminated, truncated, info

    def reset(
        self,
        seed=None,
        options=None,
    ):
        super().reset(seed=seed)

        catan_map = build_map(self.map_type)
        for player in self.players:
            player.reset_state()
        self.game = Game(
            players=self.players,
            seed=seed,
            catan_map=catan_map,
            vps_to_win=self.vps_to_win,
        )
        self.invalid_actions_count = 0

        self._advance_until_p0_decision()

        observation = self._get_observation()
        info = dict(valid_actions=self.get_valid_actions())

        return observation, info

    def _get_observation(self):
        sample = create_sample(self.game, self.p0.color)
        if self.representation == "mixed":
            board_tensor = create_board_tensor(
                self.game, self.p0.color, channels_first=True
            )
            numeric = np.array([float(sample[i]) for i in self.numeric_features])
            return {"board": board_tensor, "numeric": numeric}

        return np.array([float(sample[i]) for i in self.features])

    def _advance_until_p0_decision(self):
        while (
            self.game.winning_color() is None
            and self.game.state.current_color() != self.p0.color
        ):
            self.game.play_tick()  # will play bot


CatanatronEnv.__doc__ = f"""
1v1 environment against a random player

Attributes:
    reward_range: -1 if player lost, 1 if player won, 0 otherwise.
    action_space: Integers from the [0, 289] interval. 
        See Action Space table below.
    observation_space: Numeric Feature Vector. See Observation Space table 
        below for quantities. They appear in vector in alphabetical order,
        from the perspective of "current" player (hiding/showing information
        accordingly). P0 is "current" player. P1 is next in line.
        
        We use the following nomenclature for Tile ids and Node ids.
        Edge ids are self-describing (node-id, node-id) tuples. We also
        use Cube coordinates for tiles (see 
        https://www.redblobgames.com/grids/hexagons/#coordinates)

.. image:: _static/tile-ids.png
  :width: 300
  :alt: Tile Ids
.. image:: _static/node-ids.png
  :width: 300
  :alt: Node Ids

.. list-table:: Action Space
   :widths: 10 100
   :header-rows: 1

   * - Integer
     - Catanatron Action
"""
for i, v in enumerate(ACTIONS_ARRAY):
    CatanatronEnv.__doc__ += f"   * - {i}\n     - {v}\n"

CatanatronEnv.__doc__ += """

.. list-table:: Observation Space (Raw)
   :widths: 10 50 10 10
   :header-rows: 1

   * - Feature Name
     - Description
     - Number of Features (N=number of players)
     - Type

   * - BANK_<resource>
     - Number of cards of that `resource` in bank
     - 5
     - Integer
   * - BANK_DEV_CARDS
     - Number of development cards in bank
     - 1
     - Integer
    
   * - EDGE<i>_P<j>_ROAD
     - Whether edge `i` is owned by player `j`
     - 72 * N
     - Boolean
   * - NODE<i>_P<j>_SETTLEMENT
     - Whether player `j` has a city in node `i`
     - 54 * N
     - Boolean
   * - NODE<i>_P<j>_CITY
     - Whether player `j` has a city in node `i`
     - 54 * N
     - Boolean
   * - PORT<i>_IS_<resource>
     - Whether node `i` is port of `resource` (or THREE_TO_ONE).
     - 9 * 6
     - Boolean
   * - TILE<i>_HAS_ROBBER
     - Whether robber is on tile `i`.
     - 19
     - Boolean
   * - TILE<i>_IS_<resource>
     - Whether tile `i` yields `resource` (or DESERT).
     - 19 * 6
     - Boolean
   * - TILE<i>_PROBA
     - Tile `i`'s probability of being rolled.
     - 19
     - Float

   * - IS_DISCARDING
     - Whether current player must discard. For now, there is only 1 
       discarding action (at random), since otherwise action space
       would explode in size.
     - 1
     - Boolean
   * - IS_MOVING_ROBBER
     - Whether current player must move robber (because played knight
       or because rolled a 7).
     - 1
     - Boolean
   * - P<i>_HAS_ROLLED
     - Whether player `i` already rolled dice.
     - N
     - Boolean
   * - P0_HAS_PLAYED _DEVELOPMENT_CARD _IN_TURN
     - Whether current player already played a development card
     - 1
     - Boolean

   * - P0_ACTUAL_VPS
     - Total Victory Points (including Victory Point Development Cards)
     - 1
     - Integer
   * - P0_<resource>_IN_HAND
     - Number of `resource` cards in hand
     - 5
     - Integer
   * - P0_<dev-card>_IN_HAND
     - Number of `dev-card` cards in hand
     - 5
     - Integer
   * - P<i>_NUM_DEVS_IN_HAND
     - Number of hidden development cards player `i` has
     - N
     - Integer
   * - P<i>_NUM_RESOURCES _IN_HAND
     - Number of hidden resource cards player `i` has
     - N
     - Integer

   * - P<i>_HAS_ARMY
     - Whether player <i> has Largest Army
     - N
     - Boolean
   * - P<i>_HAS_ROAD
     - Whether player <i> has Longest Road
     - N
     - Boolean
   * - P<i>_ROADS_LEFT
     - Number of roads pieces player `i` has outside of board (left to build)
     - N
     - Integer
   * - P<i>_SETTLEMENTS_LEFT
     - Number of settlements player `i` has outside of board (left to build)
     - N
     - Integer
   * - P<i>_CITIES_LEFT
     - Number of cities player `i` has outside of board (left to build)
     - N
     - Integer
   * - P<i>_LONGEST_ROAD _LENGTH
     - Length of longest road by player `i`
     - N
     - Integer
   * - P<i>_PUBLIC_VPS
     - Amount of visible victory points for player `i` (i.e.
       doesn't include hidden victory point cards; only army,
       road and settlements/cities).
     - N
     - Integer
   * - P<i>_<dev-card>_PLAYED
     - Amount of `dev-card` cards player `i` has played in game
       (VICTORY_POINT not included).
     - 4 * N
     - Integer
   * - 
     - 
     - 194 * N + 226
     - 
"""

--- catanatron_gym/catanatron_gym/envs/__init__.py ---
from catanatron_gym.envs.catanatron_env import CatanatronEnv

--- catanatron_gym/catanatron_gym.egg-info/dependency_links.txt ---


--- catanatron_gym/catanatron_gym.egg-info/PKG-INFO ---
Metadata-Version: 2.1
Name: catanatron_gym
Version: 4.0.0
Summary: Open AI Gym to play 1v1 Catan against a random bot
Home-page: https://github.com/bcollazo/catanatron
Author: Bryan Collazo
Author-email: bcollazo2010@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: catanatron
Requires-Dist: gymnasium==0.29.1
Requires-Dist: numpy

# Catanatron Gym

For reinforcement learning purposes, we provide an Open AI Gym environment. To use:

```
pip install catanatron_gym
```

Make your training loop, ensuring to respect `env.get_valid_actions()`.

```python
import random
import gymnasium as gym

env = gym.make("catanatron_gym:catanatron-v1")
observation, info = env.reset()
for _ in range(1000):
  # your agent here (this takes random actions)
  action = random.choice(env.unwrapped.get_valid_actions())
  observation, reward, terminated, truncated, info = env.step(action)
  done = terminated or truncated
  if done:
      observation, info = env.reset()
env.close()
```

For `action` documentation see [here](https://catanatron.readthedocs.io/en/latest/catanatron_gym.envs.html#catanatron_gym.envs.catanatron_env.CatanatronEnv.action_space).

For `observation` documentation see [here](https://catanatron.readthedocs.io/en/latest/catanatron_gym.envs.html#catanatron_gym.envs.catanatron_env.CatanatronEnv.observation_space).

You can access `env.game.state` and build your own "observation" (features) vector as well.

## Stable-Baselines3 Example

Catanatron works well with SB3, and better with the Maskable models of the [SB3 Contrib](https://stable-baselines3.readthedocs.io/en/master/guide/sb3_contrib.html) repo. Here a small example of how it may work.

```python
import gymnasium as gym
import numpy as np
from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy
from sb3_contrib.common.wrappers import ActionMasker
from sb3_contrib.ppo_mask import MaskablePPO

def mask_fn(env) -> np.ndarray:
    valid_actions = env.get_valid_actions()
    mask = np.zeros(env.action_space.n, dtype=np.float32)
    mask[valid_actions] = 1

    return np.array([bool(i) for i in mask])


# Init Environment and Model
env = gym.make("catanatron_gym:catanatron-v1")
env = ActionMasker(env, mask_fn)  # Wrap to enable masking
model = MaskablePPO(MaskableActorCriticPolicy, env, verbose=1)

# Train
model.learn(total_timesteps=1_000_000)
```

## Configuration

You can also configure what map to use, how many vps to win, among other variables in the environment,
with the `config` keyword argument. See source for details.

```python
from catanatron import Color
from catanatron.players.weighted_random import WeightedRandomPlayer


def my_reward_function(game, p0_color):
    winning_color = game.winning_color()
    if p0_color == winning_color:
        return 100
    elif winning_color is None:
        return 0
    else:
        return -100

# 3-player catan on a "Mini" map (7 tiles) until 6 points.
env = gym.make(
    "catanatron_gym:catanatron-v1",
    config={
        "map_type": "MINI",
        "vps_to_win": 6,
        "enemies": [WeightedRandomPlayer(Color.RED), WeightedRandomPlayer(Color.ORANGE)],
        "reward_function": my_reward_function,
        "representation": "mixed",
    },
)
```

--- catanatron_gym/catanatron_gym.egg-info/requires.txt ---
catanatron
gymnasium==0.29.1
numpy

--- catanatron_gym/catanatron_gym.egg-info/SOURCES.txt ---
README.md
setup.py
catanatron_gym/__init__.py
catanatron_gym/board_tensor_features.py
catanatron_gym/features.py
catanatron_gym.egg-info/PKG-INFO
catanatron_gym.egg-info/SOURCES.txt
catanatron_gym.egg-info/dependency_links.txt
catanatron_gym.egg-info/requires.txt
catanatron_gym.egg-info/top_level.txt
catanatron_gym/envs/__init__.py
catanatron_gym/envs/catanatron_env.py
--- catanatron_gym/catanatron_gym.egg-info/top_level.txt ---
catanatron_gym

--- catanatron_server/catanatron_server/api.py ---
import json

from flask import Response, Blueprint, jsonify, abort, request

from catanatron_server.models import upsert_game_state, get_game_state
from catanatron.json import GameEncoder, action_from_json
from catanatron.models.player import Color, RandomPlayer
from catanatron.game import Game
from catanatron_experimental.machine_learning.players.value import ValueFunctionPlayer
from catanatron_experimental.machine_learning.players.minimax import AlphaBetaPlayer


bp = Blueprint("api", __name__, url_prefix="/api")


def player_factory(player_key):
    if player_key[0] == "CATANATRON":
        return AlphaBetaPlayer(player_key[1], 2, True)
    elif player_key[0] == "RANDOM":
        return RandomPlayer(player_key[1])
    elif player_key[0] == "HUMAN":
        return ValueFunctionPlayer(player_key[1], is_bot=False)
    else:
        raise ValueError("Invalid player key")


@bp.route("/games", methods=("POST",))
def post_game_endpoint():
    player_keys = request.json["players"]
    players = list(map(player_factory, zip(player_keys, Color)))

    game = Game(players=players)
    upsert_game_state(game)
    return jsonify({"game_id": game.id})


@bp.route("/games/<string:game_id>/states/<string:state_index>", methods=("GET",))
def get_game_endpoint(game_id, state_index):
    state_index = None if state_index == "latest" else int(state_index)
    game = get_game_state(game_id, state_index)
    if game is None:
        abort(404, description="Resource not found")

    return Response(
        response=json.dumps(game, cls=GameEncoder),
        status=200,
        mimetype="application/json",
    )


@bp.route("/games/<string:game_id>/actions", methods=["POST"])
def post_action_endpoint(game_id):
    game = get_game_state(game_id)
    if game is None:
        abort(404, description="Resource not found")

    if game.winning_color() is not None:
        return Response(
            response=json.dumps(game, cls=GameEncoder),
            status=200,
            mimetype="application/json",
        )

    # TODO: remove `or body_is_empty` when fully implement actions in FE
    body_is_empty = (not request.data) or request.json is None
    if game.state.current_player().is_bot or body_is_empty:
        game.play_tick()
        upsert_game_state(game)
    else:
        action = action_from_json(request.json)
        game.execute(action)
        upsert_game_state(game)

    return Response(
        response=json.dumps(game, cls=GameEncoder),
        status=200,
        mimetype="application/json",
    )


@bp.route("/stress-test", methods=["GET"])
def stress_test_endpoint():
    players = [
        AlphaBetaPlayer(Color.RED, 2, True),
        AlphaBetaPlayer(Color.BLUE, 2, True),
        AlphaBetaPlayer(Color.ORANGE, 2, True),
        AlphaBetaPlayer(Color.WHITE, 2, True),
    ]
    game = Game(players=players)
    game.play_tick()
    return Response(
        response=json.dumps(game, cls=GameEncoder),
        status=200,
        mimetype="application/json",
    )


# ===== Debugging Routes
# @app.route(
#     "/games/<string:game_id>/players/<int:player_index>/features", methods=["GET"]
# )
# def get_game_feature_vector(game_id, player_index):
#     game = get_game_state(game_id)
#     if game is None:
#         abort(404, description="Resource not found")

#     return create_sample(game, game.state.colors[player_index])


# @app.route("/games/<string:game_id>/value-function", methods=["GET"])
# def get_game_value_function(game_id):
#     game = get_game_state(game_id)
#     if game is None:
#         abort(404, description="Resource not found")

#     # model = tf.keras.models.load_model("data/models/mcts-rep-a")
#     model2 = tf.keras.models.load_model("data/models/mcts-rep-b")
#     feature_ordering = get_feature_ordering()
#     indices = [feature_ordering.index(f) for f in NUMERIC_FEATURES]
#     data = {}
#     for color in game.state.colors:
#         sample = create_sample_vector(game, color)
#         # scores = model.call(tf.convert_to_tensor([sample]))

#         inputs1 = [create_board_tensor(game, color)]
#         inputs2 = [[float(sample[i]) for i in indices]]
#         scores2 = model2.call(
#             [tf.convert_to_tensor(inputs1), tf.convert_to_tensor(inputs2)]
#         )
#         data[color.value] = float(scores2.numpy()[0][0])

#     return data

--- catanatron_server/catanatron_server/models.py ---
import os
import json
import pickle
from contextlib import contextmanager

from sqlalchemy import MetaData, Column, Integer, String, LargeBinary, create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import Session
from flask_sqlalchemy import SQLAlchemy

from catanatron.json import GameEncoder

# Using approach from: https://stackoverflow.com/questions/41004540/using-sqlalchemy-models-in-and-out-of-flask/41014157
metadata = MetaData()
Base = declarative_base(metadata=metadata)


class GameState(Base):
    __tablename__ = "game_states"

    id = Column(Integer, primary_key=True)
    uuid = Column(String(64), nullable=False)
    state_index = Column(Integer, nullable=False)
    state = Column(String, nullable=False)
    pickle_data = Column(LargeBinary, nullable=False)

    # TODO: unique uuid and state_index

    @staticmethod
    def from_game(game):
        state = json.dumps(game, cls=GameEncoder)
        pickle_data = pickle.dumps(game, pickle.HIGHEST_PROTOCOL)
        return GameState(
            uuid=game.id,
            state_index=len(game.state.actions),
            state=state,
            pickle_data=pickle_data,
        )


db = SQLAlchemy(metadata=metadata)


@contextmanager
def database_session():
    """Can use like:
    with database_session() as session:
        game_states = session.query(GameState).all()
    """
    database_url = os.environ.get(
        "DATABASE_URL",
        "postgresql://catanatron:victorypoint@127.0.0.1:5432/catanatron_db",
    )
    engine = create_engine(database_url)
    session = Session(engine)
    try:
        yield session
    finally:
        session.expunge_all()
        session.close()


def upsert_game_state(game, session_param=None):
    game_state = GameState.from_game(game)
    session = session_param or db.session
    session.add(game_state)
    session.commit()
    return game_state


def get_game_state(game_id, state_index=None):
    if state_index is None:
        result = (
            db.session.query(GameState)
            .filter_by(uuid=game_id)
            .order_by(GameState.state_index.desc())
            .first_or_404()
        )
    else:
        result = (
            db.session.query(GameState)
            .filter_by(uuid=game_id, state_index=state_index)
            .first_or_404()
        )
    db.session.commit()
    game = pickle.loads(result.pickle_data)
    return game

--- catanatron_server/catanatron_server/utils.py ---
import webbrowser

from catanatron_server.models import database_session, upsert_game_state


def ensure_link(game):
    """Upserts game to database per DATABASE_URL

    Returns:
        str: URL for inspecting state, per convention
    """
    with database_session() as session:
        game_state = upsert_game_state(game, session)
        url = f"http://localhost:3000/games/{game_state.uuid}/states/{game_state.state_index}"
    return url


def open_link(game):
    """Upserts game to database and opens game in browser"""
    link = ensure_link(game)
    webbrowser.open(link)

--- catanatron_server/catanatron_server/wsgi.py ---
from catanatron_server import create_app

app = create_app()

--- catanatron_server/catanatron_server/__init__.py ---
import os

from flask import Flask
from flask_cors import CORS


def create_app(test_config=None):
    """Create and configure an instance of the Flask application."""
    app = Flask(__name__)
    CORS(app)

    # ===== Load base configuration
    database_url = os.environ.get("DATABASE_URL", "sqlite:///:memory:")
    if database_url.startswith("postgres://"):
        database_url = database_url.replace("postgres://", "postgresql://", 1)
    secret_key = os.environ.get("SECRET_KEY", "dev")
    app.config.from_mapping(
        SECRET_KEY=secret_key,
        SQLALCHEMY_DATABASE_URI=database_url,
        SQLALCHEMY_TRACK_MODIFICATIONS=False,
    )
    if test_config is not None:
        app.config.update(test_config)

    # ===== Initialize Database
    from catanatron_server.models import db

    with app.app_context():
        db.init_app(app)
        db.create_all()

    # ===== Initialize Routes
    from . import api

    app.register_blueprint(api.bp)

    return app

--- catanatron_server/catanatron_server.egg-info/dependency_links.txt ---


--- catanatron_server/catanatron_server.egg-info/PKG-INFO ---
Metadata-Version: 2.1
Name: catanatron_server
Version: 1.0.0
Summary: Server to watch catanatron games
Home-page: https://github.com/bcollazo/catanatron
Author: Bryan Collazo
Author-email: bcollazo2010@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Requires-Dist: catanatron
Requires-Dist: flask
Requires-Dist: flask_cors
Requires-Dist: flask_sqlalchemy
Requires-Dist: sqlalchemy
Requires-Dist: psycopg2-binary

--- catanatron_server/catanatron_server.egg-info/requires.txt ---
catanatron
flask
flask_cors
flask_sqlalchemy
sqlalchemy
psycopg2-binary

--- catanatron_server/catanatron_server.egg-info/SOURCES.txt ---
setup.py
catanatron_server/__init__.py
catanatron_server/api.py
catanatron_server/models.py
catanatron_server/utils.py
catanatron_server/wsgi.py
catanatron_server.egg-info/PKG-INFO
catanatron_server.egg-info/SOURCES.txt
catanatron_server.egg-info/dependency_links.txt
catanatron_server.egg-info/requires.txt
catanatron_server.egg-info/top_level.txt
--- catanatron_server/catanatron_server.egg-info/top_level.txt ---
catanatron_server

--- tests/test_accumulators.py ---
from catanatron import ActionType, Color, RandomPlayer, Game, GameAccumulator
from catanatron.state_functions import get_actual_victory_points
from catanatron.game import TURNS_LIMIT
from catanatron_experimental import SimulationAccumulator
from catanatron_experimental.play import GameConfigOptions, play_batch_core


def test_accumulators():
    players = [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
    game = Game(players)

    class MyAccumulator(GameAccumulator):
        def __init__(self):
            self.games = []
            self.actions = []
            self.initialized = False
            self.finalized = False
            self.final_game = None

        def before(self, game):
            self.initialized = True

        def step(self, game, action):
            self.games.append(game.copy())
            self.actions.append(action)

        def after(self, game):
            self.final_game = game
            self.finalized = True

    accumulator = MyAccumulator()
    game.play(accumulators=[accumulator])

    assert accumulator.initialized
    assert len(accumulator.actions) == len(game.state.actions)
    assert accumulator.finalized

    # assert games in step() are before actions are taken
    discard_actions = [
        (i, a)
        for i, a in enumerate(game.state.actions)
        if a.action_type == ActionType.DISCARD
    ]
    for index, action in discard_actions:
        game_snapshot = accumulator.games[index]
        assert game_snapshot.state.is_discarding

    # assert someone wins
    assert accumulator.final_game is not None
    points = [
        get_actual_victory_points(accumulator.final_game.state, color)
        for color in game.state.colors
    ]
    assert (
        any([p >= 10 for p in points])
        or accumulator.final_game.state.num_turns >= TURNS_LIMIT
    )


def test_simulation_accumulator():
    class MySimAccumulator(SimulationAccumulator):
        def before_all(self):
            self.num_games = 0

        def after(self, game):
            self.num_games += 1

        def after_all(self):
            MySimAccumulator.after_all_num_games = self.num_games

    [
        i
        for i in play_batch_core(
            2,
            [RandomPlayer(Color.RED), RandomPlayer(Color.BLUE)],
            GameConfigOptions(),
            [MySimAccumulator()],
        )
    ]

    assert MySimAccumulator.after_all_num_games == 2

--- tests/test_algorithms.py ---
from catanatron.models.board import Board
from catanatron.state import (
    State,
)
from catanatron.state_functions import (
    buy_dev_card,
    get_largest_army,
    play_dev_card,
    player_deck_replenish,
)
from catanatron.models.player import SimplePlayer, Color
from catanatron.models.enums import KNIGHT, ORE, SHEEP, WHEAT


def test_longest_road_simple():
    board = Board()

    # Place initial settlements.
    board.build_settlement(Color.RED, 0, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    board.build_settlement(Color.BLUE, 24, initial_build_phase=True)
    board.build_road(Color.BLUE, (24, 25))
    board.build_settlement(Color.BLUE, 26, initial_build_phase=True)
    board.build_road(Color.BLUE, (25, 26))
    board.build_settlement(Color.RED, 2, initial_build_phase=True)
    board.build_road(Color.RED, (1, 2))
    assert board.road_color is None
    assert board.road_lengths == {Color.RED: 2, Color.BLUE: 2}

    board.build_road(Color.RED, (2, 3))
    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, (4, 5))
    assert board.road_color is Color.RED
    assert board.road_length == 5
    assert board.road_lengths == {Color.RED: 5, Color.BLUE: 2}


def test_longest_road_tie():
    board = Board()
    # Place initial settlements.
    board.build_settlement(Color.RED, 0, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    board.build_settlement(Color.BLUE, 24, initial_build_phase=True)
    board.build_road(Color.BLUE, (24, 25))
    board.build_settlement(Color.BLUE, 26, initial_build_phase=True)
    board.build_road(Color.BLUE, (25, 26))
    board.build_settlement(Color.RED, 2, initial_build_phase=True)
    board.build_road(Color.RED, (1, 2))
    assert board.road_color is None
    assert board.road_lengths == {Color.RED: 2, Color.BLUE: 2}

    board.build_road(Color.RED, (2, 3))
    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, (4, 5))

    board.build_road(Color.BLUE, (26, 27))
    board.build_road(Color.BLUE, (27, 28))
    board.build_road(Color.BLUE, (28, 29))
    assert (
        board.road_color is Color.RED
    )  # even if blue also has 5-road. red had it first
    assert board.road_length == 5
    assert board.road_lengths == {Color.RED: 5, Color.BLUE: 5}

    board.build_road(Color.BLUE, (29, 30))
    assert board.road_color is Color.BLUE
    assert board.road_length == 6
    assert board.road_lengths == {Color.RED: 5, Color.BLUE: 6}


# test: complicated circle around
def test_complicated_road():  # classic 8-like roads
    board = Board()

    # Place initial settlements.
    board.build_settlement(Color.RED, 0, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    board.build_settlement(Color.BLUE, 24, initial_build_phase=True)
    board.build_road(Color.BLUE, (24, 25))
    board.build_settlement(Color.BLUE, 26, initial_build_phase=True)
    board.build_road(Color.BLUE, (25, 26))
    board.build_settlement(Color.RED, 2, initial_build_phase=True)
    board.build_road(Color.RED, (1, 2))

    board.build_road(Color.RED, (2, 3))
    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, (4, 5))
    board.build_road(Color.RED, (0, 5))

    board.build_road(Color.RED, (1, 6))
    board.build_road(Color.RED, (6, 7))
    board.build_road(Color.RED, (7, 8))
    board.build_road(Color.RED, (8, 9))
    board.build_road(Color.RED, (2, 9))

    assert board.road_color is Color.RED
    assert board.road_length == 11
    assert board.road_lengths == {Color.RED: 11, Color.BLUE: 2}

    board.build_road(Color.RED, (8, 27))
    assert board.road_color is Color.RED
    assert board.road_length == 11
    assert board.road_lengths == {Color.RED: 11, Color.BLUE: 2}


def test_triple_longest_road_tie():
    board = Board()

    board.build_settlement(Color.RED, 3, True)
    board.build_road(Color.RED, (3, 2))
    board.build_road(Color.RED, (2, 1))
    board.build_road(Color.RED, (1, 0))
    board.build_road(Color.RED, (0, 5))
    board.build_road(Color.RED, (5, 4))
    board.build_road(Color.RED, (3, 4))

    board.build_settlement(Color.BLUE, 24, True)
    board.build_road(Color.BLUE, (24, 25))
    board.build_road(Color.BLUE, (25, 26))
    board.build_road(Color.BLUE, (26, 27))
    board.build_road(Color.BLUE, (27, 8))
    board.build_road(Color.BLUE, (8, 7))
    board.build_road(Color.BLUE, (7, 24))

    board.build_settlement(Color.WHITE, 17, True)
    board.build_road(Color.WHITE, (18, 17))
    board.build_road(Color.WHITE, (17, 39))
    board.build_road(Color.WHITE, (39, 41))
    board.build_road(Color.WHITE, (41, 42))
    board.build_road(Color.WHITE, (42, 40))
    board.build_road(Color.WHITE, (40, 18))

    assert board.road_color is Color.RED
    assert board.road_length == 6
    assert board.road_lengths == {Color.RED: 6, Color.BLUE: 6, Color.WHITE: 6}


def test_largest_army_calculation_when_no_one_has_three():
    red = SimplePlayer(Color.RED)
    blue = SimplePlayer(Color.BLUE)
    white = SimplePlayer(Color.WHITE)
    state = State([red, blue, white])

    player_deck_replenish(state, Color.RED, WHEAT, 2)
    player_deck_replenish(state, Color.RED, SHEEP, 2)
    player_deck_replenish(state, Color.RED, ORE, 2)
    player_deck_replenish(state, Color.BLUE, WHEAT, 1)
    player_deck_replenish(state, Color.BLUE, SHEEP, 1)
    player_deck_replenish(state, Color.BLUE, ORE, 1)
    buy_dev_card(state, Color.RED, KNIGHT)
    buy_dev_card(state, Color.RED, KNIGHT)
    buy_dev_card(state, Color.BLUE, KNIGHT)

    play_dev_card(state, Color.RED, KNIGHT)

    color, count = get_largest_army(state)
    assert color is None and count is None


def test_largest_army_calculation_on_tie():
    red = SimplePlayer(Color.RED)
    blue = SimplePlayer(Color.BLUE)
    white = SimplePlayer(Color.WHITE)
    state = State([red, blue, white])

    player_deck_replenish(state, red.color, KNIGHT, 3)
    player_deck_replenish(state, blue.color, KNIGHT, 4)
    play_dev_card(state, Color.RED, KNIGHT)
    play_dev_card(state, Color.RED, KNIGHT)
    play_dev_card(state, Color.RED, KNIGHT)
    play_dev_card(state, Color.BLUE, KNIGHT)
    play_dev_card(state, Color.BLUE, KNIGHT)
    play_dev_card(state, Color.BLUE, KNIGHT)

    color, count = get_largest_army(state)
    assert color is Color.RED and count == 3

    play_dev_card(state, Color.BLUE, KNIGHT)

    color, count = get_largest_army(state)
    assert color is Color.BLUE and count == 4


def test_cut_but_not_disconnected():
    board = Board()

    board.build_settlement(Color.RED, 0, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    board.build_road(Color.RED, (1, 2))
    board.build_road(Color.RED, (2, 3))
    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, (4, 5))
    board.build_road(Color.RED, (5, 0))
    board.build_road(Color.RED, (3, 12))
    assert (
        max(map(lambda path: len(path), board.continuous_roads_by_player(Color.RED)))
        == 7
    )
    assert len(board.find_connected_components(Color.RED)) == 1

    board.build_settlement(Color.BLUE, 2, initial_build_phase=True)
    assert len(board.find_connected_components(Color.RED)) == 1
    assert (
        max(map(lambda path: len(path), board.continuous_roads_by_player(Color.RED)))
        == 6
    )

--- tests/test_game.py ---
import pytest
from unittest.mock import MagicMock, patch

from catanatron.state_functions import (
    get_actual_victory_points,
    get_player_freqdeck,
    player_has_rolled,
)
from catanatron.game import Game, is_valid_trade
from catanatron.state import (
    apply_action,
    player_deck_replenish,
    player_num_resource_cards,
)
from catanatron.state_functions import player_key
from catanatron.models.actions import (
    generate_playable_actions
)
from catanatron.models.enums import (
    BRICK,
    ORE,
    RESOURCES,
    ActionPrompt,
    SETTLEMENT,
    ActionType,
    Action,
    WHEAT,
    WOOD,
    YEAR_OF_PLENTY,
    ROAD_BUILDING,
)
from catanatron.models.player import Color, RandomPlayer, SimplePlayer


def test_initial_build_phase():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    actions = []
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        actions.append(game.play_tick())

    p0_color = game.state.colors[0]
    assert (
        actions[0].action_type == ActionType.BUILD_SETTLEMENT
        and actions[0].color == p0_color
    )
    assert (
        actions[1].action_type == ActionType.BUILD_ROAD and actions[1].color == p0_color
    )
    assert (
        actions[2].action_type == ActionType.BUILD_SETTLEMENT
        and actions[2].color != p0_color
    )
    assert (
        actions[3].action_type == ActionType.BUILD_ROAD and actions[3].color != p0_color
    )
    assert (
        actions[4].action_type == ActionType.BUILD_SETTLEMENT
        and actions[4].color != p0_color
    )
    assert (
        actions[5].action_type == ActionType.BUILD_ROAD and actions[5].color != p0_color
    )
    assert (
        actions[6].action_type == ActionType.BUILD_SETTLEMENT
        and actions[6].color == p0_color
    )
    assert (
        actions[7].action_type == ActionType.BUILD_ROAD and actions[7].color == p0_color
    )
    assert (
        game.state.current_prompt == ActionPrompt.PLAY_TURN
        and game.state.current_color() == p0_color
    )

    assert game.state.player_state["P0_ACTUAL_VICTORY_POINTS"] == 2
    assert game.state.player_state["P1_ACTUAL_VICTORY_POINTS"] == 2
    assert game.state.player_state["P0_VICTORY_POINTS"] == 2
    assert game.state.player_state["P1_VICTORY_POINTS"] == 2

    # assert there are 4 houses and 4 roads
    settlements = [
        building
        for building in game.state.board.buildings.values()
        if building[1] == SETTLEMENT
    ]
    assert len(settlements) == 4

    # assert should be house-road pairs, or together
    paths = game.state.board.continuous_roads_by_player(players[0].color)
    assert len(paths) == 1 or (
        len(paths) == 2 and len(paths[0]) == 1 and len(paths[1]) == 1
    )

    # assert should have resources from last house.
    # can only assert <= 3 b.c. player might place on a corner desert
    assert player_num_resource_cards(game.state, players[0].color) <= 3
    assert player_num_resource_cards(game.state, players[1].color) <= 3


def test_can_play_for_a_bit():  # assert no exception thrown
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    for _ in range(10):
        game.play_tick()


@patch("catanatron.state.roll_dice")
def test_seven_cards_dont_trigger_discarding(fake_roll_dice):
    fake_roll_dice.return_value = (1, 6)
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]

    # Play initial build phase
    game = Game(players)
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    until_seven = 7 - player_num_resource_cards(game.state, players[1].color)
    player_deck_replenish(game.state, players[1].color, WHEAT, until_seven)
    assert player_num_resource_cards(game.state, players[1].color) == 7
    game.play_tick()  # should be player 0 rolling.

    assert not any(
        a.action_type == ActionType.DISCARD for a in game.state.playable_actions
    )


@patch("catanatron.state.roll_dice")
def test_rolling_a_seven_triggers_default_discard_limit(fake_roll_dice):
    fake_roll_dice.return_value = (1, 6)
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    until_nine = 9 - player_num_resource_cards(game.state, players[1].color)
    player_deck_replenish(game.state, players[1].color, WHEAT, until_nine)
    assert player_num_resource_cards(game.state, players[1].color) == 9
    game.play_tick()  # should be player 0 rolling.

    assert len(game.state.playable_actions) == 1
    assert game.state.playable_actions == [
        Action(players[1].color, ActionType.DISCARD, None)
    ]

    game.play_tick()
    assert player_num_resource_cards(game.state, players[1].color) == 5


@patch("catanatron.state.roll_dice")
def test_all_players_discard_as_needed(fake_roll_dice):
    """Tests irrespective of who rolls the 7, all players discard"""
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    ordered_players = game.state.players
    fake_roll_dice.return_value = (3, 3)
    game.play_tick()  # should be p0 rolling a 6
    game.play_tick()  # should be p0 ending turn

    # fill everyones hand
    until_nine = 9 - player_num_resource_cards(game.state, players[0].color)
    player_deck_replenish(game.state, players[0].color, WHEAT, until_nine)
    until_nine = 9 - player_num_resource_cards(game.state, players[1].color)
    player_deck_replenish(game.state, players[1].color, WHEAT, until_nine)
    until_nine = 9 - player_num_resource_cards(game.state, players[2].color)
    player_deck_replenish(game.state, players[2].color, WHEAT, until_nine)
    until_nine = 9 - player_num_resource_cards(game.state, players[3].color)
    player_deck_replenish(game.state, players[3].color, WHEAT, until_nine)
    fake_roll_dice.return_value = (1, 6)
    game.play_tick()  # should be p1 rolling a 7

    # the following assumes, no matter who rolled 7, asking players
    #   to discard, happens in original seating-order.
    assert len(game.state.playable_actions) == 1
    assert game.state.playable_actions == [
        Action(ordered_players[0].color, ActionType.DISCARD, None)
    ]

    game.play_tick()  # p0 discards, places p1 in line to discard
    assert player_num_resource_cards(game.state, ordered_players[0].color) == 5
    assert len(game.state.playable_actions) == 1
    assert game.state.playable_actions == [
        Action(ordered_players[1].color, ActionType.DISCARD, None)
    ]

    game.play_tick()
    assert player_num_resource_cards(game.state, ordered_players[1].color) == 5
    assert len(game.state.playable_actions) == 1
    assert game.state.playable_actions == [
        Action(ordered_players[2].color, ActionType.DISCARD, None)
    ]

    game.play_tick()
    assert player_num_resource_cards(game.state, ordered_players[2].color) == 5
    assert len(game.state.playable_actions) == 1
    assert game.state.playable_actions == [
        Action(ordered_players[3].color, ActionType.DISCARD, None)
    ]

    game.play_tick()  # p3 discards, game goes back to p1 moving robber
    assert player_num_resource_cards(game.state, ordered_players[3].color) == 5
    assert game.state.is_moving_knight
    assert all(a.color == ordered_players[1].color for a in game.state.playable_actions)
    assert all(
        a.action_type == ActionType.MOVE_ROBBER for a in game.state.playable_actions
    )


@patch("catanatron.state.roll_dice")
def test_discard_is_configurable(fake_roll_dice):
    fake_roll_dice.return_value = (1, 6)
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players, discard_limit=10)
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    until_nine = 9 - player_num_resource_cards(game.state, players[1].color)
    player_deck_replenish(game.state, players[1].color, WHEAT, until_nine)
    assert player_num_resource_cards(game.state, players[1].color) == 9
    game.play_tick()  # should be p0 rolling.

    assert game.state.playable_actions != [
        Action(players[1].color, ActionType.DISCARD, None)
    ]


@patch("catanatron.state.roll_dice")
def test_end_turn_goes_to_next_player(fake_roll_dice):
    fake_roll_dice.return_value = (1, 2)  # not a 7

    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    actions = []
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        actions.append(game.play_tick())

    p0_color = game.state.colors[0]
    p1_color = game.state.colors[1]
    assert (
        game.state.current_prompt == ActionPrompt.PLAY_TURN
        and game.state.current_color() == p0_color
    )
    assert game.state.playable_actions == [Action(p0_color, ActionType.ROLL, None)]

    game.execute(Action(p0_color, ActionType.ROLL, None))
    assert game.state.current_prompt == ActionPrompt.PLAY_TURN
    assert game.state.current_color() == p0_color
    assert player_has_rolled(game.state, p0_color)
    assert Action(p0_color, ActionType.END_TURN, None) in game.state.playable_actions

    game.execute(Action(p0_color, ActionType.END_TURN, None))
    assert game.state.current_prompt == ActionPrompt.PLAY_TURN
    assert game.state.current_color() == p1_color
    assert not player_has_rolled(game.state, p0_color)
    assert not player_has_rolled(game.state, p1_color)
    assert game.state.playable_actions == [Action(p1_color, ActionType.ROLL, None)]


# ===== Development Cards
def test_play_year_of_plenty_not_enough_resources():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    player_to_act = players[0]
    game = Game(players)
    game.state.resource_freqdeck = [0, 0, 0, 0, 0]
    player_deck_replenish(game.state, player_to_act.color, YEAR_OF_PLENTY)

    action_to_execute = Action(
        player_to_act.color,
        ActionType.PLAY_YEAR_OF_PLENTY,
        [ORE, WHEAT],
    )

    with pytest.raises(ValueError):  # not enough cards in bank
        game.execute(action_to_execute)


def test_play_year_of_plenty_no_year_of_plenty_card():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)

    action_to_execute = Action(
        players[0].color, ActionType.PLAY_YEAR_OF_PLENTY, [ORE, WHEAT]
    )

    with pytest.raises(ValueError):  # no year of plenty card
        game.execute(action_to_execute)


def test_play_monopoly_no_monopoly_card():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)

    action_to_execute = Action(players[0].color, ActionType.PLAY_MONOPOLY, ORE)

    with pytest.raises(ValueError):  # no monopoly
        game.execute(action_to_execute)


@patch("catanatron.state.roll_dice")
def test_play_road_building(fake_roll_dice):
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    p0 = game.state.players[0]
    player_deck_replenish(game.state, p0.color, ROAD_BUILDING)

    # play initial phase
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    # roll not a 7
    fake_roll_dice.return_value = (1, 2)
    game.play_tick()  # roll

    game.execute(Action(p0.color, ActionType.PLAY_ROAD_BUILDING, None))
    assert game.state.is_road_building
    assert game.state.free_roads_available == 2
    game.play_tick()
    assert game.state.is_road_building
    assert game.state.free_roads_available == 1
    game.play_tick()
    assert not game.state.is_road_building
    assert game.state.free_roads_available == 0


def test_longest_road_steal():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    p0, p1 = game.state.players
    p0_key = player_key(game.state, p0.color)
    p1_key = player_key(game.state, p1.color)
    board = game.state.board

    # p0 has a road of length 4
    board.build_settlement(p0.color, 6, True)
    board.build_road(p0.color, (6, 7))
    board.build_road(p0.color, (7, 8))
    board.build_road(p0.color, (8, 9))
    board.build_road(p0.color, (9, 10))
    game.state.player_state[f'{p0_key}_VICTORY_POINTS'] = 1
    game.state.player_state[f'{p0_key}_ACTUAL_VICTORY_POINTS'] = 1

    # p1 has longest road of lenght 5
    board.build_settlement(p1.color, 28, True)
    board.build_road(p1.color, (27, 28))
    board.build_road(p1.color, (28, 29))
    board.build_road(p1.color, (29, 30))
    board.build_road(p1.color, (30, 31))
    board.build_road(p1.color, (31, 32))
    game.state.player_state[f'{p1_key}_VICTORY_POINTS'] = 3
    game.state.player_state[f'{p1_key}_ACTUAL_VICTORY_POINTS'] = 3
    game.state.player_state[f'{p1_key}_HAS_ROAD'] = True

    # Required to be able to apply actions other than rolling or initial build phase.
    game.state.current_prompt = ActionPrompt.PLAY_TURN
    game.state.is_initial_build_phase = False
    game.state.player_state[f'{p0_key}_HAS_ROLLED'] = True
    game.state.playable_actions = generate_playable_actions(game.state)

    # Set up player0 to build two roads and steal longest road.
    road1 = (10, 11)
    road2 = (11, 12)
    player_deck_replenish(game.state, p0.color, WOOD, 2)
    player_deck_replenish(game.state, p0.color, BRICK, 2)

    # Matching length of longest road does not steal longest road.
    apply_action(game.state, Action(p0.color, ActionType.BUILD_ROAD, road1))
    assert game.state.player_state[f'{p0_key}_LONGEST_ROAD_LENGTH'] == 5
    assert game.state.player_state[f'{p0_key}_HAS_ROAD'] == False
    assert game.state.player_state[f'{p0_key}_VICTORY_POINTS'] == 1
    assert game.state.player_state[f'{p0_key}_ACTUAL_VICTORY_POINTS'] == 1
    assert game.state.player_state[f'{p1_key}_LONGEST_ROAD_LENGTH'] == 5
    assert game.state.player_state[f'{p1_key}_HAS_ROAD'] == True
    assert game.state.player_state[f'{p1_key}_VICTORY_POINTS'] == 3
    assert game.state.player_state[f'{p1_key}_ACTUAL_VICTORY_POINTS'] == 3

    # Surpassing length of longest road steals longest road and VPs.
    apply_action(game.state, Action(p0.color, ActionType.BUILD_ROAD, road2))
    assert game.state.player_state[f'{p0_key}_LONGEST_ROAD_LENGTH'] == 6
    assert game.state.player_state[f'{p0_key}_HAS_ROAD'] == True
    assert game.state.player_state[f'{p0_key}_VICTORY_POINTS'] == 3
    assert game.state.player_state[f'{p0_key}_ACTUAL_VICTORY_POINTS'] == 3
    assert game.state.player_state[f'{p1_key}_LONGEST_ROAD_LENGTH'] == 5
    assert game.state.player_state[f'{p1_key}_HAS_ROAD'] == False
    assert game.state.player_state[f'{p1_key}_VICTORY_POINTS'] == 1
    assert game.state.player_state[f'{p1_key}_ACTUAL_VICTORY_POINTS'] == 1


def test_second_placement_takes_cards_from_bank():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    assert sum(game.state.resource_freqdeck) == 19 * 5

    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    assert sum(game.state.resource_freqdeck) < 19 * 5


def test_vps_to_win_config():
    players = [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
    ]
    game = Game(players, vps_to_win=4)
    game.play()

    winning_color = game.winning_color()
    vps = get_actual_victory_points(game.state, winning_color)
    assert vps >= 4 and vps < 6


def test_cant_trade_same_resources_or_give():
    offering = [1, 0, 0, 0, 0]
    asking = [1, 0, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert not is_valid_trade(action_value)

    offering = [0, 1, 0, 0, 0]
    asking = [0, 2, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert not is_valid_trade(action_value)

    offering = [0, 1, 3, 0, 0]
    asking = [0, 0, 1, 0, 0]
    action_value = tuple([*offering, *asking])
    assert not is_valid_trade(action_value)


def test_cant_give_away_resources():
    offering = [1, 0, 0, 0, 0]
    asking = [0, 0, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert not is_valid_trade(action_value)

    offering = [0, 0, 0, 0, 0]
    asking = [0, 2, 0, 0, 1]
    action_value = tuple([*offering, *asking])
    assert not is_valid_trade(action_value)


def test_trade_offers_are_valid():
    offering = [1, 0, 0, 0, 0]
    asking = [0, 1, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert is_valid_trade(action_value)

    offering = [0, 0, 1, 0, 0]
    asking = [0, 2, 0, 0, 1]
    action_value = tuple([*offering, *asking])
    assert is_valid_trade(action_value)

    offering = [0, 0, 0, 2, 0]
    asking = [0, 1, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert is_valid_trade(action_value)

    offering = [0, 0, 1, 1, 0]
    asking = [0, 1, 0, 0, 0]
    action_value = tuple([*offering, *asking])
    assert is_valid_trade(action_value)


@patch("catanatron.state.roll_dice")
def test_trading_sequence(fake_roll_dice):
    # Play initial building phase
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
    ]
    game = Game(players)
    [p0, p1, p2] = game.state.players
    while not any(
        a.action_type == ActionType.ROLL for a in game.state.playable_actions
    ):
        game.play_tick()

    # create 1:1 trade
    freqdeck = get_player_freqdeck(game.state, p0.color)
    index_of_a_resource_owned = next(i for i, v in enumerate(freqdeck) if v > 0)
    missing_resource_index = freqdeck.index(
        0
    )  # assumes its impossible to have one of each resource in first turn
    offered = [0, 0, 0, 0, 0]
    offered[index_of_a_resource_owned] = 1
    asking = [0, 0, 0, 0, 0]
    asking[missing_resource_index] = 1
    trade_action_value = tuple([*offered, *asking])
    action = Action(p0.color, ActionType.OFFER_TRADE, trade_action_value)

    # apply action, and listen to p1.decide_trade
    with pytest.raises(ValueError):  # can't offer trades before rolling. must risk 7
        game.execute(action)

    # roll not a 7
    fake_roll_dice.return_value = (1, 2)
    game.play_tick()
    freqdeck = get_player_freqdeck(game.state, p0.color)

    # test 1: players deny trade
    p1.decide = MagicMock(
        return_value=Action(p1.color, ActionType.REJECT_TRADE, (*trade_action_value, 0))
    )
    p2.decide = MagicMock(
        return_value=Action(p2.color, ActionType.REJECT_TRADE, (*trade_action_value, 0))
    )
    game.execute(action)  # now you can offer trades
    assert game.state.is_resolving_trade
    assert all(a.color == p1.color for a in game.state.playable_actions)
    assert all(
        a.action_type in [ActionType.ACCEPT_TRADE, ActionType.REJECT_TRADE]
        for a in game.state.playable_actions
    )

    # assert they asked players to accept/deny trade
    game.play_tick()  # ask p1 to decide
    game.play_tick()  # ask p2 to decide
    p1.decide.assert_called_once()
    p2.decide.assert_called_once()
    # assert trade didn't happen and is back at PLAY_TURN
    assert freqdeck == get_player_freqdeck(game.state, p0.color)
    assert not game.state.is_resolving_trade
    assert game.state.current_prompt == ActionPrompt.PLAY_TURN

    # test 2: one of them (p1) accepts trade, but p0 regrets
    # ensure p1 has cards
    player_deck_replenish(game.state, p1.color, RESOURCES[missing_resource_index], 1)
    p1.decide = MagicMock(
        return_value=Action(p1.color, ActionType.ACCEPT_TRADE, (*trade_action_value, 0))
    )
    p2.decide = MagicMock(
        return_value=Action(p2.color, ActionType.REJECT_TRADE, (*trade_action_value, 0))
    )
    p0.decide = MagicMock(return_value=Action(p0.color, ActionType.CANCEL_TRADE, None))
    game.execute(action)
    assert game.state.is_resolving_trade
    game.play_tick()  # ask p1 to accept/reject
    game.play_tick()  # ask p2 to accept/reject
    game.play_tick()  # ask p1 to confirm
    p1.decide.assert_called_once()
    p2.decide.assert_called_once()
    p0.decide.assert_called_once_with(
        game,
        [
            Action(p0.color, ActionType.CANCEL_TRADE, None),
            Action(p0.color, ActionType.CONFIRM_TRADE, (*trade_action_value, p1.color)),
        ],
    )
    # assert trade didn't happen
    assert freqdeck == get_player_freqdeck(game.state, p0.color)
    assert not game.state.is_resolving_trade
    assert game.state.current_prompt == ActionPrompt.PLAY_TURN

    # test 3: both of them accepts trade, p0 selects p2
    # ensure p1 and p2 have cards
    player_deck_replenish(game.state, p1.color, RESOURCES[missing_resource_index], 1)
    player_deck_replenish(game.state, p2.color, RESOURCES[missing_resource_index], 1)
    p1.decide = MagicMock(
        return_value=Action(p1.color, ActionType.ACCEPT_TRADE, (*trade_action_value, 0))
    )
    p2.decide = MagicMock(
        return_value=Action(p2.color, ActionType.ACCEPT_TRADE, (*trade_action_value, 0))
    )
    p0.decide = MagicMock(
        return_value=Action(
            p0.color, ActionType.CONFIRM_TRADE, (*trade_action_value, p2.color)
        )
    )
    game.execute(action)
    assert game.state.is_resolving_trade
    game.play_tick()  # ask p1 to accept/reject
    game.play_tick()  # ask p2 to accept/reject
    game.play_tick()  # ask p1 to confirm
    p1.decide.assert_called_once()
    p2.decide.assert_called_once()
    p0.decide.assert_called_once_with(
        game,
        [
            Action(p0.color, ActionType.CANCEL_TRADE, None),
            Action(p0.color, ActionType.CONFIRM_TRADE, (*trade_action_value, p1.color)),
            Action(p0.color, ActionType.CONFIRM_TRADE, (*trade_action_value, p2.color)),
        ],
    )
    # assert trade did happen
    expected = freqdeck[:]
    expected[index_of_a_resource_owned] -= 1
    expected[missing_resource_index] += 1
    assert get_player_freqdeck(game.state, p0.color) == expected

--- tests/test_gym.py ---
import random

import gymnasium as gym
from gymnasium.utils.env_checker import check_env

from catanatron_gym.features import get_feature_ordering
from catanatron.models.player import Color, RandomPlayer
from catanatron_experimental.machine_learning.players.value import ValueFunctionPlayer
from catanatron_gym.envs.catanatron_env import CatanatronEnv

features = get_feature_ordering(2)


def get_p0_num_settlements(obs):
    indexes = [
        i
        for i, name in enumerate(features)
        if "NODE" in name and "SETTLEMENT" in name and "P0" in name
    ]
    return sum([obs[i] for i in indexes])


def test_check_env():
    env = CatanatronEnv()
    check_env(env)


def test_gym():
    env = CatanatronEnv()

    first_observation, _ = env.reset()  # this forces advanced until p0...
    assert len(env.get_valid_actions()) >= 50  # first seat at most blocked 4 nodes
    assert get_p0_num_settlements(first_observation) == 0

    action = random.choice(env.get_valid_actions())
    second_observation, reward, terminated, truncated, info = env.step(action)
    assert (first_observation != second_observation).any()
    assert reward == 0
    assert not terminated
    assert not truncated
    assert len(env.get_valid_actions()) in [2, 3]

    assert second_observation[features.index("BANK_DEV_CARDS")] == 25
    assert second_observation[features.index("BANK_SHEEP")] == 19
    assert get_p0_num_settlements(second_observation) == 1

    reset_obs, _ = env.reset()
    assert (reset_obs != second_observation).any()
    assert get_p0_num_settlements(reset_obs) == 0

    env.close()


def test_gym_registration_and_api_works():
    env = gym.make("catanatron_gym:catanatron-v1")
    observation, info = env.reset()
    done = False
    reward = 0
    while not done:
        action = env.action_space.sample()
        observation, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated
    env.close()
    assert reward in [-1, 1]


def test_invalid_action_reward():
    env = gym.make(
        "catanatron_gym:catanatron-v1", config={"invalid_action_reward": -1234}
    )
    first_obs, _ = env.reset()
    invalid_action = next(filter(lambda i: i not in env.get_valid_actions(), range(1000)))  # type: ignore
    observation, reward, terminated, truncated, info = env.step(invalid_action)
    assert reward == -1234
    assert not terminated
    assert not truncated
    assert (observation == first_obs).all()
    for _ in range(500):
        observation, reward, terminated, truncated, info = env.step(invalid_action)
        assert (observation == first_obs).all()
    assert not terminated
    assert truncated


def test_custom_reward():
    def custom_reward(game, p0_color):
        return 123

    env = gym.make(
        "catanatron_gym:catanatron-v1", config={"reward_function": custom_reward}
    )
    observation, info = env.reset()
    action = random.choice(env.get_valid_actions())  # type: ignore
    observation, reward, terminated, truncated, info = env.step(action)
    assert reward == 123


def test_custom_map():
    env = gym.make("catanatron_gym:catanatron-v1", config={"map_type": "MINI"})
    observation, info = env.reset()
    assert len(env.get_valid_actions()) < 50  # type: ignore
    assert len(observation) < 614
    # assert env.action_space.n == 260


def test_enemies():
    env = gym.make(
        "catanatron_gym:catanatron-v1",
        config={
            "enemies": [
                ValueFunctionPlayer(Color.RED),
                RandomPlayer(Color.ORANGE),
                RandomPlayer(Color.WHITE),
            ]
        },
    )
    observation, info = env.reset()
    assert len(observation) == len(get_feature_ordering(4))

    done = False
    reward = 0
    while not done:
        action = random.choice(env.get_valid_actions())  # type: ignore
        observation, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated

    # Virtually impossible for a Random bot to beat Value Function Player
    assert env.game.winning_color() == Color.RED  # type: ignore
    assert reward - 1
    env.close()


def test_mixed_rep():
    env = gym.make(
        "catanatron_gym:catanatron-v1",
        config={"representation": "mixed"},
    )
    observation, info = env.reset()
    assert "board" in observation
    assert "numeric" in observation

--- tests/test_imports.py ---
from catanatron import Game, RandomPlayer, Color, GameAccumulator

from catanatron_experimental.my_player import MyPlayer


def test_top_level_imports_work():
    class MyAccumulator(GameAccumulator):
        pass

    players = [
        MyPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        RandomPlayer(Color.ORANGE),
    ]
    game = Game(players)
    game.play(accumulators=[MyAccumulator()])

--- tests/test_json.py ---
import json

from catanatron.game import Game
from catanatron.models.enums import ActionType
from catanatron.models.player import SimplePlayer, Color
from catanatron.json import GameEncoder, action_from_json


def test_serialization():
    game = Game(
        players=[
            SimplePlayer(Color.RED),
            SimplePlayer(Color.BLUE),
            SimplePlayer(Color.WHITE),
            SimplePlayer(Color.ORANGE),
        ]
    )

    string = json.dumps(game, cls=GameEncoder)
    result = json.loads(string)

    # Loosely assert looks like expected
    assert isinstance(result["robber_coordinate"], list)
    assert isinstance(result["tiles"], list)
    assert isinstance(result["edges"], list)
    assert isinstance(result["nodes"], dict)
    assert isinstance(result["actions"], list)


def test_action_from_json():
    data = ["RED", "MARITIME_TRADE", ["SHEEP", "SHEEP", "SHEEP", "SHEEP", "ORE"]]
    action = action_from_json(data)
    assert action.color == Color.RED
    assert action.action_type == ActionType.MARITIME_TRADE
    assert action.value == ("SHEEP", "SHEEP", "SHEEP", "SHEEP", "ORE")

--- tests/test_machine_learning.py ---
import math
import random

import numpy as np

from tests.utils import advance_to_play_turn, build_initial_placements
from catanatron.state import player_deck_replenish
from catanatron.models.enums import ORE, Action, ActionType, WHEAT, NodeRef
from catanatron.models.board import Board, get_edges
from catanatron.models.map import (
    BASE_MAP_TEMPLATE,
    MINI_MAP_TEMPLATE,
    NUM_EDGES,
    NUM_NODES,
    CatanMap,
)
from catanatron.game import Game
from catanatron.models.map import number_probability
from catanatron.models.player import SimplePlayer, Color
from catanatron_gym.features import (
    create_sample,
    expansion_features,
    port_features,
    reachability_features,
    iter_players,
    port_distance_features,
    resource_hand_features,
    tile_features,
    graph_features,
)
from catanatron_gym.board_tensor_features import (
    create_board_tensor,
    get_node_and_edge_maps,
    init_board_tensor_map,
    init_tile_coordinate_map,
)


def test_create_sample():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)

    sample = create_sample(game, players[1].color)
    assert isinstance(sample, dict)
    assert len(sample) > 0


def test_port_distance_features():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    color = game.state.colors[0]
    game.execute(Action(color, ActionType.BUILD_SETTLEMENT, 3))
    game.execute(Action(color, ActionType.BUILD_ROAD, (2, 3)))

    ports = game.state.board.map.port_nodes
    se_port_resource = next(filter(lambda entry: 29 in entry[1], ports.items()))[0]
    port_name = "3:1" if se_port_resource is None else se_port_resource

    features = port_distance_features(game, color)
    assert features["P0_HAS_WHEAT_PORT"] == False
    assert features[f"P0_{port_name}_PORT_DISTANCE"] == 3


def test_resource_hand_features():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
    ]
    game = Game(players)

    red_index = game.state.color_to_index[Color.RED]
    game.state.player_state[f"P{red_index}_WHEAT_IN_HAND"] = 20
    player_deck_replenish(game.state, Color.BLUE, "ORE", 17)

    features = resource_hand_features(game, Color.RED)
    assert features["P0_WHEAT_IN_HAND"] == 20
    assert features["P1_NUM_RESOURCES_IN_HAND"] == 17

    features = resource_hand_features(game, Color.BLUE)
    assert features["P0_ORE_IN_HAND"] == 17
    assert features["P1_NUM_RESOURCES_IN_HAND"] == 20


def test_expansion_features():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    color = game.state.colors[0]
    game.execute(Action(color, ActionType.BUILD_SETTLEMENT, 3))
    game.execute(Action(color, ActionType.BUILD_ROAD, (2, 3)))

    neighbor_tile_resource = game.state.board.map.land_tiles[(1, -1, 0)].resource
    if neighbor_tile_resource is None:
        neighbor_tile_resource = game.state.board.map.land_tiles[(0, -1, 1)].resource

    features = expansion_features(game, color)
    assert features["P0_WHEAT_AT_DISTANCE_0"] == 0
    assert features[f"P0_{neighbor_tile_resource}_AT_DISTANCE_0"] == 0
    assert features[f"P0_{neighbor_tile_resource}_AT_DISTANCE_1"] > 0


def test_reachability_features():
    """Board in tensor-board-test.png"""
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    # NOTE: tensor-board-test.png is the board that happens after seeding random
    #   with 123 and running a random.sample() like so:
    # We do this here to allow Game.__init__ evolve freely.
    random.seed(123)
    random.sample(players, len(players))
    catan_map = CatanMap.from_template(BASE_MAP_TEMPLATE)
    game = Game(players, seed=123, catan_map=catan_map)
    p0_color = game.state.colors[0]

    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, 5))
    features = reachability_features(game, p0_color)
    assert features["P0_0_ROAD_REACHABLE_WOOD"] == number_probability(3)
    assert features["P0_0_ROAD_REACHABLE_BRICK"] == number_probability(4)
    assert features["P0_0_ROAD_REACHABLE_SHEEP"] == number_probability(6)
    assert features["P0_0_ROAD_REACHABLE_WHEAT"] == 0
    # these are 0 since cant build at distance 1
    assert features["P0_1_ROAD_REACHABLE_ORE"] == 0
    assert features["P0_1_ROAD_REACHABLE_WHEAT"] == 0
    # whats available at distance 0 should also be available at distance 1
    assert features["P0_1_ROAD_REACHABLE_WOOD"] == number_probability(3)
    assert features["P0_1_ROAD_REACHABLE_BRICK"] == number_probability(4)
    assert features["P0_1_ROAD_REACHABLE_SHEEP"] == number_probability(6)

    game.execute(Action(p0_color, ActionType.BUILD_ROAD, (0, 5)))
    features = reachability_features(game, p0_color)
    assert features["P0_0_ROAD_REACHABLE_WOOD"] == number_probability(3)
    assert features["P0_0_ROAD_REACHABLE_BRICK"] == number_probability(4)
    assert features["P0_0_ROAD_REACHABLE_SHEEP"] == number_probability(6)
    assert features["P0_0_ROAD_REACHABLE_WHEAT"] == 0
    assert features["P0_1_ROAD_REACHABLE_ORE"] == number_probability(
        8
    ) + number_probability(5)
    assert features["P0_1_ROAD_REACHABLE_WHEAT"] == 2 * number_probability(9)

    # Test distance 2
    assert math.isclose(
        features["P0_2_ROAD_REACHABLE_ORE"],
        2 * number_probability(10)
        + 3 * number_probability(8)
        + 3 * number_probability(5),
    )

    # Test enemy making building removes buildability
    p1_color = game.state.colors[1]
    game.execute(Action(p1_color, ActionType.BUILD_SETTLEMENT, 1))
    features = reachability_features(game, p0_color)
    assert features["P0_1_ROAD_REACHABLE_ORE"] == number_probability(8)
    assert math.isclose(
        features["P0_2_ROAD_REACHABLE_ORE"],
        2 * number_probability(10) + 3 * number_probability(8),
    )


def test_tile_features():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)

    features = tile_features(game, players[0].color)
    tile = game.state.board.map.land_tiles[(0, 0, 0)]
    resource = tile.resource
    value = resource if resource is not None else "DESERT"
    proba = number_probability(tile.number) if resource is not None else 0
    assert features[f"TILE0_IS_{value}"]
    assert features[f"TILE0_PROBA"] == proba


def test_tile_features_in_mini():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
    ]
    game = Game(players, catan_map=CatanMap.from_template(MINI_MAP_TEMPLATE))

    features = tile_features(game, players[0].color)
    haystack = "".join(features.keys())
    assert "TILE7" not in haystack


def test_port_features_in_mini():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
    ]
    game = Game(players, catan_map=CatanMap.from_template(MINI_MAP_TEMPLATE))

    features = port_features(game, players[0].color)
    assert len(features) == 0


def test_graph_features():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    p0_color = game.state.colors[0]
    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, 3))
    game.execute(Action(p0_color, ActionType.BUILD_ROAD, (2, 3)))

    features = graph_features(game, p0_color)
    assert features[f"NODE3_P0_SETTLEMENT"]
    assert features[f"EDGE(2, 3)_P0_ROAD"]
    assert not features[f"NODE3_P1_SETTLEMENT"]
    assert not features[f"NODE0_P1_SETTLEMENT"]
    assert len(features) == 54 * len(players) * 2 + NUM_EDGES * len(players)
    assert sum(features.values()) == 2

    haystack = "".join(features.keys())
    for edge in get_edges():
        assert str(edge) in haystack
    for node in range(NUM_NODES):
        assert ("NODE" + str(node)) in haystack


def test_graph_features_in_mini():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
    ]
    game = Game(players, catan_map=CatanMap.from_template(MINI_MAP_TEMPLATE))
    p0_color = game.state.colors[0]
    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, 3))
    game.execute(Action(p0_color, ActionType.BUILD_ROAD, (2, 3)))

    features = graph_features(game, p0_color)
    assert features[f"NODE3_P0_SETTLEMENT"]
    assert features[f"EDGE(2, 3)_P0_ROAD"]
    assert not features[f"NODE3_P1_SETTLEMENT"]
    assert not features[f"NODE0_P1_SETTLEMENT"]
    # todo: CHANGE NUM_EDGES
    assert len(features) == 24 * len(players) * 2 + 30 * len(players)
    assert sum(features.values()) == 2

    haystack = "".join(features.keys())
    for edge in get_edges(game.state.board.map.land_nodes):
        assert str(edge) in haystack
    for node in range(24):
        assert ("NODE" + str(node)) in haystack


def test_init_board_tensor_map():
    node_map, edge_map = init_board_tensor_map()
    assert node_map[82] == (0, 0)
    assert node_map[81] == (2, 0)
    assert node_map[93] == (20, 0)
    assert node_map[79] == (0, 2)
    assert node_map[43] == (4, 2)
    assert node_map[72] == (0, 10)
    assert node_map[60] == (20, 10)

    assert edge_map[(82, 81)] == (1, 0)
    assert edge_map[(81, 82)] == (1, 0)
    assert edge_map[(81, 47)] == (3, 0)
    assert edge_map[(92, 93)] == (19, 0)
    assert edge_map[(82, 79)] == (0, 1)
    assert edge_map[(47, 43)] == (4, 1)
    assert edge_map[(53, 94)] == (19, 2)
    assert edge_map[(44, 40)] == (2, 3)
    assert edge_map[(21, 16)] == (6, 3)
    assert edge_map[(24, 53)] == (18, 3)
    assert edge_map[(72, 71)] == (1, 10)
    assert edge_map[(60, 61)] == (19, 10)

    for i in range(NUM_NODES):
        assert i in node_map
    for edge in get_edges():
        assert edge in edge_map


def test_init_tile_map():
    tile_map = init_tile_coordinate_map()
    assert tile_map[(-1, 3, -2)] == (0, 0)
    assert tile_map[(0, 2, -2)] == (0, 4)
    assert tile_map[(-2, 2, 0)] == (4, 0)

    assert tile_map[(-1, 2, -1)] == (2, 2)  # first odd row

    assert tile_map[(0, 0, 0)] == (4, 8)  # center tile

    assert tile_map[(0, -2, 2)] == (8, 12)  # southeast

    for coordinate in Board().map.land_tiles.keys():
        assert coordinate in tile_map


def test_create_board_tensor_channels_first():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    p0_color = game.state.colors[0]

    tensor = create_board_tensor(game, p0_color, True)
    assert tensor.shape == (20 - 4, 21, 11)


def test_create_board_tensor():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    game = Game(players)
    p0_color = game.state.colors[0]

    # assert starts with no settlement/cities
    tensor = create_board_tensor(game, p0_color)
    assert tensor.shape == (21, 11, 20 - 4)
    assert tensor[0][0][0] == 0
    assert tensor[10][6][0] == 0
    assert tensor[9][6][0] == 0

    # assert settlement and road mark 1s correspondingly
    build_initial_placements(game, p0_actions=[3, (3, 4), 37, (14, 37)])
    tensor = create_board_tensor(game, p0_color)
    assert tensor[10][6][0] == 1
    assert tensor[9][6][1] == 1

    player_deck_replenish(game.state, p0_color, WHEAT, 2)
    player_deck_replenish(game.state, p0_color, ORE, 3)
    advance_to_play_turn(game)
    game.execute(Action(p0_color, ActionType.BUILD_CITY, 3))
    tensor = create_board_tensor(game, p0_color)
    assert tensor[10][6][0] == 2
    assert tensor[9][6][1] == 1


def test_robber_plane_simple():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)

    robber_channel = 13
    tensor = create_board_tensor(game, players[0].color)

    assert np.sum(tensor[:, :, robber_channel]) == 6
    assert np.max(tensor[:, :, robber_channel]) == 1


def test_resource_proba_planes():
    """Board in tensor-board-test.png"""
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    # NOTE: tensor-board-test.png is the board that happens after seeding random
    #   with 123 and running a random.sample() like so:
    # We do this here to allow Game.__init__ evolve freely.
    random.seed(123)
    random.sample(players, len(players))
    catan_map = CatanMap.from_template(BASE_MAP_TEMPLATE)
    game = Game(players, seed=123, catan_map=catan_map)

    tensor = create_board_tensor(game, players[0].color)
    assert tensor[0][0][0] == 0

    # Top left should be 0 for all resources. (water tile)
    for resource_channel in range(4, 9):
        top_left_tile = tensor[0:4, 0:2, resource_channel]
        assert np.all(np.equal(top_left_tile, 0))

    # Assert ten sheep left edge looks good
    sheep_channel = 10
    ten_sheep_left_edge = tensor[4, 0:3, sheep_channel]
    ten_proba = number_probability(10)
    assert np.sum(ten_sheep_left_edge) == ten_proba * 2  # 2 nodes

    # assert 5 wood top node has sheep too.
    wood_channel = 8
    five_proba = number_probability(5)
    five_wood_top_node = tensor[4, 2]
    assert np.all(np.equal(five_wood_top_node[sheep_channel], ten_proba))
    assert np.all(np.equal(five_wood_top_node[wood_channel], five_proba))

    # assert wood node adds up
    total_proba = five_proba + number_probability(11) + number_probability(3)
    middle_wood_node = tensor[4, 4]
    assert np.all(np.equal(middle_wood_node[wood_channel], total_proba))

    # assert brick tile has 6 non-zero node as expected
    four_proba = number_probability(4)
    assert tensor[6, 2, 9] == four_proba
    assert tensor[7, 2, 9] == 0.0
    assert tensor[8, 2, 9] == four_proba
    assert tensor[9, 2, 9] == 0.0
    assert tensor[10, 2, 9] == four_proba
    for i in range(5):
        assert tensor[6 + i, 3, 9] == 0.0
    assert tensor[6, 4, 9] == four_proba
    assert tensor[7, 4, 9] == 0.0
    assert tensor[8, 4, 9] == four_proba
    assert tensor[9, 4, 9] == 0.0
    assert tensor[10, 4, 9] == four_proba


def test_port_planes():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)

    tensor = create_board_tensor(game, players[0].color)

    # assert there are 18 port nodes (4 3:1 and 5 resource)
    assert np.sum(tensor[:, :, -6:]) == 2 * 9

    # assert that 3:1 ports there are 4 * 2 nodes on.
    assert np.sum(tensor[:, :, -1]) == 2 * 4


def test_robber_plane():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    tensor = create_board_tensor(game, players[0].color)

    node_map, _ = get_node_and_edge_maps()
    robber_tile = game.state.board.map.tiles[game.state.board.robber_coordinate]
    nw_desert_node = robber_tile.nodes[NodeRef.NORTHWEST]
    i, j = node_map[nw_desert_node]

    robber_plane_channel = 13
    expected = [
        [1.0, 0.0, 1.0, 0.0, 1.0],
        [0.0, 0.0, 0.0, 0.0, 0.0],
        [1.0, 0.0, 1.0, 0.0, 1.0],
    ]
    assert (
        np.transpose(tensor[i : i + 5, j : j + 3, robber_plane_channel]) == expected
    ).all()


def test_iter_players():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)

    # Test the firsts look good.
    for i in range(4):
        j, c = iter_players(tuple(game.state.colors), game.state.colors[i])[0]
        assert c == game.state.colors[i]

    # Test a specific case (p0=game.state.colors[0])
    iterator = iter_players(tuple(game.state.colors), game.state.colors[0])
    i, c = iterator[0]
    assert i == 0
    assert c == game.state.colors[0]
    i, c = iterator[1]
    assert i == 1
    assert c == game.state.colors[1]
    i, c = iterator[2]
    assert i == 2
    assert c == game.state.colors[2]
    i, c = iterator[3]
    assert i == 3
    assert c == game.state.colors[3]

--- tests/test_state.py ---
import pytest

from catanatron.state import State, apply_action
from catanatron.state_functions import (
    get_dev_cards_in_hand,
    player_freqdeck_add,
    player_deck_replenish,
    player_num_dev_cards,
    player_num_resource_cards,
)
from catanatron.models.enums import (
    RESOURCES,
    ActionPrompt,
    BRICK,
    MONOPOLY,
    ORE,
    ActionType,
    Action,
    SHEEP,
    VICTORY_POINT,
    WHEAT,
    WOOD,
    YEAR_OF_PLENTY,
)
from catanatron.models.player import Color, SimplePlayer
from catanatron.models.decks import freqdeck_count, freqdeck_from_listdeck


def test_buying_road_is_payed_for():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    state.is_initial_build_phase = False
    state.board.build_settlement(players[0].color, 3, True)
    action = Action(players[0].color, ActionType.BUILD_ROAD, (3, 4))
    player_freqdeck_add(
        state,
        players[0].color,
        freqdeck_from_listdeck([WOOD, BRICK]),
    )
    apply_action(state, action)

    assert player_num_resource_cards(state, players[0].color, WOOD) == 0
    assert player_num_resource_cards(state, players[0].color, BRICK) == 0


def test_moving_robber_steals_correctly():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    player_deck_replenish(state, players[1].color, WHEAT, 1)
    state.board.build_settlement(Color.BLUE, 3, initial_build_phase=True)

    action = Action(players[0].color, ActionType.MOVE_ROBBER, ((2, 0, -2), None, None))
    apply_action(state, action)
    assert player_num_resource_cards(state, players[0].color) == 0
    assert player_num_resource_cards(state, players[1].color) == 1

    action = Action(
        players[0].color,
        ActionType.MOVE_ROBBER,
        ((0, 0, 0), players[1].color, WHEAT),
    )
    apply_action(state, action)
    assert player_num_resource_cards(state, players[0].color) == 1
    assert player_num_resource_cards(state, players[1].color) == 0


def test_trade_execution():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    state = State(players)

    player_deck_replenish(state, players[0].color, BRICK, 4)
    trade_offer = tuple([BRICK] * 4 + [ORE])
    action = Action(players[0].color, ActionType.MARITIME_TRADE, trade_offer)
    apply_action(state, action)

    assert player_num_resource_cards(state, players[0].color) == 1
    assert sum(state.resource_freqdeck) == 19 * 5 + 4 - 1


# ===== Development Cards
def test_cant_buy_more_than_max_card():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    with pytest.raises(ValueError):  # not enough money
        apply_action(
            state, Action(players[0].color, ActionType.BUY_DEVELOPMENT_CARD, None)
        )

    player_deck_replenish(state, players[0].color, SHEEP, 26)
    player_deck_replenish(state, players[0].color, WHEAT, 26)
    player_deck_replenish(state, players[0].color, ORE, 26)

    for i in range(25):
        apply_action(
            state, Action(players[0].color, ActionType.BUY_DEVELOPMENT_CARD, None)
        )

    # assert must have all victory points
    assert player_num_dev_cards(state, players[0].color) == 25
    assert get_dev_cards_in_hand(state, players[0].color, VICTORY_POINT) == 5

    with pytest.raises(ValueError):  # not enough cards in bank
        apply_action(
            state, Action(players[0].color, ActionType.BUY_DEVELOPMENT_CARD, None)
        )

    assert player_num_resource_cards(state, players[0].color) == 3


def test_play_year_of_plenty_gives_player_resources():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    player_to_act = players[0]
    player_deck_replenish(state, player_to_act.color, YEAR_OF_PLENTY, 1)

    action_to_execute = Action(
        player_to_act.color, ActionType.PLAY_YEAR_OF_PLENTY, [ORE, WHEAT]
    )

    apply_action(state, action_to_execute)

    for card_type in RESOURCES:
        if card_type == ORE or card_type == WHEAT:
            assert player_num_resource_cards(state, player_to_act.color, card_type) == 1
            assert freqdeck_count(state.resource_freqdeck, card_type) == 18
        else:
            assert player_num_resource_cards(state, player_to_act.color, card_type) == 0
            assert freqdeck_count(state.resource_freqdeck, card_type) == 19
    assert get_dev_cards_in_hand(state, player_to_act.color, YEAR_OF_PLENTY) == 0


def test_play_monopoly_player_steals_cards():
    player_to_act = SimplePlayer(Color.RED)
    player_to_steal_from_1 = SimplePlayer(Color.BLUE)
    player_to_steal_from_2 = SimplePlayer(Color.ORANGE)
    players = [player_to_act, player_to_steal_from_1, player_to_steal_from_2]
    state = State(players)

    player_deck_replenish(state, player_to_act.color, MONOPOLY)
    player_deck_replenish(state, player_to_steal_from_1.color, ORE, 3)
    player_deck_replenish(state, player_to_steal_from_1.color, WHEAT, 1)
    player_deck_replenish(state, player_to_steal_from_2.color, ORE, 2)
    player_deck_replenish(state, player_to_steal_from_2.color, WHEAT, 1)

    action_to_execute = Action(player_to_act.color, ActionType.PLAY_MONOPOLY, ORE)
    apply_action(state, action_to_execute)

    assert player_num_resource_cards(state, player_to_act.color, ORE) == 5
    assert player_num_resource_cards(state, player_to_steal_from_1.color, ORE) == 0
    assert player_num_resource_cards(state, player_to_steal_from_1.color, WHEAT) == 1
    assert player_num_resource_cards(state, player_to_steal_from_2.color, ORE) == 0
    assert player_num_resource_cards(state, player_to_steal_from_2.color, WHEAT) == 1


def test_can_only_play_one_dev_card_per_turn():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    state = State(players)

    player_deck_replenish(state, players[0].color, YEAR_OF_PLENTY, 2)
    action = Action(players[0].color, ActionType.PLAY_YEAR_OF_PLENTY, 2 * [BRICK])
    apply_action(state, action)
    with pytest.raises(ValueError):  # shouldnt be able to play two dev cards
        apply_action(state, action)


def test_sequence():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    state = State(players)

    p0_color = state.colors[0]
    assert state.current_prompt == ActionPrompt.BUILD_INITIAL_SETTLEMENT
    assert Action(p0_color, ActionType.BUILD_SETTLEMENT, 0) in state.playable_actions
    assert Action(p0_color, ActionType.BUILD_SETTLEMENT, 50) in state.playable_actions

    apply_action(state, state.playable_actions[0])

--- tests/test_state_functions.py ---
import pytest

from catanatron.state import State, apply_action
from catanatron.state_functions import (
    buy_dev_card,
    get_actual_victory_points,
    get_largest_army,
    play_dev_card,
    player_deck_random_draw,
    player_deck_replenish,
)
from catanatron.models.enums import (
    KNIGHT,
    ORE,
    SHEEP,
    WHEAT,
    Action,
    ActionType,
)
from catanatron.models.player import Color, SimplePlayer


def test_cant_steal_devcards():
    # Arrange: Have RED buy 1 dev card (and have no resource cards)
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)
    player_deck_replenish(state, Color.RED, WHEAT)
    player_deck_replenish(state, Color.RED, ORE)
    player_deck_replenish(state, Color.RED, SHEEP)
    buy_dev_card(state, Color.RED, KNIGHT)

    # Act: Attempt to steal a resource
    with pytest.raises(IndexError):  # no resource cards in hand
        player_deck_random_draw(state, Color.RED)


def test_defeating_your_own_largest_army_doesnt_give_more_vps():
    # Arrange: Buy all dev cards
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)
    player_deck_replenish(state, players[0].color, SHEEP, 26)
    player_deck_replenish(state, players[0].color, WHEAT, 26)
    player_deck_replenish(state, players[0].color, ORE, 26)
    for i in range(25):
        apply_action(
            state, Action(players[0].color, ActionType.BUY_DEVELOPMENT_CARD, None)
        )
    assert get_largest_army(state) == (None, None)
    assert get_actual_victory_points(state, Color.RED) == 5

    # Act - Assert
    play_dev_card(state, Color.RED, KNIGHT)
    play_dev_card(state, Color.RED, KNIGHT)
    play_dev_card(state, Color.RED, KNIGHT)
    assert get_largest_army(state) == (Color.RED, 3)
    assert get_actual_victory_points(state, Color.RED) == 7

    # Act - Assert
    play_dev_card(state, Color.RED, KNIGHT)
    assert get_largest_army(state) == (Color.RED, 4)
    assert get_actual_victory_points(state, Color.RED) == 7

--- tests/test_yield_resources.py ---
from catanatron.state import yield_resources
from catanatron.models.board import Board
from catanatron.models.player import Color
from catanatron.models.decks import (
    freqdeck_count,
    freqdeck_draw,
    starting_resource_bank,
)


def test_yield_resources():
    board = Board()
    resource_freqdeck = starting_resource_bank()

    tile = board.map.land_tiles[(0, 0, 0)]
    if tile.resource is None:  # is desert
        tile = board.map.land_tiles[(-1, 0, 1)]

    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    payout, depleted = yield_resources(board, resource_freqdeck, tile.number)
    assert len(depleted) == 0
    assert freqdeck_count(payout[Color.RED], tile.resource) >= 1  # type: ignore


def test_yield_resources_two_settlements():
    board = Board()
    resource_freqdeck = starting_resource_bank()

    tile, edge2, node2 = board.map.land_tiles[(0, 0, 0)], (4, 5), 5
    if tile.resource is None:  # is desert
        tile, edge2, node2 = board.map.land_tiles[(-1, 0, 1)], (4, 15), 15

    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, edge2)
    board.build_settlement(Color.RED, node2)
    payout, depleted = yield_resources(board, resource_freqdeck, tile.number)
    assert len(depleted) == 0
    assert freqdeck_count(payout[Color.RED], tile.resource) >= 2  # type: ignore


def test_yield_resources_two_players_and_city():
    board = Board()
    resource_freqdeck = starting_resource_bank()

    tile, edge1, edge2, red_node, blue_node = (
        board.map.land_tiles[(0, 0, 0)],
        (2, 3),
        (3, 4),
        4,
        0,
    )
    if tile.resource is None:  # is desert
        tile, edge1, edge2, red_node, blue_node = (
            board.map.land_tiles[(1, -1, 0)],
            (9, 2),
            (9, 8),
            8,
            6,
        )

    # red has one settlements and one city on tile
    board.build_settlement(Color.RED, 2, initial_build_phase=True)
    board.build_road(Color.RED, edge1)
    board.build_road(Color.RED, edge2)
    board.build_settlement(Color.RED, red_node)
    board.build_city(Color.RED, red_node)

    # blue has a city in tile
    board.build_settlement(Color.BLUE, blue_node, initial_build_phase=True)
    board.build_city(Color.BLUE, blue_node)
    payout, depleted = yield_resources(board, resource_freqdeck, tile.number)
    assert len(depleted) == 0
    assert freqdeck_count(payout[Color.RED], tile.resource) >= 3  # type: ignore
    assert freqdeck_count(payout[Color.BLUE], tile.resource) >= 2  # type: ignore


def test_empty_payout_if_not_enough_resources():
    board = Board()
    resource_freqdeck = starting_resource_bank()

    tile = board.map.land_tiles[(0, 0, 0)]
    if tile.resource is None:  # is desert
        tile = board.map.land_tiles[(-1, 0, 1)]

    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_city(Color.RED, 3)
    freqdeck_draw(resource_freqdeck, 18, tile.resource)  # type: ignore

    payout, depleted = yield_resources(board, resource_freqdeck, tile.number)
    assert depleted == [tile.resource]
    assert (
        Color.RED not in payout or freqdeck_count(payout[Color.RED], tile.resource) == 0  # type: ignore
    )

--- tests/utils.py ---
from catanatron.game import Game
from catanatron.models.enums import Action, ActionType


def build_initial_placements(
    game: Game,
    p0_actions=[0, (0, 1), 2, (1, 2)],
    p1_actions=[24, (24, 25), 26, (25, 26)],
):
    p0_color = game.state.colors[0]
    p1_color = game.state.colors[1]
    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, p0_actions[0]))
    game.execute(Action(p0_color, ActionType.BUILD_ROAD, p0_actions[1]))

    game.execute(Action(p1_color, ActionType.BUILD_SETTLEMENT, p1_actions[0]))
    game.execute(Action(p1_color, ActionType.BUILD_ROAD, p1_actions[1]))
    game.execute(Action(p1_color, ActionType.BUILD_SETTLEMENT, p1_actions[2]))
    game.execute(Action(p1_color, ActionType.BUILD_ROAD, p1_actions[3]))

    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, p0_actions[2]))
    game.execute(Action(p0_color, ActionType.BUILD_ROAD, p0_actions[3]))


def advance_to_play_turn(game):
    game.execute(Action(game.state.current_color(), ActionType.ROLL, None))
    while game.state.playable_actions[0].action_type in [
        ActionType.DISCARD,
        ActionType.MOVE_ROBBER,
    ]:
        game.execute(game.state.playable_actions[0])


def end_turn(game):
    game.execute(Action(game.state.current_color(), ActionType.END_TURN, None))

--- tests/__init__.py ---

--- tests/integration_tests/test_play.py ---
from click.testing import CliRunner

from catanatron_experimental.play import simulate


def test_play():
    runner = CliRunner()
    result = runner.invoke(simulate, ["--num=5", "--players=R,R,R,W"])
    assert result.exit_code == 0
    assert "Game Summary" in result.output

--- tests/integration_tests/test_replay.py ---
import json

from catanatron.models.player import Color, RandomPlayer, SimplePlayer
from catanatron.json import GameEncoder
from catanatron.game import Game
from catanatron.models.enums import VICTORY_POINT, Action, ActionType, CITY, SETTLEMENT
from catanatron.state_functions import (
    get_actual_victory_points,
    get_dev_cards_in_hand,
    get_largest_army,
    get_longest_road_color,
    get_player_buildings,
)


def test_play_many_games():
    for _ in range(10):  # play 10 games
        players = [
            RandomPlayer(Color.RED),
            RandomPlayer(Color.BLUE),
            RandomPlayer(Color.WHITE),
            RandomPlayer(Color.ORANGE),
        ]
        game = Game(players)
        game.play()

        # Assert everything looks good
        for color in game.state.colors:
            cities = len(get_player_buildings(game.state, color, CITY))
            settlements = len(get_player_buildings(game.state, color, SETTLEMENT))
            longest = get_longest_road_color(game.state) == color
            largest = get_largest_army(game.state)[0] == color
            devvps = get_dev_cards_in_hand(game.state, color, VICTORY_POINT)
            assert (
                settlements + 2 * cities + 2 * longest + 2 * largest + devvps
            ) == get_actual_victory_points(game.state, color)


def test_copy():
    """Play 30 moves, copy game, ensure they look the same but not the same."""
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    for i in range(30):
        game.play_tick()

    game_copy = game.copy()
    assert json.dumps(game, cls=GameEncoder) == json.dumps(game_copy, cls=GameEncoder)
    assert game_copy != game


def test_execute_action_on_copies_doesnt_conflict():
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players)
    p0_color = game.state.colors[0]
    game.execute(Action(p0_color, ActionType.BUILD_SETTLEMENT, 0))

    action = Action(p0_color, ActionType.BUILD_ROAD, (0, 1))

    game_copy = game.copy()
    game_copy.execute(action)

    game_copy = game.copy()
    game_copy.execute(action)

    game.execute(action)

--- tests/integration_tests/test_server.py ---
import pytest
import json

from catanatron_server import create_app
from catanatron_server.models import db


@pytest.fixture
def app():
    """Create and configure a new app instance for each test."""
    # create the app with common test config
    app = create_app({"TESTING": True, "SQLALCHEMY_DATABASE_URI": "sqlite:///:memory:"})

    yield app


@pytest.fixture
def client(app):
    """A test client for the app."""
    return app.test_client()


def test_create_game_get_game_and_run_action(client):
    response = client.post(
        "/api/games",
        data=json.dumps({"players": ["RANDOM", "HUMAN"]}),
        content_type="application/json",
    )
    response_json = response.get_json()
    assert response.status_code == 200
    assert response.is_json
    assert "game_id" in response_json
    game_id = response_json["game_id"]

    response = client.get(f"/api/games/{game_id}/states/latest")
    response_json = response.get_json()
    assert response.status_code == 200
    assert response.is_json
    assert "tiles" in response_json

    response = client.get(f"/api/games/{game_id}/states/0")
    state_zero = response.get_json()
    assert response.status_code == 200
    assert response.is_json
    assert "tiles" in state_zero
    assert response_json == state_zero

    response = client.post(f"/api/games/{game_id}/actions")
    response_json = response.get_json()
    assert response.status_code == 200
    assert response.is_json
    assert "tiles" in response_json

    response = client.get(f"/api/games/{game_id}/states/latest")
    response_json = response.get_json()
    response = client.get(f"/api/games/{game_id}/states/0")
    state_zero = response.get_json()
    assert response_json != state_zero


def test_game_not_exists(client):
    response = client.get("/api/games/123")
    assert response.status_code == 404

--- tests/integration_tests/test_speed.py ---
import json

from catanatron.game import Game
from catanatron.json import GameEncoder
from catanatron.models.player import Color, SimplePlayer, RandomPlayer
from catanatron.players.weighted_random import WeightedRandomPlayer
from catanatron_gym.features import create_sample
from catanatron_experimental.machine_learning.players.minimax import AlphaBetaPlayer, SameTurnAlphaBetaPlayer

RANDOM_SEED = 0


# Things to benchmark. create_sample(), game.play() (random game), .to_json(), .copy()
def test_to_json_speed(benchmark):
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.ORANGE),
        SimplePlayer(Color.WHITE),
    ]
    game = Game(players, seed=RANDOM_SEED)

    result = benchmark(json.dumps, game, cls=GameEncoder)
    assert isinstance(result, str)


def test_copy_speed(benchmark):
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.ORANGE),
        SimplePlayer(Color.WHITE),
    ]
    game = Game(players, seed=RANDOM_SEED)

    result = benchmark(game.copy)
    assert result.seed == game.seed


def test_create_sample_speed(benchmark):
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players, seed=RANDOM_SEED)
    for _ in range(30):
        game.play_tick()

    sample = benchmark(create_sample, game, players[1].color)
    assert isinstance(sample, dict)
    assert len(sample) > 0


# Benchmarking individual player speeds
def test_simpleplayer_speed(benchmark):
    players = [
        SimplePlayer(Color.RED),
        SimplePlayer(Color.BLUE),
        SimplePlayer(Color.WHITE),
        SimplePlayer(Color.ORANGE),
    ]
    game = Game(players, seed=RANDOM_SEED)
    def _play_game(game):
        for _ in range(100):
            game.play_tick()
        return game

    result = benchmark(_play_game, game)


def test_weightedrandom_speed(benchmark):
    players = [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        WeightedRandomPlayer(Color.ORANGE),
    ]
    game = Game(players, seed=RANDOM_SEED)
    def _play_game(game):
        for _ in range(100):
            game.play_tick()
        return game

    result = benchmark(_play_game, game)


def test_alphabeta_speed(benchmark):
    players = [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        AlphaBetaPlayer(Color.ORANGE),
    ]
    game = Game(players, seed=RANDOM_SEED)
    def _play_game(game):
        for _ in range(100):
            game.play_tick()
        return game

    result = benchmark(_play_game, game)


def test_same_turn_alphabeta_speed(benchmark):
    players = [
        RandomPlayer(Color.RED),
        RandomPlayer(Color.BLUE),
        RandomPlayer(Color.WHITE),
        SameTurnAlphaBetaPlayer(Color.ORANGE),
    ]
    game = Game(players, seed=RANDOM_SEED)
    def _play_game(game):
        for _ in range(100):
            game.play_tick()
        return game

    result = benchmark(_play_game, game)

--- tests/models/test_actions.py ---
from catanatron.state import (
    State,
    build_city,
    build_settlement,
    player_freqdeck_add,
    player_deck_replenish,
)
from catanatron.models.actions import (
    generate_playable_actions,
    monopoly_possibilities,
    year_of_plenty_possibilities,
    road_building_possibilities,
    settlement_possibilities,
    city_possibilities,
    robber_possibilities,
    maritime_trade_possibilities,
)
from catanatron.models.enums import (
    BRICK,
    ORE,
    RESOURCES,
    ActionType,
    WHEAT,
    WOOD,
)
from catanatron.models.player import Color, SimplePlayer
from catanatron.models.decks import (
    SETTLEMENT_COST_FREQDECK,
    starting_resource_bank,
)


def test_playable_actions():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    actions = generate_playable_actions(state)
    assert len(actions) == 54
    assert actions[0].action_type == ActionType.BUILD_SETTLEMENT


def test_year_of_plenty_possible_actions_full_resource_bank():
    bank_resource_freqdeck = starting_resource_bank()
    actions = year_of_plenty_possibilities(Color.RED, bank_resource_freqdeck)
    assert len(actions) == 15


def test_year_of_plenty_possible_actions_not_enough_cards():
    bank_resource_freqdeck = [0, 0, 0, 0, 2]
    actions = year_of_plenty_possibilities(Color.RED, bank_resource_freqdeck)
    assert len(actions) == 2  # one ORE, or 2 OREs.


def test_monopoly_possible_actions():
    assert len(monopoly_possibilities(Color.RED)) == len(RESOURCES)


def test_road_possible_actions():
    player = SimplePlayer(Color.RED)
    state = State([player])

    assert len(road_building_possibilities(state, Color.RED)) == 0  # no money or place

    state.board.build_settlement(Color.RED, 3, initial_build_phase=True)
    assert len(road_building_possibilities(state, Color.RED)) == 0  # no money

    player_deck_replenish(state, player.color, WOOD)
    player_deck_replenish(state, player.color, BRICK)
    assert len(road_building_possibilities(state, Color.RED)) == 3

    state.board.build_settlement(Color.RED, 1, initial_build_phase=True)
    assert len(road_building_possibilities(state, Color.RED)) == 6


def test_settlement_possible_actions():
    player = SimplePlayer(Color.RED)
    state = State([player])

    assert len(settlement_possibilities(state, Color.RED)) == 0  # no money or place

    state.board.build_settlement(Color.RED, 3, initial_build_phase=True)
    state.board.build_road(Color.RED, (3, 4))
    state.board.build_road(Color.RED, (4, 5))
    assert len(settlement_possibilities(state, Color.RED)) == 0  # no money

    player_freqdeck_add(state, player.color, SETTLEMENT_COST_FREQDECK)
    assert len(settlement_possibilities(state, Color.RED)) == 1

    state.board.build_road(Color.RED, (5, 0))
    assert len(settlement_possibilities(state, Color.RED)) == 2


def test_city_playable_actions():
    player = SimplePlayer(Color.RED)
    state = State([player])

    assert len(city_possibilities(state, Color.RED)) == 0  # no money or place

    state.board.build_settlement(Color.RED, 3, initial_build_phase=True)
    build_settlement(state, player.color, 3, True)
    assert len(city_possibilities(state, Color.RED)) == 0  # no money

    player_deck_replenish(state, Color.RED, WHEAT, 2)
    player_deck_replenish(state, Color.RED, ORE, 3)
    assert len(city_possibilities(state, Color.RED)) == 1

    state.board.build_settlement(Color.RED, 0, initial_build_phase=True)
    build_settlement(state, player.color, 0, True)
    assert len(city_possibilities(state, Color.RED)) == 2


def test_robber_possibilities():
    red = SimplePlayer(Color.RED)
    blue = SimplePlayer(Color.BLUE)
    orange = SimplePlayer(Color.ORANGE)
    players = [red, blue, orange]
    state = State(players)

    # one for each resource tile (excluding desert)
    assert len(robber_possibilities(state, Color.RED)) == 18

    # assert same number of possibilities, b.c. players have no cards.
    state.board.build_settlement(Color.BLUE, 3, initial_build_phase=True)
    state.board.build_settlement(Color.ORANGE, 0, initial_build_phase=True)
    assert len(robber_possibilities(state, Color.RED)) == 18

    # assert same number of possibilities, b.c. only one player to rob in this tile
    player_deck_replenish(state, orange.color, WHEAT)
    assert len(robber_possibilities(state, Color.RED)) == 18

    # now possibilites increase by 1 b.c. we have to decide to steal from blue or orange
    # Unless desert is (0,0,0)... in which case still at 18...
    player_deck_replenish(state, blue.color, WHEAT)
    possibilities = len(robber_possibilities(state, Color.RED))
    assert possibilities == 19 or (
        possibilities == 18 and state.board.map.land_tiles[(0, 0, 0)].resource is None
    )


def test_building_settlement_gives_vp():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    build_settlement(state, state.colors[0], 0, True)
    assert state.player_state["P0_VICTORY_POINTS"] == 1
    assert state.player_state["P0_ACTUAL_VICTORY_POINTS"] == 1


def test_building_city_gives_vp():
    players = [SimplePlayer(Color.RED), SimplePlayer(Color.BLUE)]
    state = State(players)

    build_settlement(state, state.colors[0], 0, True)
    player_deck_replenish(state, state.colors[0], WHEAT, 2)
    player_deck_replenish(state, state.colors[0], ORE, 2)
    build_city(state, state.colors[0], 0)
    assert state.player_state["P0_VICTORY_POINTS"] == 2
    assert state.player_state["P0_ACTUAL_VICTORY_POINTS"] == 2


def test_robber_possibilities_simple():
    red = SimplePlayer(Color.RED)
    blue = SimplePlayer(Color.BLUE)
    orange = SimplePlayer(Color.ORANGE)
    players = [red, blue, orange]
    state = State(players)

    # one for each resource tile (excluding desert)
    assert len(robber_possibilities(state, Color.RED)) == 18


def test_initial_placement_possibilities():
    red = SimplePlayer(Color.RED)
    state = State([red])
    assert len(settlement_possibilities(state, Color.RED, True)) == 54


# TODO: Forcing random selection to ease dimensionality.
# def test_discard_possibilities():
#     player = SimplePlayer(Color.RED)
#     player_deck_replenish(state, player.color, Resource.WHEAT)
#     assert len(discard_possibilities(player)) == 70


def test_4to1_maritime_trade_possibilities():
    player = SimplePlayer(Color.RED)
    state = State([player])

    possibilities = maritime_trade_possibilities(state, player.color)
    assert len(possibilities) == 0

    player_deck_replenish(state, player.color, WHEAT, 4)
    possibilities = maritime_trade_possibilities(state, player.color)
    print(possibilities)
    assert len(possibilities) == 4

    player_deck_replenish(state, player.color, BRICK, 4)
    possibilities = maritime_trade_possibilities(state, player.color)
    assert len(possibilities) == 8


def test_maritime_possibities_respect_bank_not_having_cards():
    player = SimplePlayer(Color.RED)
    state = State([player])
    player_deck_replenish(state, player.color, WHEAT)
    assert len(maritime_trade_possibilities(state, player.color)) == 0


def test_year_of_plenty_same_resource():
    bank = [0, 0, 0, 1, 0]

    actions = year_of_plenty_possibilities(Color.RED, bank)

    assert len(actions) == 1
    assert actions[0].value[0] == WHEAT


def test_can_trade_with_port():
    players = [SimplePlayer(Color.RED)]

    state = State(players)
    state.board.build_settlement(Color.RED, 26, initial_build_phase=True)

    port_tile = state.board.map.tiles[(3, -3, 0)]  # port with node_id=25,26
    resource_out = port_tile.resource or WHEAT  # type: ignore
    num_out = 3 if port_tile.resource is None else 2  # type: ignore
    player_deck_replenish(state, Color.RED, resource_out, num_out)

    possibilities = maritime_trade_possibilities(state, Color.RED)
    assert len(possibilities) == 4

--- tests/models/test_board.py ---
import pytest

from catanatron.models.map import MINI_MAP_TEMPLATE, CatanMap
from catanatron.models.enums import RESOURCES
from catanatron.models.board import Board, get_node_distances
from catanatron.models.player import Color


def test_initial_build_phase_bypasses_restrictions():
    board = Board()
    with pytest.raises(ValueError):  # not connected and not initial-placement
        board.build_settlement(Color.RED, 3)
    with pytest.raises(ValueError):  # not connected to settlement
        board.build_road(Color.RED, (3, 2))

    board.build_settlement(Color.RED, 3, initial_build_phase=True)


def test_roads_must_always_be_connected():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)

    with pytest.raises(ValueError):  # not connected to settlement
        board.build_road(Color.RED, (2, 1))
    board.build_road(Color.RED, (3, 2))
    board.build_road(Color.RED, (2, 1))
    board.build_road(Color.RED, (3, 4))


def test_must_build_distance_two():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))

    with pytest.raises(ValueError):  # distance less than 2
        board.build_settlement(Color.BLUE, 4, initial_build_phase=True)
    board.build_settlement(Color.BLUE, 1, initial_build_phase=True)


def test_placements_must_be_connected():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))

    with pytest.raises(ValueError):  # distance less than 2 (even if connected)
        board.build_settlement(Color.RED, 2)
    with pytest.raises(ValueError):  # not connected
        board.build_settlement(Color.RED, 1)

    board.build_road(Color.RED, (2, 1))
    board.build_settlement(Color.RED, 1)


def test_city_requires_settlement_first():
    board = Board()
    with pytest.raises(ValueError):  # no settlement there
        board.build_city(Color.RED, 3)

    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_city(Color.RED, 3)


def test_calling_the_edge_differently_is_not_a_problem():
    """Tests building on (0,0,0), East is the same as (1,-1,0), West"""
    pass


def test_get_ports():
    board = Board()
    ports = board.map.port_nodes
    for resource in RESOURCES:
        assert len(ports[resource]) == 2
    assert len(ports[None]) == 8


def test_node_distances():
    node_distances = get_node_distances()
    assert node_distances[2][3] == 1

    # Test are symmetric
    assert node_distances[0][3] == 3
    assert node_distances[3][0] == 3

    assert node_distances[3][9] == 2
    assert node_distances[3][29] == 4

    assert node_distances[34][32] == 2
    assert node_distances[31][45] == 11


# ===== Buildable nodes
def test_buildable_nodes():
    board = Board()
    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 0
    nodes = board.buildable_node_ids(Color.RED, initial_build_phase=True)
    assert len(nodes) == 54


def test_buildable_nodes_in_mini_map():
    board = Board(catan_map=CatanMap.from_template(MINI_MAP_TEMPLATE))
    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 0
    nodes = board.buildable_node_ids(Color.RED, initial_build_phase=True)
    assert len(nodes) == 24


def test_placing_settlement_removes_four_buildable_nodes():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 0
    nodes = board.buildable_node_ids(Color.RED, initial_build_phase=True)
    assert len(nodes) == 50
    nodes = board.buildable_node_ids(Color.BLUE, initial_build_phase=True)
    assert len(nodes) == 50


def test_buildable_nodes_respects_distance_two():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)

    board.build_road(Color.RED, (3, 4))
    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 0

    board.build_road(Color.RED, (4, 5))
    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 1
    assert nodes.pop() == 5


def test_cant_use_enemy_roads_to_connect():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))

    board.build_settlement(Color.BLUE, 1, initial_build_phase=True)
    board.build_road(Color.BLUE, (1, 2))
    board.build_road(Color.BLUE, (0, 1))
    board.build_road(Color.BLUE, (0, 20))  # north out of center tile

    nodes = board.buildable_node_ids(Color.RED)
    assert len(nodes) == 0

    nodes = board.buildable_node_ids(Color.BLUE)
    assert len(nodes) == 1


# ===== Buildable edges
def test_buildable_edges_simple():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    buildable = board.buildable_edges(Color.RED)
    assert len(buildable) == 3


def test_buildable_edges_in_mini():
    board = Board(catan_map=CatanMap.from_template(MINI_MAP_TEMPLATE))
    board.build_settlement(Color.RED, 19, initial_build_phase=True)
    buildable = board.buildable_edges(Color.RED)
    assert len(buildable) == 2


def test_buildable_edges():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 4))
    buildable = board.buildable_edges(Color.RED)
    assert len(buildable) == 4


def test_water_edge_is_not_buildable():
    board = Board()
    top_left_north_edge = 45
    board.build_settlement(Color.RED, top_left_north_edge, initial_build_phase=True)
    buildable = board.buildable_edges(Color.RED)
    assert len(buildable) == 2


# ===== Find connected components
def test_connected_components_empty_board():
    board = Board()
    components = board.find_connected_components(Color.RED)
    assert len(components) == 0


def test_one_connected_component():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))
    board.build_settlement(Color.RED, 1, initial_build_phase=True)
    board.build_road(Color.RED, (1, 2))
    components = board.find_connected_components(Color.RED)
    assert len(components) == 1

    board.build_road(Color.RED, (0, 1))
    components = board.find_connected_components(Color.RED)
    assert len(components) == 1


def test_two_connected_components():
    board = Board()
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 4))
    components = board.find_connected_components(Color.RED)
    assert len(components) == 1

    board.build_settlement(Color.RED, 1, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    components = board.find_connected_components(Color.RED)
    assert len(components) == 2


def test_three_connected_components_bc_enemy_cut_road():
    board = Board()
    # Initial Building Phase of 2 players:
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 4))

    board.build_settlement(Color.BLUE, 15, initial_build_phase=True)
    board.build_road(Color.BLUE, (15, 4))
    board.build_settlement(Color.BLUE, 34, initial_build_phase=True)
    board.build_road(Color.BLUE, (34, 13))

    board.build_settlement(Color.RED, 1, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))

    # Extend road in a risky way
    board.build_road(Color.RED, (5, 0))
    board.build_road(Color.RED, (5, 16))

    # Plow </3
    board.build_road(Color.BLUE, (5, 4))
    board.build_settlement(Color.BLUE, 5)

    components = board.find_connected_components(Color.RED)
    assert len(components) == 3


def test_connected_components():
    board = Board()
    assert board.find_connected_components(Color.RED) == []

    # Simple test: roads stay at component, disconnected settlement creates new
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))
    assert len(board.find_connected_components(Color.RED)) == 1
    assert len(board.find_connected_components(Color.RED)[0]) == 2

    # This is just to be realistic
    board.build_settlement(Color.BLUE, 13, initial_build_phase=True)
    board.build_road(Color.BLUE, (13, 14))
    board.build_settlement(Color.BLUE, 37, initial_build_phase=True)
    board.build_road(Color.BLUE, (37, 14))

    board.build_settlement(Color.RED, 0, initial_build_phase=True)
    board.build_road(Color.RED, (0, 1))
    assert len(board.find_connected_components(Color.RED)) == 2
    assert len(board.find_connected_components(Color.RED)[0]) == 2
    assert len(board.find_connected_components(Color.RED)[1]) == 2

    # Merging subcomponents
    board.build_road(Color.RED, (1, 2))
    assert len(board.find_connected_components(Color.RED)) == 1
    assert len(board.find_connected_components(Color.RED)[0]) == 4

    board.build_road(Color.RED, (3, 4))
    board.build_road(Color.RED, (4, 15))
    board.build_road(Color.RED, (15, 17))
    assert len(board.find_connected_components(Color.RED)) == 1

    # Enemy cutoff
    board.build_road(Color.BLUE, (14, 15))
    board.build_settlement(Color.BLUE, 15)
    assert len(board.find_connected_components(Color.RED)) == 2


def test_building_road_to_enemy_works_well():
    board = Board()

    board.build_settlement(Color.BLUE, 0, initial_build_phase=True)
    board.build_settlement(Color.RED, 3, initial_build_phase=True)
    board.build_road(Color.RED, (3, 2))
    board.build_road(Color.RED, (2, 1))
    board.build_road(Color.RED, (1, 0))

    # Test building towards enemy works well.
    assert len(board.find_connected_components(Color.RED)) == 1
    assert len(board.find_connected_components(Color.RED)[0]) == 3


def test_building_into_enemy_doesnt_merge_components():
    board = Board()

    board.build_settlement(Color.BLUE, 0, initial_build_phase=True)
    board.build_settlement(Color.RED, 16, initial_build_phase=True)
    board.build_settlement(Color.RED, 6, initial_build_phase=True)
    board.build_road(Color.RED, (16, 5))
    board.build_road(Color.RED, (5, 0))
    board.build_road(Color.RED, (6, 1))
    board.build_road(Color.RED, (1, 0))
    assert len(board.find_connected_components(Color.RED)) == 2


def test_enemy_edge_not_buildable():
    board = Board()
    board.build_settlement(Color.BLUE, 0, initial_build_phase=True)
    board.build_road(Color.BLUE, (0, 1))

    board.build_settlement(Color.RED, 2, initial_build_phase=True)
    board.build_road(Color.RED, (2, 1))
    buildable_edges = board.buildable_edges(Color.RED)
    assert len(buildable_edges) == 3


def test_many_buildings():
    board = Board()
    board.build_settlement(Color.ORANGE, 7, True)
    board.build_settlement(Color.ORANGE, 12, True)
    board.build_road(Color.ORANGE, (6, 7))
    board.build_road(Color.ORANGE, (7, 8))
    board.build_road(Color.ORANGE, (8, 9))
    board.build_road(Color.ORANGE, (8, 27))
    board.build_road(Color.ORANGE, (26, 27))
    board.build_road(Color.ORANGE, (9, 10))
    board.build_road(Color.ORANGE, (10, 11))
    board.build_road(Color.ORANGE, (11, 12))
    board.build_road(Color.ORANGE, (12, 13))
    board.build_road(Color.ORANGE, (13, 34))
    assert len(board.find_connected_components(Color.ORANGE)) == 1

    board.build_settlement(Color.WHITE, 30, True)
    board.build_road(Color.WHITE, (29, 30))
    board.build_road(Color.WHITE, (10, 29))
    board.build_road(Color.WHITE, (28, 29))
    board.build_road(Color.WHITE, (27, 28))
    board.build_settlement(Color.WHITE, 10)  # cut
    board.build_road(Color.WHITE, (30, 31))
    board.build_road(Color.WHITE, (31, 32))
    board.build_settlement(Color.WHITE, 32)
    board.build_road(Color.WHITE, (11, 32))
    board.build_road(Color.WHITE, (32, 33))
    board.build_road(Color.WHITE, (33, 34))
    board.build_settlement(Color.WHITE, 34)
    board.build_road(Color.WHITE, (34, 35))
    board.build_road(Color.WHITE, (35, 36))

    board.build_settlement(Color.WHITE, 41, True)
    board.build_city(Color.WHITE, 41)
    board.build_road(Color.WHITE, (41, 42))
    board.build_road(Color.WHITE, (40, 42))
    board.build_settlement(Color.WHITE, 27)  # cut

    assert len(board.find_connected_components(Color.WHITE)) == 2
    assert len(board.find_connected_components(Color.ORANGE)) == 3


# TODO: Test super long road, cut at many places, to yield 5+ component graph

--- tests/models/test_coordinate_system.py ---
from catanatron.models.coordinate_system import (
    cube_to_axial,
    cube_to_offset,
    offset_to_cube,
    num_tiles_for,
    generate_coordinate_system,
)


def test_num_tiles_for():
    assert num_tiles_for(0) == 1
    assert num_tiles_for(1) == 7
    assert num_tiles_for(2) == 19
    assert num_tiles_for(3) == 37


def test_generate_coordinate_system():
    assert generate_coordinate_system(0) == set([(0, 0, 0)])


def test_generate_coordinate_system_one_layer():
    assert generate_coordinate_system(1) == set(
        [
            (0, 0, 0),
            (1, -1, 0),
            (0, -1, 1),
            (-1, 0, 1),
            (-1, 1, 0),
            (0, 1, -1),
            (1, 0, -1),
        ]
    )


def test_generate_coordinate_system_two_layer():
    assert generate_coordinate_system(2) == set(
        [
            (0, 0, 0),  # center
            # first layer
            (1, -1, 0),
            (0, -1, 1),
            (-1, 0, 1),
            (-1, 1, 0),
            (0, 1, -1),
            (1, 0, -1),
            # second layer
            (2, -2, 0),
            (1, -2, 1),
            (0, -2, 2),
            (-1, -1, 2),
            (-2, 0, 2),
            (-2, 1, 1),
            (-2, 2, 0),  # westmost
            (-1, 2, -1),
            (0, 2, -2),
            (1, 1, -2),
            (2, 0, -2),
            (2, -1, -1),
        ]
    )


def test_cube_to_axial():
    assert cube_to_axial((0, 0, 0)) == (0, 0)
    assert cube_to_axial((2, 0, -2)) == (2, -2)
    assert cube_to_axial((0, 1, -1)) == (0, -1)


def test_cube_to_offset():
    assert cube_to_offset((0, 0, 0)) == (0, 0)
    assert cube_to_offset((1, -1, 0)) == (1, 0)
    assert cube_to_offset((0, 1, -1)) == (-1, -1)
    assert cube_to_offset((0, -2, 2)) == (1, 2)


def test_offset_to_cube():
    assert offset_to_cube((0, 0)) == (0, 0, 0)
    assert offset_to_cube((1, 0)) == (1, -1, 0)
    assert offset_to_cube((-1, -1)) == (0, 1, -1)
    assert offset_to_cube((1, 2)) == (0, -2, 2)

--- tests/models/test_decks.py ---
from catanatron.models.enums import (
    KNIGHT,
    ORE,
    SHEEP,
    VICTORY_POINT,
    BRICK,
    WHEAT,
    WOOD,
)
from catanatron.models.decks import (
    draw_from_listdeck,
    freqdeck_add,
    freqdeck_from_listdeck,
    freqdeck_replenish,
    freqdeck_can_draw,
    freqdeck_count,
    freqdeck_draw,
    freqdeck_replenish,
    freqdeck_subtract,
    starting_devcard_bank,
    starting_devcard_proba,
    starting_resource_bank,
)


def test_resource_freqdeck_init():
    deck = starting_resource_bank()
    assert deck[0] == 19


def test_resource_freqdeck_can_draw():
    deck = starting_resource_bank()
    assert freqdeck_can_draw(deck, 10, BRICK)
    assert not freqdeck_can_draw(deck, 20, BRICK)


def test_resource_freqdeck_integration():
    deck = starting_resource_bank()
    assert freqdeck_count(deck, WHEAT) == 19
    assert sum(deck) == 19 * 5

    assert freqdeck_can_draw(deck, 10, WHEAT)
    freqdeck_draw(deck, 10, WHEAT)
    assert freqdeck_count(deck, WHEAT) == 9

    freqdeck_draw(deck, 9, WHEAT)
    assert freqdeck_count(deck, WHEAT) == 0

    freqdeck_replenish(deck, 2, WHEAT)
    assert freqdeck_count(deck, WHEAT) == 2

    freqdeck_draw(deck, 1, WHEAT)
    assert freqdeck_count(deck, WHEAT) == 1


def test_can_add():
    a = [0, 0, 0, 0, 0]
    b = [0, 0, 0, 0, 0]

    freqdeck_replenish(a, 10, ORE)
    freqdeck_replenish(b, 1, ORE)

    assert freqdeck_count(a, ORE) == 10
    assert freqdeck_count(b, ORE) == 1
    b = freqdeck_add(b, a)
    assert freqdeck_count(a, ORE) == 10
    assert freqdeck_count(b, ORE) == 11


def test_can_subtract():
    a = [0, 0, 0, 0, 0]
    b = [0, 0, 0, 0, 0]

    freqdeck_replenish(a, 13, SHEEP)
    freqdeck_replenish(b, 4, SHEEP)

    assert freqdeck_count(a, SHEEP) == 13
    assert freqdeck_count(b, SHEEP) == 4

    freqdeck_replenish(b, 11, SHEEP)  # now has 15
    b = freqdeck_subtract(b, a)
    assert freqdeck_count(a, SHEEP) == 13
    assert freqdeck_count(b, SHEEP) == 2


def test_from_array():
    a = freqdeck_from_listdeck([BRICK, BRICK, WOOD])
    assert sum(a) == 3
    assert freqdeck_count(a, BRICK) == 2
    assert freqdeck_count(a, WOOD) == 1


def test_deck_proba():
    assert starting_devcard_proba(KNIGHT) == 14 / 25
    assert starting_devcard_proba(VICTORY_POINT) == 5 / 25


def test_draw_from_listdeck():
    listdeck = [1, 2, 2, 4]
    draw_from_listdeck(listdeck, 1, 2)
    assert listdeck == [1, 2, 4]

--- tests/models/test_map.py ---
from catanatron import WOOD, BRICK
from catanatron.models.map import (
    BASE_MAP_TEMPLATE,
    MINI_MAP_TEMPLATE,
    CatanMap,
    LandTile,
    get_nodes_and_edges,
    get_node_counter_production,
    DICE_PROBAS,
)


def test_node_production_of_same_resource_adjacent_tile():
    # See https://github.com/bcollazo/catanatron/issues/263.
    adjacent_tiles = {
        1: [
            LandTile(1, WOOD, 8, dict(), dict()),
            LandTile(2, WOOD, 6, dict(), dict()),
            LandTile(3, WOOD, 12, dict(), dict()),
        ]
    }
    result = get_node_counter_production(adjacent_tiles, 1)
    assert result["WOOD"] == DICE_PROBAS[12] + DICE_PROBAS[6] + DICE_PROBAS[8]


def test_mini_map_can_be_created():
    mini = CatanMap.from_template(MINI_MAP_TEMPLATE)
    assert len(mini.land_tiles) == 7
    assert len(mini.land_nodes) == 24
    assert len(mini.tiles_by_id) == 7
    assert len(mini.ports_by_id) == 0
    assert len(mini.port_nodes) == 0
    assert len(mini.adjacent_tiles) == 24
    assert len(mini.node_production) == 24

    resources = [i.resource for i in mini.land_tiles.values()]
    assert any(isinstance(i, str) for i in resources)
    assert any(i is None for i in resources)  # theres one desert


def test_base_map_can_be_created():
    catan_map = CatanMap.from_template(BASE_MAP_TEMPLATE)
    assert len(catan_map.land_tiles) == 19
    assert len(catan_map.node_production) == 54


def test_get_nodes_and_edges_on_empty_board():
    nodes, edges, node_autoinc = get_nodes_and_edges({}, (0, 0, 0), 0)
    assert max(map(lambda n: n, nodes.values())) == 5


def test_get_nodes_and_edges_for_east_attachment():
    nodes1, edges1, node_autoinc = get_nodes_and_edges({}, (0, 0, 0), 0)
    nodes2, edges2, node_autoinc = get_nodes_and_edges(
        {(0, 0, 0): LandTile(0, WOOD, 3, nodes1, edges1)},
        (1, -1, 0),
        node_autoinc,
    )
    assert max(map(lambda n: n, nodes2.values())) == 9
    assert len(edges2.values()) == 6


def test_get_nodes_and_edges_for_east_and_southeast_attachment():
    nodes1, edges1, node_autoinc = get_nodes_and_edges({}, (0, 0, 0), 0)
    nodes2, edges2, node_autoinc = get_nodes_and_edges(
        {(0, 0, 0): LandTile(0, WOOD, 3, nodes1, edges1)},
        (1, -1, 0),
        node_autoinc,
    )
    nodes3, edges3, node_autoinc = get_nodes_and_edges(
        {
            (0, 0, 0): LandTile(1, WOOD, 3, nodes1, edges1),
            (1, -1, 0): LandTile(2, BRICK, 6, nodes2, edges2),
        },
        (0, -1, 1),
        node_autoinc,
    )
    assert max(map(lambda n: n, nodes3.values())) == 12
    assert len(edges3.values()) == 6

--- tests/models/test_player.py ---
from catanatron.state import (
    State,
    player_clean_turn,
    player_can_play_dev,
    player_deck_replenish,
)
from catanatron.models.player import Color, SimplePlayer


def test_playable_cards():
    player = SimplePlayer(Color.RED)

    state = State([player])
    player_deck_replenish(state, Color.RED, "KNIGHT")
    player_clean_turn(state, Color.RED)

    assert player_can_play_dev(state, Color.RED, "KNIGHT")

--- ui/src/actions.js ---
const ACTIONS = Object.freeze({
  SET_LEFT_DRAWER_OPENED: "SET_LEFT_DRAWER_OPENED",
  SET_GAME_STATE: "SET_GAME_STATE",

  SET_IS_BUILDING_ROAD: "SET_IS_BUILDING_ROAD",
  SET_IS_BUILDING_SETTLEMENT: "SET_IS_BUILDING_SETTLEMENT",
  SET_IS_BUILDING_CITY: "SET_IS_BUILDING_CITY",
});

export default ACTIONS;

--- ui/src/App.js ---
import React from "react";
import { BrowserRouter as Router, Switch, Route } from "react-router-dom";
import { SnackbarProvider } from "notistack";
import { createMuiTheme, ThemeProvider } from "@material-ui/core/styles";
import { blue, green } from "@material-ui/core/colors";
import Fade from "@material-ui/core/Fade";

import GameScreen from "./pages/GameScreen";
import HomePage from "./pages/HomePage";
import { StateProvider } from "./store";

import "./App.scss";

const theme = createMuiTheme({
  palette: {
    primary: {
      main: blue[900],
    },
    secondary: {
      main: green[900],
    },
  },
});

function App() {
  return (
    <ThemeProvider theme={theme}>
      <StateProvider>
        <SnackbarProvider
          classes={{ containerRoot: ["snackbar-container"] }}
          maxSnack={1}
          autoHideDuration={1000}
          TransitionComponent={Fade}
          TransitionProps={{ timeout: 100 }}
        >
          <Router>
            <Switch>
              <Route path="/games/:gameId/states/:stateIndex">
                <GameScreen replayMode={true} />
              </Route>
              <Route path="/games/:gameId">
                <GameScreen replayMode={false} />
              </Route>
              <Route path="/" exact={true}>
                <HomePage />
              </Route>
            </Switch>
          </Router>
        </SnackbarProvider>
      </StateProvider>
    </ThemeProvider>
  );
}

export default App;

--- ui/src/App.scss ---
* {
  box-sizing: border-box;
}

.logo {
  font-family: "Bungee Inline", sans-serif;
}

--- ui/src/App.test.js ---
import React from 'react';
import { render } from '@testing-library/react';
import App from './App';

test('renders learn react link', () => {
  const { getByText } = render(<App />);
  const linkElement = getByText(/learn react/i);
  expect(linkElement).toBeInTheDocument();
});

--- ui/src/combined_source_code.txt ---
---------- C:\Users\mason\programming\catanatron\ui\src\components\LeftDrawer.js ---------- 
import React, { useCallback, useContext } from "react";
import cn from "classnames";
import SwipeableDrawer from "@material-ui/core/SwipeableDrawer";
import Divider from "@material-ui/core/Divider";
import Drawer from "@material-ui/core/Drawer";
import { Hidden } from "@material-ui/core";

import PlayerStateBox from "../components/PlayerStateBox";
import { humanizeAction } from "../components/Prompt";
import { store } from "../store";
import ACTIONS from "../actions";
import { playerKey } from "../utils/stateUtils";

import "./LeftDrawer.scss";

function DrawerContent({ gameState }) {
  const playerSections = gameState.colors.map((color) => {
    const key = playerKey(gameState, color);
    return (
      <React.Fragment key={color}>
        <PlayerStateBox
          playerState={gameState.player_state}
          playerKey={key}
          color={color}
        />
        <Divider />
      </React.Fragment>
    );
  });

  return (
    <>
      {playerSections}
      <div className="log">
        {gameState.actions
          .slice()
          .reverse()
          .map((action, i) => (
            <div key={i} className={cn("action foreground", action)}>
              {humanizeAction(gameState, action)}
            </div>
          ))}
      </div>
    </>
  );
}

export default function LeftDrawer() {
  const { state, dispatch } = useContext(store);
  const iOS = process.browser && /iPad|iPhone|iPod/.test(navigator.userAgent);

  const openLeftDrawer = useCallback(
    (event) => {
      if (
        event &&
        event.type === "keydown" &&
        (event.key === "Tab" || event.key === "Shift")
      ) {
        return;
      }

      dispatch({ type: ACTIONS.SET_LEFT_DRAWER_OPENED, data: true });
    },
    [dispatch]
  );
  const closeLeftDrawer = useCallback(
    (event) => {
      if (
        event &&
        event.type === "keydown" &&
        (event.key === "Tab" || event.key === "Shift")
      ) {
        return;
      }

      dispatch({ type: ACTIONS.SET_LEFT_DRAWER_OPENED, data: false });
    },
    [dispatch]
  );

  return (
    <>
      <Hidden mdUp implementation="js">
        <SwipeableDrawer
          className="left-drawer"
          anchor="left"
          open={state.isLeftDrawerOpen}
          onClose={closeLeftDrawer}
          onOpen={openLeftDrawer}
          disableBackdropTransition={!iOS}
          disableDiscovery={iOS}
          onKeyDown={closeLeftDrawer}
        >
          <DrawerContent gameState={state.gameState} />
        </SwipeableDrawer>
      </Hidden>
      <Hidden smDown implementation="css">
        <Drawer className="left-drawer" anchor="left" variant="permanent" open>
          <DrawerContent gameState={state.gameState} />
        </Drawer>
      </Hidden>
    </>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\PlayerStateBox.js ---------- 
import React from "react";
import cn from "classnames";

import "./PlayerStateBox.scss";
import { Paper } from "@material-ui/core";

export function ResourceCards({ playerState, playerKey }) {
  const amount = (card) => playerState[`${playerKey}_${card}_IN_HAND`];
  return (
    <div className="resource-cards" title="Resource Cards">
      {amount("WOOD") !== 0 && (
        <div className="wood-cards center-text card">
          <Paper>{amount("WOOD")}</Paper>
        </div>
      )}
      {amount("BRICK") !== 0 && (
        <div className="brick-cards center-text card">
          <Paper>{amount("BRICK")}</Paper>
        </div>
      )}
      {amount("SHEEP") !== 0 && (
        <div className="sheep-cards center-text card">
          <Paper>{amount("SHEEP")}</Paper>
        </div>
      )}
      {amount("WHEAT") !== 0 && (
        <div className="wheat-cards center-text card">
          <Paper>{amount("WHEAT")}</Paper>
        </div>
      )}
      {amount("ORE") !== 0 && (
        <div className="ore-cards center-text card">
          <Paper>{amount("ORE")}</Paper>
        </div>
      )}
      <div className="separator"></div>
      {amount("VICTORY_POINT") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("VICTORY_POINT") + " Victory Point Card(s)"}
        >
          <Paper>
            <span>{amount("VICTORY_POINT")}</span>
            <span>VP</span>
          </Paper>
        </div>
      )}
      {amount("KNIGHT") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("KNIGHT") + " Knight Card(s)"}
        >
          <Paper>
            <span>{amount("KNIGHT")}</span>
            <span>KN</span>
          </Paper>
        </div>
      )}
      {amount("MONOPOLY") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("MONOPOLY") + " Monopoly Card(s)"}
        >
          <Paper>
            <span>{amount("MONOPOLY")}</span>
            <span>MO</span>
          </Paper>
        </div>
      )}
      {amount("YEAR_OF_PLENTY") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("YEAR_OF_PLENTY") + " Year of Plenty Card(s)"}
        >
          <Paper>
            <span>{amount("YEAR_OF_PLENTY")}</span>
            <span>YP</span>
          </Paper>
        </div>
      )}
      {amount("ROAD_BUILDING") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("ROAD_BUILDING") + " Road Building Card(s)"}
        >
          <Paper>
            <span>{amount("ROAD_BUILDING")}</span>
            <span>RB</span>
          </Paper>
        </div>
      )}
    </div>
  );
}

export default function PlayerStateBox({ playerState, playerKey, color }) {
  const actualVps = playerState[`${playerKey}_ACTUAL_VICTORY_POINTS`];
  return (
    <div className={cn("player-state-box foreground", color)}>
      <ResourceCards playerState={playerState} playerKey={playerKey} />
      <div className="scores">
        <div
          className={cn("num-knights center-text", {
            bold: playerState[`${playerKey}_HAS_ARMY`],
          })}
          title="Knights Played"
        >
          <span>{playerState[`${playerKey}_PLAYED_KNIGHT`]}</span>
          <small>knights</small>
        </div>
        <div
          className={cn("num-roads center-text", {
            bold: playerState[`${playerKey}_HAS_ROAD`],
          })}
          title="Longest Road"
        >
          {playerState[`${playerKey}_LONGEST_ROAD_LENGTH`]}
          <small>roads</small>
        </div>
        <div
          className={cn("victory-points center-text", {
            bold: actualVps >= 10,
          })}
          title="Victory Points"
        >
          {actualVps}
          <small>VPs</small>
        </div>
      </div>
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\Prompt.js ---------- 
import React from "react";
import { isPlayersTurn } from "../utils/stateUtils";

import "./Prompt.scss";

function findTileByCoordinate(gameState, coordinate) {
  for (const tile of Object.values(gameState.tiles)) {
    if (JSON.stringify(tile.coordinate) === JSON.stringify(coordinate)) {
      return tile;
    }
  }
}

function findTileById(gameState, tileId) {
  return gameState.tiles[tileId];
}

function getTileString(tile) {
  return `${tile.tile.number} ${tile.tile.resource}`;
}

function getShortTileString(tileTile) {
  return tileTile.number || tileTile.type;
}

export function humanizeAction(gameState, action) {
  const botColors = gameState.bot_colors;
  const player = botColors.includes(action[0]) ? "BOT" : "YOU";
  switch (action[1]) {
    case "ROLL":
      return `${player} ROLLED A ${action[2][0] + action[2][1]}`;
    case "DISCARD":
      return `${player} DISCARDED`;
    case "BUY_DEVELOPMENT_CARD":
      return `${player} BOUGHT DEVELOPMENT CARD`;
    case "BUILD_SETTLEMENT":
    case "BUILD_CITY": {
      const parts = action[1].split("_");
      const building = parts[parts.length - 1];
      const tileId = action[2];
      const tiles = gameState.adjacent_tiles[tileId];
      const tileString = tiles.map(getShortTileString).join("-");
      return `${player} BUILT ${building} ON ${tileString}`;
    }
    case "BUILD_ROAD": {
      const edge = action[2];
      const a = gameState.adjacent_tiles[edge[0]].map((t) => t.id);
      const b = gameState.adjacent_tiles[edge[1]].map((t) => t.id);
      const intersection = a.filter((t) => b.includes(t));
      const tiles = intersection.map(
        (tileId) => findTileById(gameState, tileId).tile
      );
      const edgeString = tiles.map(getShortTileString).join("-");
      return `${player} BUILT ROAD ON ${edgeString}`;
    }
    case "PLAY_KNIGHT_CARD": {
      return `${player} PLAYED KNIGHT CARD`;
    }
    case "PLAY_YEAR_OF_PLENTY": {
      return `${player} YEAR OF PLENTY ${action[2]}`;
    }
    case "MOVE_ROBBER": {
      const tile = findTileByCoordinate(gameState, action[2][0]);
      const tileString = getTileString(tile);
      return `${player} ROBBED ${tileString} (STOLE ${action[2][2]})`;
    }
    case "MARITIME_TRADE": {
      const label = humanizeTradeAction(action);
      return `${player} TRADED ${label}`;
    }
    case "END_TURN":
      return `${player} ENDED TURN`;
    default:
      return `${player} ${action.slice(1)}`;
  }
}

export function humanizeTradeAction(action) {
  const out = action[2].slice(0, 4).filter((resource) => resource !== null);
  return `${out.length} ${out[0]} => ${action[2][4]}`;
}

function humanizePrompt(current_prompt) {
  switch (current_prompt) {
    case "ROLL":
      return `YOUR TURN`;
    case "PLAY_TURN":
      return `YOUR TURN`;
    case "BUILD_INITIAL_SETTLEMENT":
    case "BUILD_INITIAL_ROAD":
    default: {
      const prompt = current_prompt.replaceAll("_", " ");
      return `PLEASE ${prompt}`;
    }
  }
}

export default function Prompt({ gameState, isBotThinking }) {
  let prompt = "";
  if (isBotThinking) {
    // Do nothing, but still render.
  } else if (gameState.winning_color) {
    prompt = `Game Over. Congrats, ${gameState.winning_color}!`;
  } else if (isPlayersTurn(gameState)) {
    prompt = humanizePrompt(gameState.current_prompt);
  } else {
    // prompt = humanizeAction(gameState.actions[gameState.actions.length - 1], gameState.bot_colors);
  }
  return <div className="prompt">{prompt}</div>;
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\Snackbar.js ---------- 
import React from "react";
import { IconButton } from "@material-ui/core";
import CloseIcon from "@material-ui/icons/Close";
import { humanizeAction } from "./Prompt";

export const snackbarActions = (closeSnackbar) => (key) =>
  (
    <>
      <IconButton
        size="small"
        aria-label="close"
        color="inherit"
        onClick={() => closeSnackbar(key)}
      >
        <CloseIcon fontSize="small" />
      </IconButton>
    </>
  );

export function dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState) {
  enqueueSnackbar(humanizeAction(gameState, gameState.actions.slice(-1)[0]), {
    action: snackbarActions(closeSnackbar),
    onClick: () => {
      closeSnackbar();
    },
  });
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\LeftDrawer.scss ---------- 
@import "../variables.scss";

$dark-divider: rgb(0 0 0 / 80%);

.left-drawer {
  .MuiDrawer-paper {
    width: 280px;
    background: $dark-gray;
  }

  .MuiDivider-root {
    background: $dark-divider;
  }

  .MuiDrawer-paperAnchorDockedLeft {
    border-color: $dark-divider;
  }

  .log {
    overflow-y: auto;
    font-size: 0.8rem;

    // To ensure always clipped towards bottom
    display: flex;
    flex-direction: column-reverse;
    .action {
      padding: $sm-gutter;
    }
  }
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\PlayerStateBox.scss ---------- 
@import "../variables.scss";

.resource-cards {
  height: 40px;
  display: flex;
  gap: 6px;

  margin-bottom: $sm-gutter;

  .card {
    border-radius: 4px;
    div {
      background: #151313;
      color: white;

      width: 21px;
      height: 36px;

      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-size: 0.8rem;
      font-weight: bold;
      position: relative;
    }
  }
  .wood-cards {
    background: $wood;
  }
  .brick-cards {
    background: $brick;
  }
  .wheat-cards {
    background: $wheat;
  }
  .sheep-cards {
    background: $darker-sheep;
  }
  .ore-cards {
    background: $ore;
  }
  .dev-cards {
    background: purple;
    div {
      font-size: 0.7rem;
    }
  }
}

.center-text {
  display: flex;
  justify-content: center;
  align-items: center;

  width: 25px;
  height: 40px;
}

.player-state-box {
  padding: $sm-gutter;

  max-width: $sm-breakpoint;
  margin: 0 auto;
  width: 100%;

  .scores {
    display: flex;
    justify-content: space-between;
  }

  .num-knights,
  .num-roads,
  .victory-points {
    flex-direction: column;
    width: 50px;
    height: 40px;
  }

  .bold {
    font-weight: bold;
  }
}
---------- C:\Users\mason\programming\catanatron\ui\src\components\Prompt.scss ---------- 
@import "../variables.scss";

.prompt {
  padding: $sm-gutter;

  height: 60px;
  width: 100%;
  font-size: 1rem;

  text-align: left;
  display: flex;
  flex-direction: column;
  align-items: center;

  overflow-x: auto;
  white-space: nowrap;
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\ActionsToolbar.js ---------- 
import React, {
  useState,
  useRef,
  useEffect,
  useContext,
  useCallback,
} from "react";
import memoize from "fast-memoize";
import { Button, Hidden } from "@material-ui/core";
import ChevronLeftIcon from "@material-ui/icons/ChevronLeft";
import AccountBalanceIcon from "@material-ui/icons/AccountBalance";
import BuildIcon from "@material-ui/icons/Build";
import NavigateNextIcon from "@material-ui/icons/NavigateNext";
import MenuItem from "@material-ui/core/MenuItem";
import ClickAwayListener from "@material-ui/core/ClickAwayListener";
import Grow from "@material-ui/core/Grow";
import Paper from "@material-ui/core/Paper";
import Popper from "@material-ui/core/Popper";
import MenuList from "@material-ui/core/MenuList";
import SimCardIcon from "@material-ui/icons/SimCard";
import { useParams } from "react-router";

import { ResourceCards } from "../components/PlayerStateBox";
import Prompt, { humanizeTradeAction } from "../components/Prompt";
import { store } from "../store";
import ACTIONS from "../actions";
import { getHumanColor, playerKey } from "../utils/stateUtils";
import { postAction } from "../utils/apiClient";

import "./ActionsToolbar.scss";
import { useSnackbar } from "notistack";
import { dispatchSnackbar } from "../components/Snackbar";

function PlayButtons() {
  const { gameId } = useParams();
  const { state, dispatch } = useContext(store);
  const { enqueueSnackbar, closeSnackbar } = useSnackbar();

  const carryOutAction = useCallback(
    memoize((action) => async () => {
      const gameState = await postAction(gameId, action);
      dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
    }),
    [enqueueSnackbar, closeSnackbar]
  );

  const { gameState } = state;
  const key = playerKey(gameState, gameState.current_color);
  const isRoll =
    gameState.current_prompt === "PLAY_TURN" &&
    !gameState.player_state[`${key}_HAS_ROLLED`];
  const isDiscard = gameState.current_prompt === "DISCARD";
  const isMove = gameState.current_prompt === "MOVE_ROBBER";
  const playableDevCardTypes = new Set(
    gameState.current_playable_actions
      .filter((action) => action[1].startsWith("PLAY"))
      .map((action) => action[1])
  );
  const useItems = [
    {
      label: "Monopoly",
      disabled: !playableDevCardTypes.has("PLAY_MONOPOLY"),
    },
    {
      label: "Year of Plenty",
      disabled: !playableDevCardTypes.has("PLAY_YEAR_OF_PLENTY"),
    },
    {
      label: "Road Building",
      disabled: !playableDevCardTypes.has("PLAY_ROAD_BUILDING"),
    },
    {
      label: "Knight",
      disabled: !playableDevCardTypes.has("PLAY_KNIGHT_CARD"),
    },
  ];

  const buildActionTypes = new Set(
    state.gameState.is_initial_build_phase
      ? []
      : state.gameState.current_playable_actions
          .filter(
            (action) =>
              action[1].startsWith("BUY") || action[1].startsWith("BUILD")
          )
          .map((a) => a[1])
  );
  const humanColor = getHumanColor(state.gameState);
  const buyDevCard = useCallback(async () => {
    const action = [humanColor, "BUY_DEVELOPMENT_CARD", null];
    const gameState = await postAction(gameId, action);
    dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
    dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
  }, [gameId, dispatch, enqueueSnackbar, closeSnackbar, humanColor]);
  const setIsBuildingSettlement = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_SETTLEMENT });
  }, [dispatch]);
  const setIsBuildingCity = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_CITY });
  }, [dispatch]);
  const setIsBuildingRoad = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_ROAD });
  }, [dispatch]);
  const buildItems = [
    {
      label: "Development Card",
      disabled: !buildActionTypes.has("BUY_DEVELOPMENT_CARD"),
      onClick: buyDevCard,
    },
    {
      label: "City",
      disabled: !buildActionTypes.has("BUILD_CITY"),
      onClick: setIsBuildingCity,
    },
    {
      label: "Settlement",
      disabled: !buildActionTypes.has("BUILD_SETTLEMENT"),
      onClick: setIsBuildingSettlement,
    },
    {
      label: "Road",
      disabled: !buildActionTypes.has("BUILD_ROAD"),
      onClick: setIsBuildingRoad,
    },
  ];

  const tradeActions = state.gameState.current_playable_actions.filter(
    (action) => action[1] === "MARITIME_TRADE"
  );
  const tradeItems = tradeActions.map((action) => {
    const label = humanizeTradeAction(action);
    return {
      label: label,
      disabled: false,
      onClick: carryOutAction(action),
    };
  });

  const rollAction = carryOutAction([humanColor, "ROLL", null]);
  const proceedAction = carryOutAction();
  const endTurnAction = carryOutAction([humanColor, "END_TURN", null]);
  return (
    <>
      <OptionsButton
        disabled={playableDevCardTypes.size === 0}
        menuListId="use-menu-list"
        icon={<SimCardIcon />}
        items={useItems}
      >
        Use
      </OptionsButton>
      <OptionsButton
        disabled={buildActionTypes.size === 0}
        menuListId="build-menu-list"
        icon={<BuildIcon />}
        items={buildItems}
      >
        Buy
      </OptionsButton>
      <OptionsButton
        disabled={tradeItems.length === 0}
        menuListId="trade-menu-list"
        icon={<AccountBalanceIcon />}
        items={tradeItems}
      >
        Trade
      </OptionsButton>
      <Button
        disabled={gameState.is_initial_build_phase}
        variant="contained"
        color="primary"
        startIcon={<NavigateNextIcon />}
        onClick={
          isRoll
            ? rollAction
            : isDiscard || isMove
            ? proceedAction
            : endTurnAction
        }
      >
        {isRoll ? "ROLL" : isDiscard ? "DISCARD" : isMove ? "ROB" : "END"}
      </Button>
    </>
  );
}

export default function ActionsToolbar({
  zoomIn,
  zoomOut,
  isBotThinking,
  replayMode,
}) {
  const { state, dispatch } = useContext(store);

  const openLeftDrawer = useCallback(() => {
    dispatch({
      type: ACTIONS.SET_LEFT_DRAWER_OPENED,
      data: true,
    });
  }, [dispatch]);

  const botsTurn = state.gameState.bot_colors.includes(
    state.gameState.current_color
  );
  const humanColor = getHumanColor(state.gameState);
  return (
    <>
      <div className="state-summary">
        <Hidden mdUp>
          <Button className="open-drawer-btn" onClick={openLeftDrawer}>
            <ChevronLeftIcon />
          </Button>
        </Hidden>
        {humanColor && (
          <ResourceCards
            playerState={state.gameState.player_state}
            playerKey={playerKey(state.gameState, humanColor)}
          />
        )}
      </div>
      <div className="actions-toolbar">
        {!(botsTurn || state.gameState.winning_color) && !replayMode && (
          <PlayButtons gameState={state.gameState} />
        )}
        {(botsTurn || state.gameState.winning_color) && (
          <Prompt gameState={state.gameState} isBotThinking={isBotThinking} />
        )}
        {/* <Button
          disabled={disabled}
          className="confirm-btn"
          variant="contained"
          color="primary"
          onClick={onTick}
        >
          Ok
        </Button> */}

        {/* <Button onClick={zoomIn}>Zoom In</Button>
      <Button onClick={zoomOut}>Zoom Out</Button> */}
      </div>
    </>
  );
}

function OptionsButton({ menuListId, icon, children, items, disabled }) {
  const [open, setOpen] = useState(false);
  const anchorRef = useRef(null);

  const handleToggle = () => {
    setOpen((prevOpen) => !prevOpen);
  };
  const handleClose = (onClick) => (event) => {
    if (anchorRef.current && anchorRef.current.contains(event.target)) {
      return;
    }

    onClick && onClick();
    setOpen(false);
  };
  function handleListKeyDown(event) {
    if (event.key === "Tab") {
      event.preventDefault();
      setOpen(false);
    }
  }
  // return focus to the button when we transitioned from !open -> open
  const prevOpen = useRef(open);
  useEffect(() => {
    if (prevOpen.current === true && open === false) {
      anchorRef.current.focus();
    }

    prevOpen.current = open;
  }, [open]);

  return (
    <React.Fragment>
      <Button
        disabled={disabled}
        ref={anchorRef}
        aria-controls={open ? menuListId : undefined}
        aria-haspopup="true"
        variant="contained"
        color="secondary"
        startIcon={icon}
        onClick={handleToggle}
      >
        {children}
      </Button>
      <Popper
        className="action-popover"
        open={open}
        anchorEl={anchorRef.current}
        role={undefined}
        transition
        disablePortal
      >
        {({ TransitionProps, placement }) => (
          <Grow
            {...TransitionProps}
            style={{
              transformOrigin:
                placement === "bottom" ? "center top" : "center bottom",
            }}
          >
            <Paper>
              <ClickAwayListener onClickAway={handleClose}>
                <MenuList
                  autoFocusItem={open}
                  id={menuListId}
                  onKeyDown={handleListKeyDown}
                >
                  {items.map((item) => (
                    <MenuItem
                      key={item.label}
                      onClick={handleClose(item.onClick)}
                      disabled={item.disabled}
                    >
                      {item.label}
                    </MenuItem>
                  ))}
                </MenuList>
              </ClickAwayListener>
            </Paper>
          </Grow>
        )}
      </Popper>
    </React.Fragment>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Board.js ---------- 
import React from "react";
import classnames from "classnames";

import { SQRT3 } from "../utils/coordinates";
import Tile from "./Tile";
import Node from "./Node";
import Edge from "./Edge";
import Robber from "./Robber";

import "./Board.scss";

/**
 * This uses the formulas: W = SQRT3 * size and H = 2 * size.
 * Math comes from https://www.redblobgames.com/grids/hexagons/.
 */
function computeDefaultSize(divWidth, divHeight) {
  const numLevels = 6; // 3 rings + 1/2 a tile for the outer water ring
  // divHeight = numLevels * (3h/4) + (h/4), implies:
  const maxSizeThatRespectsHeight = (4 * divHeight) / (3 * numLevels + 1) / 2;
  const correspondingWidth = SQRT3 * maxSizeThatRespectsHeight;
  let size;
  if (numLevels * correspondingWidth < divWidth) {
    // thus complete board would fit if we pick size based on height (height is limiting factor)
    size = maxSizeThatRespectsHeight;
  } else {
    // we'll have to decide size based on width.
    const maxSizeThatRespectsWidth = divWidth / numLevels / SQRT3;
    size = maxSizeThatRespectsWidth;
  }
  return size;
}

export default function Board({
  width,
  height,
  buildOnNodeClick,
  buildOnEdgeClick,
  nodeActions,
  edgeActions,
  replayMode,
  gameState,
  isMobile,
  show,
}) {
  // TODO: Keep in sync with CSS
  const containerHeight = height - 144 - 38 - 40;
  const containerWidth = isMobile ? width - 280 : width;
  const center = [containerWidth / 2, containerHeight / 2];
  const size = computeDefaultSize(containerWidth, containerHeight);
  if (!size) {
    return null;
  }

  const tiles = gameState.tiles.map(({ coordinate, tile }) => (
    <Tile
      key={coordinate}
      center={center}
      coordinate={coordinate}
      tile={tile}
      size={size}
    />
  ));
  const nodes = Object.values(gameState.nodes).map(
    ({ color, building, direction, tile_coordinate, id }) => (
      <Node
        key={id}
        id={id}
        center={center}
        size={size}
        coordinate={tile_coordinate}
        direction={direction}
        building={building}
        color={color}
        flashing={!replayMode && id in nodeActions}
        onClick={buildOnNodeClick(id, nodeActions[id])}
      />
    )
  );
  const edges = Object.values(gameState.edges).map(
    ({ color, direction, tile_coordinate, id }) => (
      <Edge
        id={id}
        key={id}
        center={center}
        size={size}
        coordinate={tile_coordinate}
        direction={direction}
        color={color}
        flashing={id in edgeActions}
        onClick={buildOnEdgeClick(id, edgeActions[id])}
      />
    )
  );
  return (
    <div className={classnames("board", { show })}>
      {tiles}
      {edges}
      {nodes}
      <Robber
        center={center}
        size={size}
        coordinate={gameState.robber_coordinate}
      />
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Edge.js ---------- 
import React from "react";
import cn from "classnames";

import { tilePixelVector, getEdgeTransform } from "../utils/coordinates";
import useWindowSize from "../utils/useWindowSize";

function Road({ color }) {
  return <div className={cn("road", color)}></div>;
}

export default function Edge({
  id,
  center,
  size,
  coordinate,
  direction,
  color,
  flashing,
  onClick,
}) {
  const { width } = useWindowSize();
  const [centerX, centerY] = center;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const transform = getEdgeTransform(direction, size, width);

  return (
    <div
      id={id}
      className={"edge " + direction}
      style={{
        left: tileX,
        top: tileY,
        width: size * 0.9,
        transform: transform,
      }}
      onClick={onClick}
    >
      {color && <Road color={color} />}
      {flashing && <div className="pulse"></div>}
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\GameScreen.js ---------- 
import React, { useEffect, useState, useContext } from "react";
import { useParams } from "react-router-dom";
import PropTypes from "prop-types";
import Loader from "react-loader-spinner";
import { useSnackbar } from "notistack";

import ZoomableBoard from "./ZoomableBoard";
import ActionsToolbar from "./ActionsToolbar";

import "react-loader-spinner/dist/loader/css/react-spinner-loader.css";
import "./GameScreen.scss";
import LeftDrawer from "../components/LeftDrawer";
import { store } from "../store";
import ACTIONS from "../actions";
import { getState, postAction } from "../utils/apiClient";
import { dispatchSnackbar } from "../components/Snackbar";
import { getHumanColor } from "../utils/stateUtils";

const ROBOT_THINKING_TIME = 300;

function GameScreen({ replayMode }) {
  const { gameId, stateIndex } = useParams();
  const { state, dispatch } = useContext(store);
  const { enqueueSnackbar, closeSnackbar } = useSnackbar();
  const [isBotThinking, setIsBotThinking] = useState(false);

  // Load game state
  useEffect(() => {
    if (!gameId) {
      return;
    }

    (async () => {
      const gameState = await getState(gameId, stateIndex);
      dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
    })();
  }, [gameId, stateIndex, dispatch]);

  // Maybe kick off next query?
  useEffect(() => {
    if (!state.gameState || replayMode) {
      return;
    }
    if (
      state.gameState.bot_colors.includes(state.gameState.current_color) &&
      !state.gameState.winning_color
    ) {
      // Make bot click next action.
      (async () => {
        setIsBotThinking(true);
        const start = new Date();
        const gameState = await postAction(gameId);
        const requestTime = new Date() - start;
        setTimeout(() => {
          // simulate thinking
          setIsBotThinking(false);
          dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
          if (getHumanColor(gameState)) {
            dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
          }
        }, ROBOT_THINKING_TIME - requestTime);
      })();
    }
  }, [
    gameId,
    replayMode,
    state.gameState,
    dispatch,
    enqueueSnackbar,
    closeSnackbar,
  ]);

  if (!state.gameState) {
    return (
      <main>
        <Loader
          className="loader"
          type="Grid"
          color="#000000"
          height={100}
          width={100}
        />
      </main>
    );
  }

  return (
    <main>
      <h1 className="logo">Catanatron</h1>
      <ZoomableBoard replayMode={replayMode} />
      <ActionsToolbar isBotThinking={isBotThinking} replayMode={replayMode} />
      <LeftDrawer />
    </main>
  );
}

GameScreen.propTypes = {
  /**
   * Injected by the documentation to work in an iframe.
   * You won't need it on your project.
   */
  window: PropTypes.func,
};

export default GameScreen;
---------- C:\Users\mason\programming\catanatron\ui\src\pages\HomePage.js ---------- 
import React, { useState } from "react";
import { useHistory } from "react-router-dom";

import "./HomePage.scss";
import { Button } from "@material-ui/core";
import Loader from "react-loader-spinner";
import { createGame } from "../utils/apiClient";

export default function HomePage() {
  const [loading, setLoading] = useState(false);
  const history = useHistory();

  const handleCreateGame = async (players) => {
    setLoading(true);
    const gameId = await createGame(players);
    setLoading(false);
    history.push("/games/" + gameId);
  };

  return (
    <div className="home-page">
      <h1 className="logo">Catanatron</h1>
      <div className="switchable">
        {!loading && (
          <>
            <ul>
              <li>1V1</li>
              <li>OPEN HAND</li>
              <li>NO CHOICE DURING DISCARD</li>
            </ul>
            <Button
              variant="contained"
              color="primary"
              onClick={() => handleCreateGame(["HUMAN", "CATANATRON"])}
            >
              Play against Catanatron
            </Button>
            <Button
              variant="contained"
              color="secondary"
              onClick={() => handleCreateGame(["RANDOM", "RANDOM"])}
            >
              Watch Random Bots
            </Button>
            <Button
              variant="contained"
              color="secondary"
              onClick={() => handleCreateGame(["CATANATRON", "CATANATRON"])}
            >
              Watch Catanatron
            </Button>
          </>
        )}
        {loading && (
          <Loader
            className="loader"
            type="Grid"
            color="#ffffff"
            height={60}
            width={60}
          />
        )}
      </div>
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Node.js ---------- 
import React from "react";
import cn from "classnames";

import { tilePixelVector, getNodeDelta, SQRT3 } from "../utils/coordinates";

function Building({ building, color }) {
  const type = building === "CITY" ? "city" : "settlement";
  return <div className={cn(color, type)}></div>;
}

export default function Node({
  id,
  center,
  size,
  coordinate,
  direction,
  building,
  color,
  flashing,
  onClick,
}) {
  const [centerX, centerY] = center;
  const w = SQRT3 * size;
  const h = 2 * size;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const [deltaX, deltaY] = getNodeDelta(direction, w, h);
  const x = tileX + deltaX;
  const y = tileY + deltaY;

  return (
    <div
      className="node"
      style={{
        width: size * 0.5,
        height: size * 0.5,
        left: x,
        top: y,
        transform: `translateY(-50%) translateX(-50%)`,
      }}
      onClick={onClick}
    >
      {color && <Building building={building} color={color} />}
      {flashing && <div className="pulse"></div>}
      {/* {id} */}
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Robber.js ---------- 
import React from "react";

import { NumberToken } from "./Tile";
import { SQRT3, tilePixelVector } from "../utils/coordinates";

export default function Robber({ center, size, coordinate }) {
  const [centerX, centerY] = center;
  const w = SQRT3 * size;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const [deltaX, deltaY] = [-w / 2 + w / 8, 0];
  const x = tileX + deltaX;
  const y = tileY + deltaY;

  return (
    <NumberToken
      className="robber"
      size={size}
      style={{
        left: x,
        top: y,
      }}
    >
      R
    </NumberToken>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Tile.js ---------- 
import React from "react";
import cn from "classnames";
import Paper from "@material-ui/core/Paper";

import "./Tile.scss";
import brickTile from "../assets/tile_brick.svg";
import desertTile from "../assets/tile_desert.svg";
import grainTile from "../assets/tile_wheat.svg";
import lumberTile from "../assets/tile_wood.svg";
import oreTile from "../assets/tile_ore.svg";
import woolTile from "../assets/tile_sheep.svg";
import { SQRT3, tilePixelVector } from "../utils/coordinates";

export function NumberToken({ className, children, style, size }) {
  return (
    <Paper
      elevation={3}
      className={cn("number-token", className)}
      style={{
        "--base-size": `${size}px`, // this var can be overrided via `style` prop
        ...style,
      }}
    >
      {children}
    </Paper>
  );
}

const numberToPips = (number) => {
  switch (number) {
    case 2:
    case 12:
      return "•";
    case 3:
    case 11:
      return "••";
    case 4:
    case 10:
      return "•••";
    case 5:
    case 9:
      return "••••";
    case 6:
    case 8:
      return "•••••";
    default:
      return "";
  }
};

export default function Tile({ center, coordinate, tile, size }) {
  const w = SQRT3 * size;
  const h = 2 * size;
  const [centerX, centerY] = center;
  const [x, y] = tilePixelVector(coordinate, size, centerX, centerY);

  let contents;
  let resourceTile;
  if (tile.type === "RESOURCE_TILE") {
    contents = (
      <NumberToken size={size}>
        <div>{tile.number}</div>
        <div class="pips">{numberToPips(tile.number)}</div>
      </NumberToken>
    );
    resourceTile = {
      BRICK: brickTile,
      SHEEP: woolTile,
      ORE: oreTile,
      WOOD: lumberTile,
      WHEAT: grainTile,
    }[tile.resource];
  } else if (tile.type === "DESERT") {
    resourceTile = desertTile;
  } else if (tile.type === "PORT") {
    let x = 0;
    let y = 0;
    if (tile.direction.includes("SOUTH")) {
      y += size / 3;
    }
    if (tile.direction.includes("NORTH")) {
      y -= size / 3;
    }
    if (tile.direction.includes("WEST")) {
      x -= size / 4;
      if (tile.direction === "WEST") {
        x = -size / 3;
      }
    }
    if (tile.direction.includes("EAST")) {
      x += size / 4;
      if (tile.direction === "EAST") {
        x = size / 3;
      }
    }
    if (tile.resource === null) {
      contents = (
        <div
          className="port"
          style={{
            left: x,
            top: y,
          }}
        >
          3:1
        </div>
      );
    } else {
      const portBackground = {
        BRICK: brickTile,
        SHEEP: woolTile,
        ORE: oreTile,
        WOOD: lumberTile,
        WHEAT: grainTile,
      }[tile.resource];
      contents = (
        <div
          className="port"
          style={{
            left: x,
            top: y,
            backgroundImage: `url('${portBackground}')`,
            height: 60,
            backgroundSize: "contain",
            width: 52,
            backgroundRepeat: "no-repeat",
          }}
        >
          2:1
        </div>
      );
    }
  }

  return (
    <div
      key={coordinate}
      className="tile"
      style={{
        left: x - w / 2,
        top: y - h / 2,
        width: w,
        height: h,
        backgroundImage: `url('${resourceTile}')`,
        backgroundSize: "contain",
      }}
    >
      {contents}
    </div>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\ZoomableBoard.js ---------- 
import React, { useCallback, useContext, useEffect, useState } from "react";
import { TransformWrapper, TransformComponent } from "react-zoom-pan-pinch";
import memoize from "fast-memoize";
import { useMediaQuery, useTheme } from "@material-ui/core";

import useWindowSize from "../utils/useWindowSize";

import "./Board.scss";
import { store } from "../store";
import { isPlayersTurn } from "../utils/stateUtils";
import { postAction } from "../utils/apiClient";
import { useParams } from "react-router";
import ACTIONS from "../actions";
import Board from "./Board";

/**
 * Returns object representing actions to be taken if click on node.
 * @returns {3 => ["BLUE", "BUILD_CITY", 3], ...}
 */
function buildNodeActions(state) {
  if (!isPlayersTurn(state.gameState)) {
    return {};
  }

  const nodeActions = {};
  const buildInitialSettlementActions = state.gameState.is_initial_build_phase
    ? state.gameState.current_playable_actions.filter(
        (action) => action[1] === "BUILD_SETTLEMENT"
      )
    : [];
  const inInitialBuildPhase = state.gameState.is_initial_build_phase;
  if (inInitialBuildPhase) {
    buildInitialSettlementActions.forEach((action) => {
      nodeActions[action[2]] = action;
    });
  } else if (state.isBuildingSettlement) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_SETTLEMENT")
      .forEach((action) => {
        nodeActions[action[2]] = action;
      });
  } else if (state.isBuildingCity) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_CITY")
      .forEach((action) => {
        nodeActions[action[2]] = action;
      });
  }
  return nodeActions;
}

function buildEdgeActions(state) {
  if (!isPlayersTurn(state.gameState)) {
    return {};
  }

  const edgeActions = {};
  const buildInitialRoadActions = state.gameState.is_initial_build_phase
    ? state.gameState.current_playable_actions.filter(
        (action) => action[1] === "BUILD_ROAD"
      )
    : [];
  const inInitialBuildPhase = state.gameState.is_initial_build_phase;
  if (inInitialBuildPhase) {
    buildInitialRoadActions.forEach((action) => {
      edgeActions[action[2]] = action;
    });
  } else if (state.isBuildingRoad) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_ROAD")
      .forEach((action) => {
        edgeActions[action[2]] = action;
      });
  }
  return edgeActions;
}

export default function ZoomableBoard({ replayMode }) {
  const { gameId } = useParams();
  const { state, dispatch } = useContext(store);
  const { width, height } = useWindowSize();
  const theme = useTheme();
  const isMobile = useMediaQuery(theme.breakpoints.up("md"));
  const [show, setShow] = useState(false);

  // TODO: Move these up to GameScreen and let Zoomable be presentational component
  // https://stackoverflow.com/questions/61255053/react-usecallback-with-parameter
  const buildOnNodeClick = useCallback(
    memoize((id, action) => async () => {
      console.log("Clicked Node ", id, action);
      if (action) {
        const gameState = await postAction(gameId, action);
        dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      }
    }),
    []
  );
  const buildOnEdgeClick = useCallback(
    memoize((id, action) => async () => {
      console.log("Clicked Edge ", id, action);
      if (action) {
        const gameState = await postAction(gameId, action);
        dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      }
    }),
    []
  );

  const nodeActions = replayMode ? {} : buildNodeActions(state);
  const edgeActions = replayMode ? {} : buildEdgeActions(state);

  useEffect(() => {
    setTimeout(() => {
      setShow(true);
    }, 300);
  }, []);

  return (
    <TransformWrapper
      options={{
        limitToBounds: true,
      }}
    >
      {({
        zoomIn,
        zoomOut,
        resetTransform,
        positionX,
        positionY,
        scale,
        previousScale,
      }) => (
        <React.Fragment>
          <div className="board-container">
            <TransformComponent>
              <Board
                width={width}
                height={height}
                buildOnNodeClick={buildOnNodeClick}
                buildOnEdgeClick={buildOnEdgeClick}
                nodeActions={nodeActions}
                edgeActions={edgeActions}
                replayMode={replayMode}
                show={show}
                gameState={state.gameState}
                isMobile={isMobile}
              ></Board>
            </TransformComponent>
          </div>
        </React.Fragment>
      )}
    </TransformWrapper>
  );
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\ActionsToolbar.scss ---------- 
@import "../variables.scss";

.state-summary {
  height: 60px;
  width: 100%;
  max-width: $sm-breakpoint;
  margin: 0 auto;
  display: flex;
  padding: $sm-gutter;
  .open-drawer-btn {
    color: white;
    margin-right: $sm-gutter;
  }
}

$btn-height: 60px;
.actions-toolbar {
  height: $btn-height + 2 * $sm-gutter;
  width: 100%;
  max-width: $sm-breakpoint;
  margin-left: auto;
  margin-right: auto;
  padding: $sm-gutter;
  display: flex;
  justify-content: space-between;
  gap: $sm-gutter;

  button {
    min-width: 60px;
    width: 100px;
    height: $btn-height;
  }

  .confirm-btn {
    width: 100%;
  }

  .action-popover {
    z-index: 1;

    overflow: auto;
    max-height: calc(100% - #{$btn-height});
    margin-bottom: 10px;
  }

  .MuiButton-label {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;

    .MuiButton-startIcon {
      margin: 0;
    }
  }
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Board.scss ---------- 
@import "../variables.scss";

.RED {
  background: $red;
}
.BLUE {
  background: $blue;
}
.ORANGE {
  background: $orange;
}
.WHITE {
  background: $white;
}
.RED.foreground {
  color: $red;
  background: #00000000;
}
.BLUE.foreground {
  color: $blue;
  background: #00000000;
}
.ORANGE.foreground {
  color: $orange;
  background: #00000000;
}
.WHITE.foreground {
  color: white;
  background: #00000000;
}

// ===== Number Tokens
.number-token,
.port {
  width: 20px;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.8rem;
  font-weight: bold;

  position: relative;
}

@media screen and (min-width: $sm-breakpoint) {
  .number-token,
  .port {
    font-size: 1.3rem;
  }
}

.MuiPaper-elevation3.number-token {
  background: $dark-gray;
  color: white;
}

.MuiPaper-elevation3.robber {
  background: #6b6b6b;
  position: absolute;
  font-size: 100%;
}

// ===== Tiles
.tile {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
}

// ===== Edges
.edge {
  position: absolute;
  display: flex;
  justify-content: center;

  height: 5px; // stroke
}
.road {
  position: absolute;
  border: 1px solid $dark-gray;
  width: 100%;
  height: 100%;
  border-radius: 2px;
}
@media screen and (min-width: $sm-breakpoint) {
  .edge {
    height: 12px; // stroke
  }
}

// ===== Nodes
.node {
  position: absolute;
  height: 10px;
  width: 10px;

  display: flex;
  justify-content: center;
  align-items: center;
}
.settlement {
  width: 80%;
  height: 80%;
}
.city {
  width: 100%;
  height: 100%;
}
.settlement,
.city {
  border-radius: 4px; // mimic Paper
  border: 2px solid $dark-gray;
}

.BLUE.city {
  border: 4px solid $blue;
  background: $dark-gray;
}
.RED.city {
  border: 4px solid $red;
  background: $dark-gray;
}
.ORANGE.city {
  border: 4px solid $orange;
  background: $dark-gray;
}
.WHITE.city {
  border: 4px solid $white;
  background: $dark-gray;
}

// Taken from https://codepen.io/peeke/pen/BjxXZa.
.pulse {
  cursor: pointer;
  position: absolute;
  left: 50%;
  top: 50%;
  transform: translateX(-50%) translateY(-50%);

  &:after {
    content: "";
    position: absolute;
    left: 0;
    top: 0;
    display: block;
    width: 100%;
    height: 100%;
    background-color: white;
    border-radius: 4px;
    box-shadow: 0 0 8px rgba(0, 0, 0, 0.3);
    animation: pulse-dot 1.25s cubic-bezier(0.455, 0.03, 0.515, 0.955) -0.4s infinite;
  }
}

@keyframes pulse-dot {
  0% {
    transform: scale(0.8);
  }
  50% {
    transform: scale(1);
  }
  100% {
    transform: scale(0.8);
  }
}

.edge .pulse {
  width: 90%;
  height: 90%;
}

.node .pulse {
  width: 75%;
  height: 75%;
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\GameScreen.scss ---------- 
@import "../variables.scss";

.MuiToolbar-root {
  background: $black;
}

h6.MuiTypography-h6 {
  font-family: "Bungee Inline", sans-serif;
}

@media (min-width: 600px) {
  #root .snackbar-container {
    display: none;
  }
}

// For Snackbar
#root .snackbar-container {
  z-index: 1200;
  left: 50% !important;
  bottom: 0px;
  transform: translateX(-50%);
  max-width: $sm-breakpoint;
  width: 100%;
  .MuiCollapse-container {
    padding: 0 10px;
    width: 100%;
    .MuiCollapse-wrapper {
      margin-top: 10px;
      margin-bottom: 10px;
      height: 60px;
      padding: 0;

      > div > div {
        height: 100%;

        > div {
          height: 100%;
        }
      }
    }
  }
}

main {
  .logo {
    margin: 20px 20px 0 20px;
    text-align: center;
  }

  background: $black;
  color: white;

  height: 100%;
  display: flex;
  flex-direction: column;

  .loader {
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .board-container,
  .loader {
    height: 100%;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
  }
}

.board-container {
  .react-transform-component {
    height: 100%;
    width: 100%;

    .react-transform-element {
      height: 100%;
      width: 100%;
    }
  }

  .board {
    position: relative;
    opacity: 0;

    height: 100%;
    width: 100%;
  }
  .board.show {
    opacity: 1;
  }
}

@media (min-width: $md-breakpoint) {
  main {
    padding-left: 280px;
  }
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\HomePage.scss ---------- 
@import "../variables.scss";

.home-page {
  height: 100%;

  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;

  h1 {
    color: white;
    font-size: 2.5rem;
    margin-bottom: 0px;
  }
  ul {
    color: white;
  }

  .switchable {
    height: 224px; // NOTE: Fixed to avoid loading jump
    display: flex;
    flex-direction: column;
    justify-content: center;

    button {
      margin-bottom: $sm-gutter;
    }
  }
}
---------- C:\Users\mason\programming\catanatron\ui\src\pages\Tile.scss ---------- 
@import "../variables.scss";

.number-token {
    --scale-factor: 0.65;
    --base-font-size: 100%;
    height: 4ch;
    width: 4ch;
    text-align: center;
    padding: 5px;
    line-height: .8rem;
    position: relative;
    display: flex;
    flex-direction: column;
    .pips {
        font-size: calc(var(--base-font-size) * 60%);
    }
}

@media(max-width: $sm-breakpoint) {
    .number-token {
        --base-font-size: 75%;
    }
}


--- ui/src/configuration.js ---
export const API_URL = process.env.REACT_APP_API_URL || "http://localhost:5000";

--- ui/src/constants.js ---

--- ui/src/index.css ---
html,
body,
#root {
  margin: 0;
  height: 100%;
  overflow: hidden;
}

body {
  font-family: "Roboto", sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, "Courier New",
    monospace;
}

--- ui/src/index.js ---
import React from 'react';
import ReactDOM from 'react-dom';
import './index.css';
import App from './App';
import * as serviceWorker from './serviceWorker';

ReactDOM.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
  document.getElementById('root')
);

// If you want your app to work offline and load faster, you can change
// unregister() to register() below. Note this comes with some pitfalls.
// Learn more about service workers: https://bit.ly/CRA-PWA
serviceWorker.unregister();

--- ui/src/serviceWorker.js ---
// This optional code is used to register a service worker.
// register() is not called by default.

// This lets the app load faster on subsequent visits in production, and gives
// it offline capabilities. However, it also means that developers (and users)
// will only see deployed updates on subsequent visits to a page, after all the
// existing tabs open on the page have been closed, since previously cached
// resources are updated in the background.

// To learn more about the benefits of this model and instructions on how to
// opt-in, read https://bit.ly/CRA-PWA

const isLocalhost = Boolean(
  window.location.hostname === 'localhost' ||
    // [::1] is the IPv6 localhost address.
    window.location.hostname === '[::1]' ||
    // 127.0.0.0/8 are considered localhost for IPv4.
    window.location.hostname.match(
      /^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/
    )
);

export function register(config) {
  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {
    // The URL constructor is available in all browsers that support SW.
    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);
    if (publicUrl.origin !== window.location.origin) {
      // Our service worker won't work if PUBLIC_URL is on a different origin
      // from what our page is served on. This might happen if a CDN is used to
      // serve assets; see https://github.com/facebook/create-react-app/issues/2374
      return;
    }

    window.addEventListener('load', () => {
      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;

      if (isLocalhost) {
        // This is running on localhost. Let's check if a service worker still exists or not.
        checkValidServiceWorker(swUrl, config);

        // Add some additional logging to localhost, pointing developers to the
        // service worker/PWA documentation.
        navigator.serviceWorker.ready.then(() => {
          console.log(
            'This web app is being served cache-first by a service ' +
              'worker. To learn more, visit https://bit.ly/CRA-PWA'
          );
        });
      } else {
        // Is not localhost. Just register service worker
        registerValidSW(swUrl, config);
      }
    });
  }
}

function registerValidSW(swUrl, config) {
  navigator.serviceWorker
    .register(swUrl)
    .then(registration => {
      registration.onupdatefound = () => {
        const installingWorker = registration.installing;
        if (installingWorker == null) {
          return;
        }
        installingWorker.onstatechange = () => {
          if (installingWorker.state === 'installed') {
            if (navigator.serviceWorker.controller) {
              // At this point, the updated precached content has been fetched,
              // but the previous service worker will still serve the older
              // content until all client tabs are closed.
              console.log(
                'New content is available and will be used when all ' +
                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'
              );

              // Execute callback
              if (config && config.onUpdate) {
                config.onUpdate(registration);
              }
            } else {
              // At this point, everything has been precached.
              // It's the perfect time to display a
              // "Content is cached for offline use." message.
              console.log('Content is cached for offline use.');

              // Execute callback
              if (config && config.onSuccess) {
                config.onSuccess(registration);
              }
            }
          }
        };
      };
    })
    .catch(error => {
      console.error('Error during service worker registration:', error);
    });
}

function checkValidServiceWorker(swUrl, config) {
  // Check if the service worker can be found. If it can't reload the page.
  fetch(swUrl, {
    headers: { 'Service-Worker': 'script' },
  })
    .then(response => {
      // Ensure service worker exists, and that we really are getting a JS file.
      const contentType = response.headers.get('content-type');
      if (
        response.status === 404 ||
        (contentType != null && contentType.indexOf('javascript') === -1)
      ) {
        // No service worker found. Probably a different app. Reload the page.
        navigator.serviceWorker.ready.then(registration => {
          registration.unregister().then(() => {
            window.location.reload();
          });
        });
      } else {
        // Service worker found. Proceed as normal.
        registerValidSW(swUrl, config);
      }
    })
    .catch(() => {
      console.log(
        'No internet connection found. App is running in offline mode.'
      );
    });
}

export function unregister() {
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.ready
      .then(registration => {
        registration.unregister();
      })
      .catch(error => {
        console.error(error.message);
      });
  }
}

--- ui/src/setupTests.js ---
// jest-dom adds custom jest matchers for asserting on DOM nodes.
// allows you to do things like:
// expect(element).toHaveTextContent(/react/i)
// learn more: https://github.com/testing-library/jest-dom
import '@testing-library/jest-dom/extend-expect';

--- ui/src/store.js ---
import React, { createContext, useReducer } from "react";
import ACTIONS from "./actions";

const initialState = {
  gameState: null,
  // UI
  isBuildingRoad: false,
  isBuildingSettlement: false,
  isBuildingCity: false,
  isLeftDrawerOpen: false,
};
const store = createContext(initialState);
const { Provider } = store;

const StateProvider = ({ children }) => {
  const [state, dispatch] = useReducer((state, action) => {
    switch (action.type) {
      case ACTIONS.SET_LEFT_DRAWER_OPENED:
        return { ...state, isLeftDrawerOpen: action.data };
      case ACTIONS.SET_GAME_STATE:
        return {
          ...state,
          gameState: action.data,
          // Lazy way of turning these off
          isBuildingRoad: false,
          isBuildingSettlement: false,
          isBuildingCity: false,
        };
      case ACTIONS.SET_IS_BUILDING_ROAD:
        return { ...state, isBuildingRoad: true };
      case ACTIONS.SET_IS_BUILDING_SETTLEMENT:
        return { ...state, isBuildingSettlement: true };
      case ACTIONS.SET_IS_BUILDING_CITY:
        return { ...state, isBuildingCity: true };
      default:
        throw new Error("Unknown Reducer Action: " + action.type);
    }
  }, initialState);

  return <Provider value={{ state, dispatch }}>{children}</Provider>;
};

export { store, StateProvider };

--- ui/src/variables.scss ---
// Taken from https://material-ui.com/customization/breakpoints/
$sm-breakpoint: 600px;
$md-breakpoint: 960px;

$sm-gutter: 10px;

$black: #030000;
$dark-gray: #151313;

$blue: #2278ff;
$red: #fe0400;
$orange: #ffa500;
$white: white;

$wood: #119822;
$brick: #cc0300;
$wheat: #fac60c;
$sheep: #87ff65;
$darker-sheep: #72cf57;
$ore: #616166;

--- ui/src/components/LeftDrawer.js ---
import React, { useCallback, useContext } from "react";
import cn from "classnames";
import SwipeableDrawer from "@material-ui/core/SwipeableDrawer";
import Divider from "@material-ui/core/Divider";
import Drawer from "@material-ui/core/Drawer";
import { Hidden } from "@material-ui/core";

import PlayerStateBox from "../components/PlayerStateBox";
import { humanizeAction } from "../components/Prompt";
import { store } from "../store";
import ACTIONS from "../actions";
import { playerKey } from "../utils/stateUtils";

import "./LeftDrawer.scss";

function DrawerContent({ gameState }) {
  const playerSections = gameState.colors.map((color) => {
    const key = playerKey(gameState, color);
    return (
      <React.Fragment key={color}>
        <PlayerStateBox
          playerState={gameState.player_state}
          playerKey={key}
          color={color}
        />
        <Divider />
      </React.Fragment>
    );
  });

  return (
    <>
      {playerSections}
      <div className="log">
        {gameState.actions
          .slice()
          .reverse()
          .map((action, i) => (
            <div key={i} className={cn("action foreground", action)}>
              {humanizeAction(gameState, action)}
            </div>
          ))}
      </div>
    </>
  );
}

export default function LeftDrawer() {
  const { state, dispatch } = useContext(store);
  const iOS = process.browser && /iPad|iPhone|iPod/.test(navigator.userAgent);

  const openLeftDrawer = useCallback(
    (event) => {
      if (
        event &&
        event.type === "keydown" &&
        (event.key === "Tab" || event.key === "Shift")
      ) {
        return;
      }

      dispatch({ type: ACTIONS.SET_LEFT_DRAWER_OPENED, data: true });
    },
    [dispatch]
  );
  const closeLeftDrawer = useCallback(
    (event) => {
      if (
        event &&
        event.type === "keydown" &&
        (event.key === "Tab" || event.key === "Shift")
      ) {
        return;
      }

      dispatch({ type: ACTIONS.SET_LEFT_DRAWER_OPENED, data: false });
    },
    [dispatch]
  );

  return (
    <>
      <Hidden mdUp implementation="js">
        <SwipeableDrawer
          className="left-drawer"
          anchor="left"
          open={state.isLeftDrawerOpen}
          onClose={closeLeftDrawer}
          onOpen={openLeftDrawer}
          disableBackdropTransition={!iOS}
          disableDiscovery={iOS}
          onKeyDown={closeLeftDrawer}
        >
          <DrawerContent gameState={state.gameState} />
        </SwipeableDrawer>
      </Hidden>
      <Hidden smDown implementation="css">
        <Drawer className="left-drawer" anchor="left" variant="permanent" open>
          <DrawerContent gameState={state.gameState} />
        </Drawer>
      </Hidden>
    </>
  );
}

--- ui/src/components/LeftDrawer.scss ---
@import "../variables.scss";

$dark-divider: rgb(0 0 0 / 80%);

.left-drawer {
  .MuiDrawer-paper {
    width: 280px;
    background: $dark-gray;
  }

  .MuiDivider-root {
    background: $dark-divider;
  }

  .MuiDrawer-paperAnchorDockedLeft {
    border-color: $dark-divider;
  }

  .log {
    overflow-y: auto;
    font-size: 0.8rem;

    // To ensure always clipped towards bottom
    display: flex;
    flex-direction: column-reverse;
    .action {
      padding: $sm-gutter;
    }
  }
}

--- ui/src/components/PlayerStateBox.js ---
import React from "react";
import cn from "classnames";

import "./PlayerStateBox.scss";
import { Paper } from "@material-ui/core";

export function ResourceCards({ playerState, playerKey }) {
  const amount = (card) => playerState[`${playerKey}_${card}_IN_HAND`];
  return (
    <div className="resource-cards" title="Resource Cards">
      {amount("WOOD") !== 0 && (
        <div className="wood-cards center-text card">
          <Paper>{amount("WOOD")}</Paper>
        </div>
      )}
      {amount("BRICK") !== 0 && (
        <div className="brick-cards center-text card">
          <Paper>{amount("BRICK")}</Paper>
        </div>
      )}
      {amount("SHEEP") !== 0 && (
        <div className="sheep-cards center-text card">
          <Paper>{amount("SHEEP")}</Paper>
        </div>
      )}
      {amount("WHEAT") !== 0 && (
        <div className="wheat-cards center-text card">
          <Paper>{amount("WHEAT")}</Paper>
        </div>
      )}
      {amount("ORE") !== 0 && (
        <div className="ore-cards center-text card">
          <Paper>{amount("ORE")}</Paper>
        </div>
      )}
      <div className="separator"></div>
      {amount("VICTORY_POINT") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("VICTORY_POINT") + " Victory Point Card(s)"}
        >
          <Paper>
            <span>{amount("VICTORY_POINT")}</span>
            <span>VP</span>
          </Paper>
        </div>
      )}
      {amount("KNIGHT") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("KNIGHT") + " Knight Card(s)"}
        >
          <Paper>
            <span>{amount("KNIGHT")}</span>
            <span>KN</span>
          </Paper>
        </div>
      )}
      {amount("MONOPOLY") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("MONOPOLY") + " Monopoly Card(s)"}
        >
          <Paper>
            <span>{amount("MONOPOLY")}</span>
            <span>MO</span>
          </Paper>
        </div>
      )}
      {amount("YEAR_OF_PLENTY") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("YEAR_OF_PLENTY") + " Year of Plenty Card(s)"}
        >
          <Paper>
            <span>{amount("YEAR_OF_PLENTY")}</span>
            <span>YP</span>
          </Paper>
        </div>
      )}
      {amount("ROAD_BUILDING") !== 0 && (
        <div
          className="dev-cards center-text card"
          title={amount("ROAD_BUILDING") + " Road Building Card(s)"}
        >
          <Paper>
            <span>{amount("ROAD_BUILDING")}</span>
            <span>RB</span>
          </Paper>
        </div>
      )}
    </div>
  );
}

export default function PlayerStateBox({ playerState, playerKey, color }) {
  const actualVps = playerState[`${playerKey}_ACTUAL_VICTORY_POINTS`];
  return (
    <div className={cn("player-state-box foreground", color)}>
      <ResourceCards playerState={playerState} playerKey={playerKey} />
      <div className="scores">
        <div
          className={cn("num-knights center-text", {
            bold: playerState[`${playerKey}_HAS_ARMY`],
          })}
          title="Knights Played"
        >
          <span>{playerState[`${playerKey}_PLAYED_KNIGHT`]}</span>
          <small>knights</small>
        </div>
        <div
          className={cn("num-roads center-text", {
            bold: playerState[`${playerKey}_HAS_ROAD`],
          })}
          title="Longest Road"
        >
          {playerState[`${playerKey}_LONGEST_ROAD_LENGTH`]}
          <small>roads</small>
        </div>
        <div
          className={cn("victory-points center-text", {
            bold: actualVps >= 10,
          })}
          title="Victory Points"
        >
          {actualVps}
          <small>VPs</small>
        </div>
      </div>
    </div>
  );
}

--- ui/src/components/PlayerStateBox.scss ---
@import "../variables.scss";

.resource-cards {
  height: 40px;
  display: flex;
  gap: 6px;

  margin-bottom: $sm-gutter;

  .card {
    border-radius: 4px;
    div {
      background: #151313;
      color: white;

      width: 21px;
      height: 36px;

      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-size: 0.8rem;
      font-weight: bold;
      position: relative;
    }
  }
  .wood-cards {
    background: $wood;
  }
  .brick-cards {
    background: $brick;
  }
  .wheat-cards {
    background: $wheat;
  }
  .sheep-cards {
    background: $darker-sheep;
  }
  .ore-cards {
    background: $ore;
  }
  .dev-cards {
    background: purple;
    div {
      font-size: 0.7rem;
    }
  }
}

.center-text {
  display: flex;
  justify-content: center;
  align-items: center;

  width: 25px;
  height: 40px;
}

.player-state-box {
  padding: $sm-gutter;

  max-width: $sm-breakpoint;
  margin: 0 auto;
  width: 100%;

  .scores {
    display: flex;
    justify-content: space-between;
  }

  .num-knights,
  .num-roads,
  .victory-points {
    flex-direction: column;
    width: 50px;
    height: 40px;
  }

  .bold {
    font-weight: bold;
  }
}

--- ui/src/components/Prompt.js ---
import React from "react";
import { isPlayersTurn } from "../utils/stateUtils";

import "./Prompt.scss";

function findTileByCoordinate(gameState, coordinate) {
  for (const tile of Object.values(gameState.tiles)) {
    if (JSON.stringify(tile.coordinate) === JSON.stringify(coordinate)) {
      return tile;
    }
  }
}

function findTileById(gameState, tileId) {
  return gameState.tiles[tileId];
}

function getTileString(tile) {
  return `${tile.tile.number} ${tile.tile.resource}`;
}

function getShortTileString(tileTile) {
  return tileTile.number || tileTile.type;
}

export function humanizeAction(gameState, action) {
  const botColors = gameState.bot_colors;
  const player = botColors.includes(action[0]) ? "BOT" : "YOU";
  switch (action[1]) {
    case "ROLL":
      return `${player} ROLLED A ${action[2][0] + action[2][1]}`;
    case "DISCARD":
      return `${player} DISCARDED`;
    case "BUY_DEVELOPMENT_CARD":
      return `${player} BOUGHT DEVELOPMENT CARD`;
    case "BUILD_SETTLEMENT":
    case "BUILD_CITY": {
      const parts = action[1].split("_");
      const building = parts[parts.length - 1];
      const tileId = action[2];
      const tiles = gameState.adjacent_tiles[tileId];
      const tileString = tiles.map(getShortTileString).join("-");
      return `${player} BUILT ${building} ON ${tileString}`;
    }
    case "BUILD_ROAD": {
      const edge = action[2];
      const a = gameState.adjacent_tiles[edge[0]].map((t) => t.id);
      const b = gameState.adjacent_tiles[edge[1]].map((t) => t.id);
      const intersection = a.filter((t) => b.includes(t));
      const tiles = intersection.map(
        (tileId) => findTileById(gameState, tileId).tile
      );
      const edgeString = tiles.map(getShortTileString).join("-");
      return `${player} BUILT ROAD ON ${edgeString}`;
    }
    case "PLAY_KNIGHT_CARD": {
      return `${player} PLAYED KNIGHT CARD`;
    }
    case "PLAY_YEAR_OF_PLENTY": {
      return `${player} YEAR OF PLENTY ${action[2]}`;
    }
    case "MOVE_ROBBER": {
      const tile = findTileByCoordinate(gameState, action[2][0]);
      const tileString = getTileString(tile);
      return `${player} ROBBED ${tileString} (STOLE ${action[2][2]})`;
    }
    case "MARITIME_TRADE": {
      const label = humanizeTradeAction(action);
      return `${player} TRADED ${label}`;
    }
    case "END_TURN":
      return `${player} ENDED TURN`;
    default:
      return `${player} ${action.slice(1)}`;
  }
}

export function humanizeTradeAction(action) {
  const out = action[2].slice(0, 4).filter((resource) => resource !== null);
  return `${out.length} ${out[0]} => ${action[2][4]}`;
}

function humanizePrompt(current_prompt) {
  switch (current_prompt) {
    case "ROLL":
      return `YOUR TURN`;
    case "PLAY_TURN":
      return `YOUR TURN`;
    case "BUILD_INITIAL_SETTLEMENT":
    case "BUILD_INITIAL_ROAD":
    default: {
      const prompt = current_prompt.replaceAll("_", " ");
      return `PLEASE ${prompt}`;
    }
  }
}

export default function Prompt({ gameState, isBotThinking }) {
  let prompt = "";
  if (isBotThinking) {
    // Do nothing, but still render.
  } else if (gameState.winning_color) {
    prompt = `Game Over. Congrats, ${gameState.winning_color}!`;
  } else if (isPlayersTurn(gameState)) {
    prompt = humanizePrompt(gameState.current_prompt);
  } else {
    // prompt = humanizeAction(gameState.actions[gameState.actions.length - 1], gameState.bot_colors);
  }
  return <div className="prompt">{prompt}</div>;
}

--- ui/src/components/Prompt.scss ---
@import "../variables.scss";

.prompt {
  padding: $sm-gutter;

  height: 60px;
  width: 100%;
  font-size: 1rem;

  text-align: left;
  display: flex;
  flex-direction: column;
  align-items: center;

  overflow-x: auto;
  white-space: nowrap;
}

--- ui/src/components/Snackbar.js ---
import React from "react";
import { IconButton } from "@material-ui/core";
import CloseIcon from "@material-ui/icons/Close";
import { humanizeAction } from "./Prompt";

export const snackbarActions = (closeSnackbar) => (key) =>
  (
    <>
      <IconButton
        size="small"
        aria-label="close"
        color="inherit"
        onClick={() => closeSnackbar(key)}
      >
        <CloseIcon fontSize="small" />
      </IconButton>
    </>
  );

export function dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState) {
  enqueueSnackbar(humanizeAction(gameState, gameState.actions.slice(-1)[0]), {
    action: snackbarActions(closeSnackbar),
    onClick: () => {
      closeSnackbar();
    },
  });
}

--- ui/src/pages/ActionsToolbar.js ---
import React, {
  useState,
  useRef,
  useEffect,
  useContext,
  useCallback,
} from "react";
import memoize from "fast-memoize";
import { Button, Hidden } from "@material-ui/core";
import ChevronLeftIcon from "@material-ui/icons/ChevronLeft";
import AccountBalanceIcon from "@material-ui/icons/AccountBalance";
import BuildIcon from "@material-ui/icons/Build";
import NavigateNextIcon from "@material-ui/icons/NavigateNext";
import MenuItem from "@material-ui/core/MenuItem";
import ClickAwayListener from "@material-ui/core/ClickAwayListener";
import Grow from "@material-ui/core/Grow";
import Paper from "@material-ui/core/Paper";
import Popper from "@material-ui/core/Popper";
import MenuList from "@material-ui/core/MenuList";
import SimCardIcon from "@material-ui/icons/SimCard";
import { useParams } from "react-router";

import { ResourceCards } from "../components/PlayerStateBox";
import Prompt, { humanizeTradeAction } from "../components/Prompt";
import { store } from "../store";
import ACTIONS from "../actions";
import { getHumanColor, playerKey } from "../utils/stateUtils";
import { postAction } from "../utils/apiClient";

import "./ActionsToolbar.scss";
import { useSnackbar } from "notistack";
import { dispatchSnackbar } from "../components/Snackbar";

function PlayButtons() {
  const { gameId } = useParams();
  const { state, dispatch } = useContext(store);
  const { enqueueSnackbar, closeSnackbar } = useSnackbar();

  const carryOutAction = useCallback(
    memoize((action) => async () => {
      const gameState = await postAction(gameId, action);
      dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
    }),
    [enqueueSnackbar, closeSnackbar]
  );

  const { gameState } = state;
  const key = playerKey(gameState, gameState.current_color);
  const isRoll =
    gameState.current_prompt === "PLAY_TURN" &&
    !gameState.player_state[`${key}_HAS_ROLLED`];
  const isDiscard = gameState.current_prompt === "DISCARD";
  const isMove = gameState.current_prompt === "MOVE_ROBBER";
  const playableDevCardTypes = new Set(
    gameState.current_playable_actions
      .filter((action) => action[1].startsWith("PLAY"))
      .map((action) => action[1])
  );
  const useItems = [
    {
      label: "Monopoly",
      disabled: !playableDevCardTypes.has("PLAY_MONOPOLY"),
    },
    {
      label: "Year of Plenty",
      disabled: !playableDevCardTypes.has("PLAY_YEAR_OF_PLENTY"),
    },
    {
      label: "Road Building",
      disabled: !playableDevCardTypes.has("PLAY_ROAD_BUILDING"),
    },
    {
      label: "Knight",
      disabled: !playableDevCardTypes.has("PLAY_KNIGHT_CARD"),
    },
  ];

  const buildActionTypes = new Set(
    state.gameState.is_initial_build_phase
      ? []
      : state.gameState.current_playable_actions
          .filter(
            (action) =>
              action[1].startsWith("BUY") || action[1].startsWith("BUILD")
          )
          .map((a) => a[1])
  );
  const humanColor = getHumanColor(state.gameState);
  const buyDevCard = useCallback(async () => {
    const action = [humanColor, "BUY_DEVELOPMENT_CARD", null];
    const gameState = await postAction(gameId, action);
    dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
    dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
  }, [gameId, dispatch, enqueueSnackbar, closeSnackbar, humanColor]);
  const setIsBuildingSettlement = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_SETTLEMENT });
  }, [dispatch]);
  const setIsBuildingCity = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_CITY });
  }, [dispatch]);
  const setIsBuildingRoad = useCallback(() => {
    dispatch({ type: ACTIONS.SET_IS_BUILDING_ROAD });
  }, [dispatch]);
  const buildItems = [
    {
      label: "Development Card",
      disabled: !buildActionTypes.has("BUY_DEVELOPMENT_CARD"),
      onClick: buyDevCard,
    },
    {
      label: "City",
      disabled: !buildActionTypes.has("BUILD_CITY"),
      onClick: setIsBuildingCity,
    },
    {
      label: "Settlement",
      disabled: !buildActionTypes.has("BUILD_SETTLEMENT"),
      onClick: setIsBuildingSettlement,
    },
    {
      label: "Road",
      disabled: !buildActionTypes.has("BUILD_ROAD"),
      onClick: setIsBuildingRoad,
    },
  ];

  const tradeActions = state.gameState.current_playable_actions.filter(
    (action) => action[1] === "MARITIME_TRADE"
  );
  const tradeItems = tradeActions.map((action) => {
    const label = humanizeTradeAction(action);
    return {
      label: label,
      disabled: false,
      onClick: carryOutAction(action),
    };
  });

  const rollAction = carryOutAction([humanColor, "ROLL", null]);
  const proceedAction = carryOutAction();
  const endTurnAction = carryOutAction([humanColor, "END_TURN", null]);
  return (
    <>
      <OptionsButton
        disabled={playableDevCardTypes.size === 0}
        menuListId="use-menu-list"
        icon={<SimCardIcon />}
        items={useItems}
      >
        Use
      </OptionsButton>
      <OptionsButton
        disabled={buildActionTypes.size === 0}
        menuListId="build-menu-list"
        icon={<BuildIcon />}
        items={buildItems}
      >
        Buy
      </OptionsButton>
      <OptionsButton
        disabled={tradeItems.length === 0}
        menuListId="trade-menu-list"
        icon={<AccountBalanceIcon />}
        items={tradeItems}
      >
        Trade
      </OptionsButton>
      <Button
        disabled={gameState.is_initial_build_phase}
        variant="contained"
        color="primary"
        startIcon={<NavigateNextIcon />}
        onClick={
          isRoll
            ? rollAction
            : isDiscard || isMove
            ? proceedAction
            : endTurnAction
        }
      >
        {isRoll ? "ROLL" : isDiscard ? "DISCARD" : isMove ? "ROB" : "END"}
      </Button>
    </>
  );
}

export default function ActionsToolbar({
  zoomIn,
  zoomOut,
  isBotThinking,
  replayMode,
}) {
  const { state, dispatch } = useContext(store);

  const openLeftDrawer = useCallback(() => {
    dispatch({
      type: ACTIONS.SET_LEFT_DRAWER_OPENED,
      data: true,
    });
  }, [dispatch]);

  const botsTurn = state.gameState.bot_colors.includes(
    state.gameState.current_color
  );
  const humanColor = getHumanColor(state.gameState);
  return (
    <>
      <div className="state-summary">
        <Hidden mdUp>
          <Button className="open-drawer-btn" onClick={openLeftDrawer}>
            <ChevronLeftIcon />
          </Button>
        </Hidden>
        {humanColor && (
          <ResourceCards
            playerState={state.gameState.player_state}
            playerKey={playerKey(state.gameState, humanColor)}
          />
        )}
      </div>
      <div className="actions-toolbar">
        {!(botsTurn || state.gameState.winning_color) && !replayMode && (
          <PlayButtons gameState={state.gameState} />
        )}
        {(botsTurn || state.gameState.winning_color) && (
          <Prompt gameState={state.gameState} isBotThinking={isBotThinking} />
        )}
        {/* <Button
          disabled={disabled}
          className="confirm-btn"
          variant="contained"
          color="primary"
          onClick={onTick}
        >
          Ok
        </Button> */}

        {/* <Button onClick={zoomIn}>Zoom In</Button>
      <Button onClick={zoomOut}>Zoom Out</Button> */}
      </div>
    </>
  );
}

function OptionsButton({ menuListId, icon, children, items, disabled }) {
  const [open, setOpen] = useState(false);
  const anchorRef = useRef(null);

  const handleToggle = () => {
    setOpen((prevOpen) => !prevOpen);
  };
  const handleClose = (onClick) => (event) => {
    if (anchorRef.current && anchorRef.current.contains(event.target)) {
      return;
    }

    onClick && onClick();
    setOpen(false);
  };
  function handleListKeyDown(event) {
    if (event.key === "Tab") {
      event.preventDefault();
      setOpen(false);
    }
  }
  // return focus to the button when we transitioned from !open -> open
  const prevOpen = useRef(open);
  useEffect(() => {
    if (prevOpen.current === true && open === false) {
      anchorRef.current.focus();
    }

    prevOpen.current = open;
  }, [open]);

  return (
    <React.Fragment>
      <Button
        disabled={disabled}
        ref={anchorRef}
        aria-controls={open ? menuListId : undefined}
        aria-haspopup="true"
        variant="contained"
        color="secondary"
        startIcon={icon}
        onClick={handleToggle}
      >
        {children}
      </Button>
      <Popper
        className="action-popover"
        open={open}
        anchorEl={anchorRef.current}
        role={undefined}
        transition
        disablePortal
      >
        {({ TransitionProps, placement }) => (
          <Grow
            {...TransitionProps}
            style={{
              transformOrigin:
                placement === "bottom" ? "center top" : "center bottom",
            }}
          >
            <Paper>
              <ClickAwayListener onClickAway={handleClose}>
                <MenuList
                  autoFocusItem={open}
                  id={menuListId}
                  onKeyDown={handleListKeyDown}
                >
                  {items.map((item) => (
                    <MenuItem
                      key={item.label}
                      onClick={handleClose(item.onClick)}
                      disabled={item.disabled}
                    >
                      {item.label}
                    </MenuItem>
                  ))}
                </MenuList>
              </ClickAwayListener>
            </Paper>
          </Grow>
        )}
      </Popper>
    </React.Fragment>
  );
}

--- ui/src/pages/ActionsToolbar.scss ---
@import "../variables.scss";

.state-summary {
  height: 60px;
  width: 100%;
  max-width: $sm-breakpoint;
  margin: 0 auto;
  display: flex;
  padding: $sm-gutter;
  .open-drawer-btn {
    color: white;
    margin-right: $sm-gutter;
  }
}

$btn-height: 60px;
.actions-toolbar {
  height: $btn-height + 2 * $sm-gutter;
  width: 100%;
  max-width: $sm-breakpoint;
  margin-left: auto;
  margin-right: auto;
  padding: $sm-gutter;
  display: flex;
  justify-content: space-between;
  gap: $sm-gutter;

  button {
    min-width: 60px;
    width: 100px;
    height: $btn-height;
  }

  .confirm-btn {
    width: 100%;
  }

  .action-popover {
    z-index: 1;

    overflow: auto;
    max-height: calc(100% - #{$btn-height});
    margin-bottom: 10px;
  }

  .MuiButton-label {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;

    .MuiButton-startIcon {
      margin: 0;
    }
  }
}

--- ui/src/pages/Board.js ---
import React from "react";
import classnames from "classnames";

import { SQRT3 } from "../utils/coordinates";
import Tile from "./Tile";
import Node from "./Node";
import Edge from "./Edge";
import Robber from "./Robber";

import "./Board.scss";

/**
 * This uses the formulas: W = SQRT3 * size and H = 2 * size.
 * Math comes from https://www.redblobgames.com/grids/hexagons/.
 */
function computeDefaultSize(divWidth, divHeight) {
  const numLevels = 6; // 3 rings + 1/2 a tile for the outer water ring
  // divHeight = numLevels * (3h/4) + (h/4), implies:
  const maxSizeThatRespectsHeight = (4 * divHeight) / (3 * numLevels + 1) / 2;
  const correspondingWidth = SQRT3 * maxSizeThatRespectsHeight;
  let size;
  if (numLevels * correspondingWidth < divWidth) {
    // thus complete board would fit if we pick size based on height (height is limiting factor)
    size = maxSizeThatRespectsHeight;
  } else {
    // we'll have to decide size based on width.
    const maxSizeThatRespectsWidth = divWidth / numLevels / SQRT3;
    size = maxSizeThatRespectsWidth;
  }
  return size;
}

export default function Board({
  width,
  height,
  buildOnNodeClick,
  buildOnEdgeClick,
  nodeActions,
  edgeActions,
  replayMode,
  gameState,
  isMobile,
  show,
}) {
  // TODO: Keep in sync with CSS
  const containerHeight = height - 144 - 38 - 40;
  const containerWidth = isMobile ? width - 280 : width;
  const center = [containerWidth / 2, containerHeight / 2];
  const size = computeDefaultSize(containerWidth, containerHeight);
  if (!size) {
    return null;
  }

  const tiles = gameState.tiles.map(({ coordinate, tile }) => (
    <Tile
      key={coordinate}
      center={center}
      coordinate={coordinate}
      tile={tile}
      size={size}
    />
  ));
  const nodes = Object.values(gameState.nodes).map(
    ({ color, building, direction, tile_coordinate, id }) => (
      <Node
        key={id}
        id={id}
        center={center}
        size={size}
        coordinate={tile_coordinate}
        direction={direction}
        building={building}
        color={color}
        flashing={!replayMode && id in nodeActions}
        onClick={buildOnNodeClick(id, nodeActions[id])}
      />
    )
  );
  const edges = Object.values(gameState.edges).map(
    ({ color, direction, tile_coordinate, id }) => (
      <Edge
        id={id}
        key={id}
        center={center}
        size={size}
        coordinate={tile_coordinate}
        direction={direction}
        color={color}
        flashing={id in edgeActions}
        onClick={buildOnEdgeClick(id, edgeActions[id])}
      />
    )
  );
  return (
    <div className={classnames("board", { show })}>
      {tiles}
      {edges}
      {nodes}
      <Robber
        center={center}
        size={size}
        coordinate={gameState.robber_coordinate}
      />
    </div>
  );
}

--- ui/src/pages/Board.scss ---
@import "../variables.scss";

.RED {
  background: $red;
}
.BLUE {
  background: $blue;
}
.ORANGE {
  background: $orange;
}
.WHITE {
  background: $white;
}
.RED.foreground {
  color: $red;
  background: #00000000;
}
.BLUE.foreground {
  color: $blue;
  background: #00000000;
}
.ORANGE.foreground {
  color: $orange;
  background: #00000000;
}
.WHITE.foreground {
  color: white;
  background: #00000000;
}

// ===== Number Tokens
.number-token,
.port {
  width: 20px;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.8rem;
  font-weight: bold;

  position: relative;
}

@media screen and (min-width: $sm-breakpoint) {
  .number-token,
  .port {
    font-size: 1.3rem;
  }
}

.MuiPaper-elevation3.number-token {
  background: $dark-gray;
  color: white;
}

.MuiPaper-elevation3.robber {
  background: #6b6b6b;
  position: absolute;
  font-size: 100%;
}

// ===== Tiles
.tile {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
}

// ===== Edges
.edge {
  position: absolute;
  display: flex;
  justify-content: center;

  height: 5px; // stroke
}
.road {
  position: absolute;
  border: 1px solid $dark-gray;
  width: 100%;
  height: 100%;
  border-radius: 2px;
}
@media screen and (min-width: $sm-breakpoint) {
  .edge {
    height: 12px; // stroke
  }
}

// ===== Nodes
.node {
  position: absolute;
  height: 10px;
  width: 10px;

  display: flex;
  justify-content: center;
  align-items: center;
}
.settlement {
  width: 80%;
  height: 80%;
}
.city {
  width: 100%;
  height: 100%;
}
.settlement,
.city {
  border-radius: 4px; // mimic Paper
  border: 2px solid $dark-gray;
}

.BLUE.city {
  border: 4px solid $blue;
  background: $dark-gray;
}
.RED.city {
  border: 4px solid $red;
  background: $dark-gray;
}
.ORANGE.city {
  border: 4px solid $orange;
  background: $dark-gray;
}
.WHITE.city {
  border: 4px solid $white;
  background: $dark-gray;
}

// Taken from https://codepen.io/peeke/pen/BjxXZa.
.pulse {
  cursor: pointer;
  position: absolute;
  left: 50%;
  top: 50%;
  transform: translateX(-50%) translateY(-50%);

  &:after {
    content: "";
    position: absolute;
    left: 0;
    top: 0;
    display: block;
    width: 100%;
    height: 100%;
    background-color: white;
    border-radius: 4px;
    box-shadow: 0 0 8px rgba(0, 0, 0, 0.3);
    animation: pulse-dot 1.25s cubic-bezier(0.455, 0.03, 0.515, 0.955) -0.4s infinite;
  }
}

@keyframes pulse-dot {
  0% {
    transform: scale(0.8);
  }
  50% {
    transform: scale(1);
  }
  100% {
    transform: scale(0.8);
  }
}

.edge .pulse {
  width: 90%;
  height: 90%;
}

.node .pulse {
  width: 75%;
  height: 75%;
}

--- ui/src/pages/Edge.js ---
import React from "react";
import cn from "classnames";

import { tilePixelVector, getEdgeTransform } from "../utils/coordinates";
import useWindowSize from "../utils/useWindowSize";

function Road({ color }) {
  return <div className={cn("road", color)}></div>;
}

export default function Edge({
  id,
  center,
  size,
  coordinate,
  direction,
  color,
  flashing,
  onClick,
}) {
  const { width } = useWindowSize();
  const [centerX, centerY] = center;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const transform = getEdgeTransform(direction, size, width);

  return (
    <div
      id={id}
      className={"edge " + direction}
      style={{
        left: tileX,
        top: tileY,
        width: size * 0.9,
        transform: transform,
      }}
      onClick={onClick}
    >
      {color && <Road color={color} />}
      {flashing && <div className="pulse"></div>}
    </div>
  );
}

--- ui/src/pages/GameScreen.js ---
import React, { useEffect, useState, useContext } from "react";
import { useParams } from "react-router-dom";
import PropTypes from "prop-types";
import Loader from "react-loader-spinner";
import { useSnackbar } from "notistack";

import ZoomableBoard from "./ZoomableBoard";
import ActionsToolbar from "./ActionsToolbar";

import "react-loader-spinner/dist/loader/css/react-spinner-loader.css";
import "./GameScreen.scss";
import LeftDrawer from "../components/LeftDrawer";
import { store } from "../store";
import ACTIONS from "../actions";
import { getState, postAction } from "../utils/apiClient";
import { dispatchSnackbar } from "../components/Snackbar";
import { getHumanColor } from "../utils/stateUtils";

const ROBOT_THINKING_TIME = 300;

function GameScreen({ replayMode }) {
  const { gameId, stateIndex } = useParams();
  const { state, dispatch } = useContext(store);
  const { enqueueSnackbar, closeSnackbar } = useSnackbar();
  const [isBotThinking, setIsBotThinking] = useState(false);

  // Load game state
  useEffect(() => {
    if (!gameId) {
      return;
    }

    (async () => {
      const gameState = await getState(gameId, stateIndex);
      dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
    })();
  }, [gameId, stateIndex, dispatch]);

  // Maybe kick off next query?
  useEffect(() => {
    if (!state.gameState || replayMode) {
      return;
    }
    if (
      state.gameState.bot_colors.includes(state.gameState.current_color) &&
      !state.gameState.winning_color
    ) {
      // Make bot click next action.
      (async () => {
        setIsBotThinking(true);
        const start = new Date();
        const gameState = await postAction(gameId);
        const requestTime = new Date() - start;
        setTimeout(() => {
          // simulate thinking
          setIsBotThinking(false);
          dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
          if (getHumanColor(gameState)) {
            dispatchSnackbar(enqueueSnackbar, closeSnackbar, gameState);
          }
        }, ROBOT_THINKING_TIME - requestTime);
      })();
    }
  }, [
    gameId,
    replayMode,
    state.gameState,
    dispatch,
    enqueueSnackbar,
    closeSnackbar,
  ]);

  if (!state.gameState) {
    return (
      <main>
        <Loader
          className="loader"
          type="Grid"
          color="#000000"
          height={100}
          width={100}
        />
      </main>
    );
  }

  return (
    <main>
      <h1 className="logo">Catanatron</h1>
      <ZoomableBoard replayMode={replayMode} />
      <ActionsToolbar isBotThinking={isBotThinking} replayMode={replayMode} />
      <LeftDrawer />
    </main>
  );
}

GameScreen.propTypes = {
  /**
   * Injected by the documentation to work in an iframe.
   * You won't need it on your project.
   */
  window: PropTypes.func,
};

export default GameScreen;

--- ui/src/pages/GameScreen.scss ---
@import "../variables.scss";

.MuiToolbar-root {
  background: $black;
}

h6.MuiTypography-h6 {
  font-family: "Bungee Inline", sans-serif;
}

@media (min-width: 600px) {
  #root .snackbar-container {
    display: none;
  }
}

// For Snackbar
#root .snackbar-container {
  z-index: 1200;
  left: 50% !important;
  bottom: 0px;
  transform: translateX(-50%);
  max-width: $sm-breakpoint;
  width: 100%;
  .MuiCollapse-container {
    padding: 0 10px;
    width: 100%;
    .MuiCollapse-wrapper {
      margin-top: 10px;
      margin-bottom: 10px;
      height: 60px;
      padding: 0;

      > div > div {
        height: 100%;

        > div {
          height: 100%;
        }
      }
    }
  }
}

main {
  .logo {
    margin: 20px 20px 0 20px;
    text-align: center;
  }

  background: $black;
  color: white;

  height: 100%;
  display: flex;
  flex-direction: column;

  .loader {
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .board-container,
  .loader {
    height: 100%;
    width: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
  }
}

.board-container {
  .react-transform-component {
    height: 100%;
    width: 100%;

    .react-transform-element {
      height: 100%;
      width: 100%;
    }
  }

  .board {
    position: relative;
    opacity: 0;

    height: 100%;
    width: 100%;
  }
  .board.show {
    opacity: 1;
  }
}

@media (min-width: $md-breakpoint) {
  main {
    padding-left: 280px;
  }
}

--- ui/src/pages/HomePage.js ---
import React, { useState } from "react";
import { useHistory } from "react-router-dom";

import "./HomePage.scss";
import { Button } from "@material-ui/core";
import Loader from "react-loader-spinner";
import { createGame } from "../utils/apiClient";

export default function HomePage() {
  const [loading, setLoading] = useState(false);
  const history = useHistory();

  const handleCreateGame = async (players) => {
    setLoading(true);
    const gameId = await createGame(players);
    setLoading(false);
    history.push("/games/" + gameId);
  };

  return (
    <div className="home-page">
      <h1 className="logo">Catanatron</h1>
      <div className="switchable">
        {!loading && (
          <>
            <ul>
              <li>1V1</li>
              <li>OPEN HAND</li>
              <li>NO CHOICE DURING DISCARD</li>
            </ul>
            <Button
              variant="contained"
              color="primary"
              onClick={() => handleCreateGame(["HUMAN", "CATANATRON"])}
            >
              Play against Catanatron
            </Button>
            <Button
              variant="contained"
              color="secondary"
              onClick={() => handleCreateGame(["RANDOM", "RANDOM"])}
            >
              Watch Random Bots
            </Button>
            <Button
              variant="contained"
              color="secondary"
              onClick={() => handleCreateGame(["CATANATRON", "CATANATRON"])}
            >
              Watch Catanatron
            </Button>
          </>
        )}
        {loading && (
          <Loader
            className="loader"
            type="Grid"
            color="#ffffff"
            height={60}
            width={60}
          />
        )}
      </div>
    </div>
  );
}

--- ui/src/pages/HomePage.scss ---
@import "../variables.scss";

.home-page {
  height: 100%;

  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;

  h1 {
    color: white;
    font-size: 2.5rem;
    margin-bottom: 0px;
  }
  ul {
    color: white;
  }

  .switchable {
    height: 224px; // NOTE: Fixed to avoid loading jump
    display: flex;
    flex-direction: column;
    justify-content: center;

    button {
      margin-bottom: $sm-gutter;
    }
  }
}

--- ui/src/pages/Node.js ---
import React from "react";
import cn from "classnames";

import { tilePixelVector, getNodeDelta, SQRT3 } from "../utils/coordinates";

function Building({ building, color }) {
  const type = building === "CITY" ? "city" : "settlement";
  return <div className={cn(color, type)}></div>;
}

export default function Node({
  id,
  center,
  size,
  coordinate,
  direction,
  building,
  color,
  flashing,
  onClick,
}) {
  const [centerX, centerY] = center;
  const w = SQRT3 * size;
  const h = 2 * size;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const [deltaX, deltaY] = getNodeDelta(direction, w, h);
  const x = tileX + deltaX;
  const y = tileY + deltaY;

  return (
    <div
      className="node"
      style={{
        width: size * 0.5,
        height: size * 0.5,
        left: x,
        top: y,
        transform: `translateY(-50%) translateX(-50%)`,
      }}
      onClick={onClick}
    >
      {color && <Building building={building} color={color} />}
      {flashing && <div className="pulse"></div>}
      {/* {id} */}
    </div>
  );
}

--- ui/src/pages/Robber.js ---
import React from "react";

import { NumberToken } from "./Tile";
import { SQRT3, tilePixelVector } from "../utils/coordinates";

export default function Robber({ center, size, coordinate }) {
  const [centerX, centerY] = center;
  const w = SQRT3 * size;
  const [tileX, tileY] = tilePixelVector(coordinate, size, centerX, centerY);
  const [deltaX, deltaY] = [-w / 2 + w / 8, 0];
  const x = tileX + deltaX;
  const y = tileY + deltaY;

  return (
    <NumberToken
      className="robber"
      size={size}
      style={{
        left: x,
        top: y,
      }}
    >
      R
    </NumberToken>
  );
}

--- ui/src/pages/Tile.js ---
import React from "react";
import cn from "classnames";
import Paper from "@material-ui/core/Paper";

import "./Tile.scss";
import brickTile from "../assets/tile_brick.svg";
import desertTile from "../assets/tile_desert.svg";
import grainTile from "../assets/tile_wheat.svg";
import lumberTile from "../assets/tile_wood.svg";
import oreTile from "../assets/tile_ore.svg";
import woolTile from "../assets/tile_sheep.svg";
import { SQRT3, tilePixelVector } from "../utils/coordinates";

export function NumberToken({ className, children, style, size }) {
  return (
    <Paper
      elevation={3}
      className={cn("number-token", className)}
      style={{
        "--base-size": `${size}px`, // this var can be overrided via `style` prop
        ...style,
      }}
    >
      {children}
    </Paper>
  );
}

const numberToPips = (number) => {
  switch (number) {
    case 2:
    case 12:
      return "•";
    case 3:
    case 11:
      return "••";
    case 4:
    case 10:
      return "•••";
    case 5:
    case 9:
      return "••••";
    case 6:
    case 8:
      return "•••••";
    default:
      return "";
  }
};

export default function Tile({ center, coordinate, tile, size }) {
  const w = SQRT3 * size;
  const h = 2 * size;
  const [centerX, centerY] = center;
  const [x, y] = tilePixelVector(coordinate, size, centerX, centerY);

  let contents;
  let resourceTile;
  if (tile.type === "RESOURCE_TILE") {
    contents = (
      <NumberToken size={size}>
        <div>{tile.number}</div>
        <div class="pips">{numberToPips(tile.number)}</div>
      </NumberToken>
    );
    resourceTile = {
      BRICK: brickTile,
      SHEEP: woolTile,
      ORE: oreTile,
      WOOD: lumberTile,
      WHEAT: grainTile,
    }[tile.resource];
  } else if (tile.type === "DESERT") {
    resourceTile = desertTile;
  } else if (tile.type === "PORT") {
    let x = 0;
    let y = 0;
    if (tile.direction.includes("SOUTH")) {
      y += size / 3;
    }
    if (tile.direction.includes("NORTH")) {
      y -= size / 3;
    }
    if (tile.direction.includes("WEST")) {
      x -= size / 4;
      if (tile.direction === "WEST") {
        x = -size / 3;
      }
    }
    if (tile.direction.includes("EAST")) {
      x += size / 4;
      if (tile.direction === "EAST") {
        x = size / 3;
      }
    }
    if (tile.resource === null) {
      contents = (
        <div
          className="port"
          style={{
            left: x,
            top: y,
          }}
        >
          3:1
        </div>
      );
    } else {
      const portBackground = {
        BRICK: brickTile,
        SHEEP: woolTile,
        ORE: oreTile,
        WOOD: lumberTile,
        WHEAT: grainTile,
      }[tile.resource];
      contents = (
        <div
          className="port"
          style={{
            left: x,
            top: y,
            backgroundImage: `url('${portBackground}')`,
            height: 60,
            backgroundSize: "contain",
            width: 52,
            backgroundRepeat: "no-repeat",
          }}
        >
          2:1
        </div>
      );
    }
  }

  return (
    <div
      key={coordinate}
      className="tile"
      style={{
        left: x - w / 2,
        top: y - h / 2,
        width: w,
        height: h,
        backgroundImage: `url('${resourceTile}')`,
        backgroundSize: "contain",
      }}
    >
      {contents}
    </div>
  );
}

--- ui/src/pages/Tile.scss ---
@import "../variables.scss";

.number-token {
    --scale-factor: 0.65;
    --base-font-size: 100%;
    height: 4ch;
    width: 4ch;
    text-align: center;
    padding: 5px;
    line-height: .8rem;
    position: relative;
    display: flex;
    flex-direction: column;
    .pips {
        font-size: calc(var(--base-font-size) * 60%);
    }
}

@media(max-width: $sm-breakpoint) {
    .number-token {
        --base-font-size: 75%;
    }
}


--- ui/src/pages/ZoomableBoard.js ---
import React, { useCallback, useContext, useEffect, useState } from "react";
import { TransformWrapper, TransformComponent } from "react-zoom-pan-pinch";
import memoize from "fast-memoize";
import { useMediaQuery, useTheme } from "@material-ui/core";

import useWindowSize from "../utils/useWindowSize";

import "./Board.scss";
import { store } from "../store";
import { isPlayersTurn } from "../utils/stateUtils";
import { postAction } from "../utils/apiClient";
import { useParams } from "react-router";
import ACTIONS from "../actions";
import Board from "./Board";

/**
 * Returns object representing actions to be taken if click on node.
 * @returns {3 => ["BLUE", "BUILD_CITY", 3], ...}
 */
function buildNodeActions(state) {
  if (!isPlayersTurn(state.gameState)) {
    return {};
  }

  const nodeActions = {};
  const buildInitialSettlementActions = state.gameState.is_initial_build_phase
    ? state.gameState.current_playable_actions.filter(
        (action) => action[1] === "BUILD_SETTLEMENT"
      )
    : [];
  const inInitialBuildPhase = state.gameState.is_initial_build_phase;
  if (inInitialBuildPhase) {
    buildInitialSettlementActions.forEach((action) => {
      nodeActions[action[2]] = action;
    });
  } else if (state.isBuildingSettlement) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_SETTLEMENT")
      .forEach((action) => {
        nodeActions[action[2]] = action;
      });
  } else if (state.isBuildingCity) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_CITY")
      .forEach((action) => {
        nodeActions[action[2]] = action;
      });
  }
  return nodeActions;
}

function buildEdgeActions(state) {
  if (!isPlayersTurn(state.gameState)) {
    return {};
  }

  const edgeActions = {};
  const buildInitialRoadActions = state.gameState.is_initial_build_phase
    ? state.gameState.current_playable_actions.filter(
        (action) => action[1] === "BUILD_ROAD"
      )
    : [];
  const inInitialBuildPhase = state.gameState.is_initial_build_phase;
  if (inInitialBuildPhase) {
    buildInitialRoadActions.forEach((action) => {
      edgeActions[action[2]] = action;
    });
  } else if (state.isBuildingRoad) {
    state.gameState.current_playable_actions
      .filter((action) => action[1] === "BUILD_ROAD")
      .forEach((action) => {
        edgeActions[action[2]] = action;
      });
  }
  return edgeActions;
}

export default function ZoomableBoard({ replayMode }) {
  const { gameId } = useParams();
  const { state, dispatch } = useContext(store);
  const { width, height } = useWindowSize();
  const theme = useTheme();
  const isMobile = useMediaQuery(theme.breakpoints.up("md"));
  const [show, setShow] = useState(false);

  // TODO: Move these up to GameScreen and let Zoomable be presentational component
  // https://stackoverflow.com/questions/61255053/react-usecallback-with-parameter
  const buildOnNodeClick = useCallback(
    memoize((id, action) => async () => {
      console.log("Clicked Node ", id, action);
      if (action) {
        const gameState = await postAction(gameId, action);
        dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      }
    }),
    []
  );
  const buildOnEdgeClick = useCallback(
    memoize((id, action) => async () => {
      console.log("Clicked Edge ", id, action);
      if (action) {
        const gameState = await postAction(gameId, action);
        dispatch({ type: ACTIONS.SET_GAME_STATE, data: gameState });
      }
    }),
    []
  );

  const nodeActions = replayMode ? {} : buildNodeActions(state);
  const edgeActions = replayMode ? {} : buildEdgeActions(state);

  useEffect(() => {
    setTimeout(() => {
      setShow(true);
    }, 300);
  }, []);

  return (
    <TransformWrapper
      options={{
        limitToBounds: true,
      }}
    >
      {({
        zoomIn,
        zoomOut,
        resetTransform,
        positionX,
        positionY,
        scale,
        previousScale,
      }) => (
        <React.Fragment>
          <div className="board-container">
            <TransformComponent>
              <Board
                width={width}
                height={height}
                buildOnNodeClick={buildOnNodeClick}
                buildOnEdgeClick={buildOnEdgeClick}
                nodeActions={nodeActions}
                edgeActions={edgeActions}
                replayMode={replayMode}
                show={show}
                gameState={state.gameState}
                isMobile={isMobile}
              ></Board>
            </TransformComponent>
          </div>
        </React.Fragment>
      )}
    </TransformWrapper>
  );
}

--- ui/src/utils/apiClient.js ---
import axios from "axios";

import { API_URL } from "../configuration";

export async function createGame(players) {
  const response = await axios.post(API_URL + "/api/games", { players });
  return response.data.game_id;
}

export async function getState(gameId, stateIndex = "latest") {
  const response = await axios.get(
    `${API_URL}/api/games/${gameId}/states/${stateIndex}`
  );
  return response.data;
}

/** action=undefined means bot action */
export async function postAction(gameId, action = undefined) {
  const response = await axios.post(
    `${API_URL}/api/games/${gameId}/actions`,
    action
  );
  return response.data;
}

--- ui/src/utils/coordinates.js ---
// Helpers for implementing https://www.redblobgames.com/grids/hexagons/

// Gives center coordinate for tile.
export function tilePixelVector(coordinate, size, centerX, centerY) {
  const hex = cubeToAxial(coordinate);
  return [
    size * (SQRT3 * hex.q + (SQRT3 / 2) * hex.r) + centerX,
    size * (3 / 2) * hex.r + centerY,
  ];
}

export function cubeToAxial(cube) {
  return { q: cube[0], r: cube[2] };
}
export function getNodeDelta(direction, w, h) {
  switch (direction) {
    case "NORTH":
      return [0, -h / 2];
    case "NORTHEAST":
      return [w / 2, -h / 4];
    case "SOUTHEAST":
      return [w / 2, h / 4];
    case "SOUTH":
      return [0, h / 2];
    case "SOUTHWEST":
      return [-w / 2, h / 4];
    case "NORTHWEST":
      return [-w / 2, -h / 4];
    default:
      throw Error("Unkown direction " + direction);
  }
}

export function getEdgeTransform(direction, size) {
  const distanceToEdge = size * 0.865;
  const translate = (deg) =>
    `translateX(-50%) translateY(-50%) rotate(${deg}deg) translateY(${-distanceToEdge}px)`;
  switch (direction) {
    case "NORTHEAST":
      return `${translate(30)}`;
    case "EAST":
      return `${translate(90)}`;
    case "SOUTHEAST":
      return `${translate(150)}`;
    case "SOUTHWEST":
      return `${translate(210)}`;
    case "WEST":
      return `${translate(270)}`;
    case "NORTHWEST":
      return `${translate(330)}`;
    default:
      throw Error("Unkown direction " + direction);
  }
}

export const SQRT3 = 1.73205080757;

--- ui/src/utils/stateUtils.js ---
export function isPlayersTurn(gameState) {
  return !gameState.bot_colors.includes(gameState.current_color);
}

export function playerKey(gameState, color) {
  return `P${gameState.colors.indexOf(color)}`;
}

export function getHumanColor(gameState) {
  return gameState.colors.find(
    (color) => !gameState.bot_colors.includes(color)
  );
}

--- ui/src/utils/useWindowSize.js ---
import { useEffect, useState } from "react";

// Hook
export default function useWindowSize() {
  // Initialize state with undefined width/height so server and client renders match
  // Learn more here: https://joshwcomeau.com/react/the-perils-of-rehydration/
  const [windowSize, setWindowSize] = useState({
    width: undefined,
    height: undefined,
  });

  useEffect(() => {
    // Handler to call on window resize
    function handleResize() {
      // Set window width/height to state
      setWindowSize({
        width: window.innerWidth,
        height: window.innerHeight,
      });
    }

    // Add event listener
    window.addEventListener("resize", handleResize);

    // Call handler right away so state gets updated with initial window size
    handleResize();

    // Remove event listener on cleanup
    return () => window.removeEventListener("resize", handleResize);
  }, []); // Empty array ensures that effect is only run on mount

  return windowSize;
}
